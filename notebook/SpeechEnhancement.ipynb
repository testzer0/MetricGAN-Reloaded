{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4iym5MuJ7VB"
      },
      "source": [
        "This is an implementation of MetricGAN in pytorch.\n",
        "The specific model architecture and hyperparameters are taken from [1], which was implemented in keras.\n",
        "\n",
        "[1] https://github.com/JasonSWFu/MetricGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVB1fJiJH34M",
        "outputId": "cf0ebdb6-ee8b-448d-b137-a345f4ca6e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pystoi in /usr/local/lib/python3.7/dist-packages (0.3.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.21.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "# pip installs go here\n",
        "! pip install pystoi\n",
        "! pip install transformers\n",
        "! pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zqHKyrWNP-b"
      },
      "outputs": [],
      "source": [
        "# imports go here\n",
        "from google.colab import drive\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "import time\n",
        "import datetime\n",
        "import re\n",
        "import pickle\n",
        "import subprocess\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from pystoi import stoi\n",
        "\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiUpaUtvZVzs",
        "outputId": "11531da6-ab8b-483b-f982-564991e60317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa73pbX_IXX2"
      },
      "outputs": [],
      "source": [
        "# Global variables go here\n",
        "DATASET_DIR = \"/content/gdrive/MyDrive/MS-SNSD-dataset-30\"\n",
        "SCALE_FACTOR = 10\n",
        "MASK_MIN_VALUE = 0.05\n",
        "TARGET = 1                                                  # 0-1 range of clean-ness\n",
        "BATCH_SIZE = 1\n",
        "CHECKPT_DIR = \"/content/gdrive/MyDrive/se-checkpoints/\"\n",
        "NUM_GAN_EPOCHS = 10              # Original paper uses 200\n",
        "NUM_DISCRIMINATOR_EPOCHS = 2    # Number of discriminator epochs in each GAN epoch [15 before] \n",
        "NUM_GENERATOR_EPOCHS = 2        # Number of generator epochs in each GAN epoch [40 before]\n",
        "FORCE_RESTART = False           # Restart training from epoch 0\n",
        "RESUME_FROM = 8                 # Epoch number (0-indexed) to resume from if FORCE_RESTART is False\n",
        "CONTINUE = False                # Load epoch number but not model states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8luf4mfEIj9b"
      },
      "outputs": [],
      "source": [
        "def get_MS_file_pairs(root_dir, split='train', snrs=[0.0, 10.0, 20.0], high=30.0):\n",
        "  clean_dir = os.path.join(root_dir, split+'/clean')\n",
        "  noisy_dir = os.path.join(root_dir, split+'/noisy')\n",
        "  data = []\n",
        "  clean_data = []\n",
        "  high_data = []\n",
        "  for fname in os.listdir(clean_dir):\n",
        "    if not (fname.startswith('clnsp') and fname.endswith('.wav')):\n",
        "      continue\n",
        "    example_number = int(fname[5:-4])\n",
        "    for snr in snrs:\n",
        "      noisy_name = \"noisy{}_SNRdb_{:.1f}_clnsp{}.wav\".format(example_number, snr, example_number)\n",
        "      if os.path.isfile(os.path.join(noisy_dir, noisy_name)):\n",
        "        data.append((os.path.join(clean_dir, fname), os.path.join(noisy_dir, noisy_name)))\n",
        "        clean_data.append((os.path.join(clean_dir, fname), os.path.join(clean_dir, fname)))\n",
        "    noisy_name = \"noisy{}_SNRdb_{:.1f}_clnsp{}.wav\".format(example_number, high, example_number)\n",
        "    if os.path.isfile(os.path.join(noisy_dir, noisy_name)):\n",
        "      high_data.append((os.path.join(clean_dir, fname), os.path.join(noisy_dir, noisy_name)))\n",
        "  clean_data = list(set(clean_data))\n",
        "  return data, clean_data, high_data\n",
        "\n",
        "def wav_to_spectrogram(wav, normalize=False):\n",
        "  \"\"\"\n",
        "  Given a wav file read in by librosa, performs STFT, then optionally normalizes the result.\n",
        "  Returns the magnitude, the phase of the STFT, and signal length\n",
        "  \"\"\"\n",
        "  orig_length = wav.shape[0]\n",
        "  n_fft = 512                                                                   # Window size *after* padding with zeros\n",
        "  wav_padded = librosa.util.fix_length(wav, orig_length + (n_fft//2))           # Pad the signal for FFT\n",
        "  epsilon = 1e-12\n",
        "\n",
        "  stft = librosa.stft(wav_padded, n_fft=n_fft, hop_length=(n_fft//2), win_length=n_fft, window=scipy.signal.hamming)\n",
        "  result = np.abs(stft)\n",
        "  phase = np.angle(stft)\n",
        "\n",
        "  if normalize:\n",
        "    mean = np.mean(result, axis=1).reshape((257,1))\n",
        "    std = np.std(result, axis=1).reshape((257,1)) + epsilon\n",
        "    result = (result-mean)/std\n",
        "  \n",
        "  result = np.reshape(result.T, (result.shape[1], 257))\n",
        "  return result, phase, orig_length\n",
        "\n",
        "def spectrogram_to_wav(stft, phase, signal_length):\n",
        "  \"\"\"\n",
        "  Convert a spectrogram back to the original audio\n",
        "  \"\"\"\n",
        "  scaled = np.multiply(stft, np.exp(1j*phase)) # Reconstruct the stft result from abs and phase\n",
        "  result = librosa.istft(scaled, hop_length=256, win_length=512, window=scipy.signal.hamming, length=signal_length)\n",
        "  return result\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCi72pNCZe73"
      },
      "outputs": [],
      "source": [
        "file_pairs, clean_pairs, high_pairs = get_MS_file_pairs(DATASET_DIR)\n",
        "new_pairs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mlX6ctSKvfm",
        "outputId": "b700f258-6217-44cd-fdf0-b9c6583c512b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example shape of result:  (775, 257)\n",
            "Example shape of phase:  (257, 775)\n"
          ]
        }
      ],
      "source": [
        "example = librosa.load(file_pairs[0][1], sr=16000)\n",
        "result, phase, orig_length = wav_to_spectrogram(example[0])\n",
        "print(\"Example shape of result: \", result.shape)\n",
        "print(\"Example shape of phase: \", phase.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0gS8k7CPGRR",
        "outputId": "d0c6cad6-7810-4c1b-85de-9b8344e01273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('/content/gdrive/MyDrive/MS-SNSD-dataset-30/train/clean/clnsp174.wav', '/content/gdrive/MyDrive/MS-SNSD-dataset-30/train/noisy/noisy174_SNRdb_0.0_clnsp174.wav')\n"
          ]
        }
      ],
      "source": [
        "print(file_pairs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPCSFfaR03cz"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_dim=257, out_dim=200):\n",
        "    super().__init__()\n",
        "    self.in_dim = in_dim\n",
        "    self.out_dim = out_dim\n",
        "    self.lstms = nn.LSTM(input_size=self.in_dim, hidden_size=self.out_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
        "    self.linear1 = nn.Linear(in_features=2*self.out_dim, out_features=300)\n",
        "    self.leaky_relu = nn.LeakyReLU()\n",
        "    self.dropout = nn.Dropout(p=0.05)\n",
        "    self.linear2 = nn.Linear(in_features=300, out_features=257)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    lstm_out, _ = self.lstms(x)\n",
        "    layer1_out = self.dropout(self.leaky_relu(self.linear1(lstm_out)))\n",
        "    layer2_out = self.sigmoid(self.linear2(layer1_out))\n",
        "    return layer2_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYY43bO65-xy"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_dim=257):\n",
        "    super().__init__()\n",
        "    # We are passed (batch_size, 2, n_frames, in_dim=257) as input -> since we need both clean and noisy\n",
        "    # Note that there is no 'channels_last' feature in pytorch\n",
        "    self.in_dim = in_dim\n",
        "    self.batch_norm = nn.BatchNorm2d(num_features=2)\n",
        "    self.conv2d_sn1 = spectral_norm(nn.Conv2d(in_channels=2, out_channels=15, kernel_size=(5,5), padding='valid'))\n",
        "    self.leaky_relu1 = nn.LeakyReLU()\n",
        "    self.conv2d_sn2 = spectral_norm(nn.Conv2d(in_channels=15, out_channels=35, kernel_size=(7,7), padding='valid'))\n",
        "    self.leaky_relu2 = nn.LeakyReLU()\n",
        "    self.conv2d_sn3 = spectral_norm(nn.Conv2d(in_channels=35, out_channels=65, kernel_size=(9,9), padding='valid'))\n",
        "    self.leaky_relu3 = nn.LeakyReLU()\n",
        "    self.conv2d_sn4 = spectral_norm(nn.Conv2d(in_channels=65, out_channels=90, kernel_size=(11,11), padding='valid'))\n",
        "    self.leaky_relu4 = nn.LeakyReLU()\n",
        "    # pytorch has no global average pooling layer (i.e. (channels, h, w) -> channels)\n",
        "    # use AdaptiveAvgPool2d to get (channels, 1, 1) then flatter\n",
        "    self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.flatten = nn.Flatten()         # Now output should be batch_size x 50\n",
        "    self.linear1 = spectral_norm(nn.Linear(in_features=90, out_features=50))\n",
        "    self.leaky_relu5 = nn.LeakyReLU()\n",
        "    self.linear2 = spectral_norm(nn.Linear(in_features=50, out_features=10))\n",
        "    self.leaky_relu6 = nn.LeakyReLU()\n",
        "    self.linear3 = spectral_norm(nn.Linear(in_features=10, out_features=1))\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.std = 0.1\n",
        "\n",
        "  def std_step(self):\n",
        "    self.std = self.std * 0.9\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_normalized = self.batch_norm(x)\n",
        "    # x_normalized = x_normalized + (self.std**0.5)*torch.randn(x_normalized.shape).to(device)\n",
        "    conv1_out = self.leaky_relu1(self.conv2d_sn1(x_normalized))\n",
        "    conv2_out = self.leaky_relu2(self.conv2d_sn2(conv1_out))\n",
        "    conv3_out = self.leaky_relu3(self.conv2d_sn3(conv2_out))\n",
        "    conv4_out = self.leaky_relu4(self.conv2d_sn4(conv3_out))\n",
        "    global_pool_out = self.flatten(self.global_avg_pool(conv4_out))\n",
        "    linear1_out = self.leaky_relu5(self.linear1(global_pool_out))\n",
        "    linear2_out = self.leaky_relu6(self.linear2(linear1_out))\n",
        "    out = self.linear3(linear2_out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC4l0ByQ55Gs"
      },
      "outputs": [],
      "source": [
        "def get_path_for_generator(path, epoch, create=False):\n",
        "  \"\"\"\n",
        "  Given a path to the noisy wav file, returns the name/path that should be given to the generator's \n",
        "  output wav file in the i-th training epoch\n",
        "  \"\"\"\n",
        "  file_name = path.split('/')[-1]\n",
        "  if create:\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/SE-training/epoch{}'.format(epoch)):\n",
        "      os.mkdir('/content/gdrive/MyDrive/SE-training/epoch{}'.format(epoch))\n",
        "  return '/content/gdrive/MyDrive/SE-training/epoch{}/{}'.format(epoch, file_name)\n",
        "\n",
        "def get_generator_sample(file_pair):\n",
        "  \"\"\"\n",
        "  Given a file pair for (clean, noisy), reads the audio in and creates an appropriate training/test sample for the Generator.\n",
        "  It seems with noisy audio, librosa clips off some audio because its conversion from mel to stft is lossy.\n",
        "  See here: https://stackoverflow.com/questions/60365904/reconstructing-audio-from-a-melspectrogram-has-some-clipping-with-librosa\n",
        "  Thus, we multiply the noisy audio by a constant (10), and later scale the output down by the same amount.\n",
        "  \"\"\"\n",
        "  clean_file, noisy_file = file_pair\n",
        "  noisy_wav, _ = librosa.load(noisy_file, sr=16000)\n",
        "  noisy_spectrogram_normalized, _, _ = wav_to_spectrogram(noisy_wav*SCALE_FACTOR, normalize=True)\n",
        "  noisy_spectrogram, phase, length = wav_to_spectrogram(noisy_wav*SCALE_FACTOR)\n",
        "\n",
        "  clean_wav, _ = librosa.load(clean_file, sr=16000)\n",
        "  clean_spectrogram, _, _ = wav_to_spectrogram(clean_wav)\n",
        "\n",
        "  # The spectrograms now have the shape, (num_frames, frame_dim)\n",
        "  # which is what we want to give to the generator, since it expects (batch_size, seq_length, input_size)\n",
        "  # when batch_first=True is passed\n",
        "  noisy_spectrogram_normalized = torch.from_numpy(noisy_spectrogram_normalized)\n",
        "  noisy_spectrogram = torch.from_numpy(noisy_spectrogram)\n",
        "  clean_spectrogram = torch.from_numpy(clean_spectrogram)\n",
        "  mask = MASK_MIN_VALUE * torch.ones((noisy_spectrogram.shape[0], 257))\n",
        "\n",
        "  return noisy_spectrogram_normalized, noisy_spectrogram, clean_spectrogram, mask, phase, length\n",
        "  \n",
        "def get_discriminator_sample(file_pair):\n",
        "  \"\"\"\n",
        "  The analogous function for the discriminator. Here we pass in a 'clean' sample and a corresponding\n",
        "  'noisy' sample -- except, the noisy sample may also be clean. We want to train the disciminator to give a score close to 1\n",
        "  for clean samples and a score close to 0 for noisy ones. Thus, the 'noisy' sample may also be clean. If it is not, it needs\n",
        "  to be scaled by the scale factor as usual. Whether it is found by checking whether 'SNRdb' appears in its name.\n",
        "  \"\"\"\n",
        "  clean_file, noisy_file = file_pair\n",
        "  noisy_wav, _ = librosa.load(noisy_file, sr=16000)\n",
        "  # if 'SNRdb' in noisy_file:\n",
        "  # Actually 'noisy' -- need the scale factor\n",
        "  noisy_spectrogram, _, _ = wav_to_spectrogram(noisy_wav*SCALE_FACTOR)\n",
        "  # else:\n",
        "  #   noisy_spectrogram, _, _ = wav_to_spectrogram(noisy_wav)\n",
        "  clean_wav, _ = librosa.load(clean_file, sr=16000)\n",
        "  clean_spectrogram, phase, sr = wav_to_spectrogram(clean_wav)\n",
        "  true_stoi_noisy = torch.tensor([float(stoi(x=clean_wav, y=noisy_wav, fs_sig=16000, extended=False))])\n",
        "\n",
        "  # both spectrograms are of the shape (1, n_frames, 257) now\n",
        "  input_np_noisy = np.stack((noisy_spectrogram, clean_spectrogram), axis=-1)\n",
        "  input_torch_noisy = torch.from_numpy(input_np_noisy)\n",
        "\n",
        "  # Now the input is of shape (n_frames, 257, 2) - we need it to be (2, n_frames, 257)\n",
        "  input_torch_noisy = input_torch_noisy.permute(2,0,1)\n",
        "  return input_torch_noisy, true_stoi_noisy, phase, sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxWHwVxKBRbr"
      },
      "outputs": [],
      "source": [
        "class GeneratorDataset(Dataset):\n",
        "  def __init__(self, file_pairs):\n",
        "    super().__init__()\n",
        "    self.file_pairs = file_pairs\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.file_pairs)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return get_generator_sample(self.file_pairs[idx])\n",
        "\n",
        "class DiscriminatorDataset(Dataset):\n",
        "  def __init__(self, file_pairs):\n",
        "    super().__init__()\n",
        "    self.file_pairs = file_pairs\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.file_pairs)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return get_discriminator_sample(self.file_pairs[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpKzltb6rqjA"
      },
      "outputs": [],
      "source": [
        "def get_max_checkpt(checkpt_dir):\n",
        "  max_checkpt = 0\n",
        "  for filename in os.listdir(checkpt_dir):\n",
        "    if re.match(r\"checkpt-gen-([0-9]+).pt\", filename):\n",
        "      checkpt_num = int(filename.split('.')[-2].split('-')[-1])\n",
        "      if checkpt_num > max_checkpt:\n",
        "        max_checkpt = checkpt_num\n",
        "  return max_checkpt\n",
        "\n",
        "def load_latest_checkpt(checkpt_dir=CHECKPT_DIR):\n",
        "  global new_pairs, discriminator_dataset, discriminator_sampler, discriminator_dataloader\n",
        "  if RESUME_FROM == -1:\n",
        "    mx_checkpt = get_max_checkpt(checkpt_dir)\n",
        "  else:\n",
        "    mx_checkpt = RESUME_FROM\n",
        "  if mx_checkpt > 0:\n",
        "    gen_checkpt_file = os.path.join(checkpt_dir, \"checkpt-gen-{}.pt\".format(mx_checkpt))\n",
        "    dis_checkpt_file = os.path.join(checkpt_dir, \"checkpt-dis-{}.pt\".format(mx_checkpt))\n",
        "    genopt_checkpt_file = os.path.join(checkpt_dir, \"checkpt-genopt-{}.pt\".format(mx_checkpt))\n",
        "    disopt_checkpt_file = os.path.join(checkpt_dir, \"checkpt-disopt-{}.pt\".format(mx_checkpt))\n",
        "    generator.load_state_dict(torch.load(gen_checkpt_file))\n",
        "    discriminator.load_state_dict(torch.load(dis_checkpt_file))\n",
        "    generator_optimizer.load_state_dict(torch.load(genopt_checkpt_file))\n",
        "    discriminator_optimizer.load_state_dict(torch.load(disopt_checkpt_file))\n",
        "    new_pairs = pickle.load(open(os.path.join(CHECKPT_DIR, \"npairs_{}.pkl\".format(mx_checkpt)), 'rb'))\n",
        "    discriminator_dataset = DiscriminatorDataset(new_pairs)\n",
        "    discriminator_sampler = RandomSampler(discriminator_dataset)\n",
        "    discriminator_dataloader = DataLoader(discriminator_dataset, sampler=discriminator_sampler, batch_size=BATCH_SIZE)\n",
        "  return mx_checkpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NlU6ziuRPN_",
        "outputId": "ec12d17d-65b7-455b-912f-34ea12df98bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 669, 257]) torch.Size([1, 669, 257]) torch.Size([1, 669, 257]) torch.Size([1, 669, 257])\n",
            "torch.Size([1, 2, 678, 257]) torch.Size([1, 1])\n",
            "Using GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "generator_dataset = GeneratorDataset(file_pairs)\n",
        "discriminator_dataset = DiscriminatorDataset(file_pairs + clean_pairs)\n",
        "generator_sampler = RandomSampler(generator_dataset)\n",
        "discriminator_sampler = RandomSampler(discriminator_dataset)\n",
        "generator_dataloader = DataLoader(generator_dataset, sampler=generator_sampler, batch_size=BATCH_SIZE)\n",
        "discriminator_dataloader = DataLoader(discriminator_dataset, sampler=discriminator_sampler, batch_size=BATCH_SIZE)\n",
        "generator_sample = next(iter(generator_dataloader))\n",
        "discriminator_sample = next(iter(discriminator_dataloader))\n",
        "print(generator_sample[0].shape, generator_sample[1].shape, generator_sample[2].shape, generator_sample[3].shape)\n",
        "print(discriminator_sample[0].shape, discriminator_sample[1].shape)\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator_optimizer = AdamW(generator.parameters(), lr=1e-4, eps=1e-11)\n",
        "discriminator_optimizer = AdamW(discriminator.parameters(), lr=2e-5, eps=1e-11)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
        "  device = torch.device(\"cuda\")\n",
        "  discriminator.cuda()\n",
        "  generator.cuda()\n",
        "else:\n",
        "  print(\"No GPUs available, using CPU\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BckQyUiqLdBW",
        "outputId": "9a356fa9-550a-4b31-c3f4-f0fa13e135aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch 2580 of 6492. Elapsed 0:21:43\n",
            "Sample: 0.8588351607322693 v/s 0.8629838824272156 v/s 0.8842645295535324\n",
            "Batch 2590 of 6492. Elapsed 0:21:49\n",
            "Sample: 0.8019071817398071 v/s 0.7491417527198792 v/s 0.8061253175149075\n",
            "Batch 2600 of 6492. Elapsed 0:21:53\n",
            "Sample: 0.9069784283638 v/s 0.9242422580718994 v/s 0.9371953693172869\n",
            "Batch 2610 of 6492. Elapsed 0:21:58\n",
            "Sample: 0.8859620094299316 v/s 0.9381535649299622 v/s 0.9560934278200134\n",
            "Batch 2620 of 6492. Elapsed 0:22:03\n",
            "Sample: 0.8872944712638855 v/s 0.8725707530975342 v/s 0.9222196722830637\n",
            "Batch 2630 of 6492. Elapsed 0:22:08\n",
            "Sample: 0.6976976990699768 v/s 0.6792864799499512 v/s 0.7507370829836862\n",
            "Batch 2640 of 6492. Elapsed 0:22:13\n",
            "Sample: 0.7672492861747742 v/s 0.8379219174385071 v/s 0.8639492286263397\n",
            "Batch 2650 of 6492. Elapsed 0:22:18\n",
            "Sample: 0.8607964515686035 v/s 0.8904073238372803 v/s 0.9170445185562012\n",
            "Batch 2660 of 6492. Elapsed 0:22:23\n",
            "Sample: 0.8314743041992188 v/s 0.8023664951324463 v/s 0.8663980571146549\n",
            "Batch 2670 of 6492. Elapsed 0:22:27\n",
            "Sample: 0.8132785558700562 v/s 0.7549789547920227 v/s 0.796716541240478\n",
            "Batch 2680 of 6492. Elapsed 0:22:32\n",
            "Sample: 0.7560808062553406 v/s 0.7214502692222595 v/s 0.7876146771249439\n",
            "Batch 2690 of 6492. Elapsed 0:22:37\n",
            "Sample: 0.8023276925086975 v/s 0.8437096476554871 v/s 0.8777024499512514\n",
            "Batch 2700 of 6492. Elapsed 0:22:41\n",
            "Sample: 0.873639702796936 v/s 0.9285311102867126 v/s 0.9435315816760129\n",
            "Batch 2710 of 6492. Elapsed 0:22:46\n",
            "Sample: 0.879967212677002 v/s 0.8059791922569275 v/s 0.8492954477760224\n",
            "Batch 2720 of 6492. Elapsed 0:22:51\n",
            "Sample: 0.7935218811035156 v/s 0.8103380799293518 v/s 0.8433305138551483\n",
            "Batch 2730 of 6492. Elapsed 0:22:56\n",
            "Sample: 0.832198977470398 v/s 0.8592203855514526 v/s 0.901634854674538\n",
            "Batch 2740 of 6492. Elapsed 0:23:00\n",
            "Sample: 0.8597143888473511 v/s 0.8743076324462891 v/s 0.9029088504747207\n",
            "Batch 2750 of 6492. Elapsed 0:23:05\n",
            "Sample: 0.7417263388633728 v/s 0.7840156555175781 v/s 0.8174209443419475\n",
            "Batch 2760 of 6492. Elapsed 0:23:10\n",
            "Sample: 0.8574232459068298 v/s 0.90840744972229 v/s 0.9239141059358119\n",
            "Batch 2770 of 6492. Elapsed 0:23:15\n",
            "Sample: 0.7962540984153748 v/s 0.8066366314888 v/s 0.8454364043497249\n",
            "Batch 2780 of 6492. Elapsed 0:23:20\n",
            "Sample: 0.6572378277778625 v/s 0.6396738886833191 v/s 0.6998857405982868\n",
            "Batch 2790 of 6492. Elapsed 0:23:25\n",
            "Sample: 0.7969303131103516 v/s 0.7775078415870667 v/s 0.8206698373553217\n",
            "Batch 2800 of 6492. Elapsed 0:23:30\n",
            "Sample: 0.8602006435394287 v/s 0.9135282039642334 v/s 0.9321897232828285\n",
            "Batch 2810 of 6492. Elapsed 0:23:35\n",
            "Sample: 0.7664457559585571 v/s 0.7180326581001282 v/s 0.7883007373582148\n",
            "Batch 2820 of 6492. Elapsed 0:23:40\n",
            "Sample: 0.760239839553833 v/s 0.7546071410179138 v/s 0.7962797397170396\n",
            "Batch 2830 of 6492. Elapsed 0:23:44\n",
            "Sample: 0.7519297003746033 v/s 0.7490336894989014 v/s 0.807643452124959\n",
            "Batch 2840 of 6492. Elapsed 0:23:49\n",
            "Sample: 0.6510208249092102 v/s 0.6329588890075684 v/s 0.6999942813849935\n",
            "Batch 2850 of 6492. Elapsed 0:23:54\n",
            "Sample: 0.6991013288497925 v/s 0.7186694145202637 v/s 0.7732897437031749\n",
            "Batch 2860 of 6492. Elapsed 0:23:59\n",
            "Sample: 0.8300148248672485 v/s 0.7520903944969177 v/s 0.7932044880816042\n",
            "Batch 2870 of 6492. Elapsed 0:24:04\n",
            "Sample: 0.8232285380363464 v/s 0.7946295142173767 v/s 0.8516911066979698\n",
            "Batch 2880 of 6492. Elapsed 0:24:09\n",
            "Sample: 0.7350305914878845 v/s 0.7532901763916016 v/s 0.8019417742589314\n",
            "Batch 2890 of 6492. Elapsed 0:24:15\n",
            "Sample: 0.8197790384292603 v/s 0.8292831778526306 v/s 0.8740630120964465\n",
            "Batch 2900 of 6492. Elapsed 0:24:19\n",
            "Sample: 0.8328224420547485 v/s 0.8452889919281006 v/s 0.8792045418171006\n",
            "Batch 2910 of 6492. Elapsed 0:24:24\n",
            "Sample: 0.8246697783470154 v/s 0.8420352935791016 v/s 0.8660106885840153\n",
            "Batch 2920 of 6492. Elapsed 0:24:29\n",
            "Sample: 0.8381040096282959 v/s 0.7606810927391052 v/s 0.7859843297572598\n",
            "Batch 2930 of 6492. Elapsed 0:24:34\n",
            "Sample: 0.787137508392334 v/s 0.7739285230636597 v/s 0.8378211105541988\n",
            "Batch 2940 of 6492. Elapsed 0:24:40\n",
            "Sample: 0.8941716551780701 v/s 0.8561943173408508 v/s 0.8817338684657718\n",
            "Batch 2950 of 6492. Elapsed 0:24:45\n",
            "Sample: 0.8363370895385742 v/s 0.8147772550582886 v/s 0.8617502829653565\n",
            "Batch 2960 of 6492. Elapsed 0:24:50\n",
            "Sample: 0.8266131281852722 v/s 0.7430616617202759 v/s 0.825128581930113\n",
            "Batch 2970 of 6492. Elapsed 0:24:55\n",
            "Sample: 0.6909360885620117 v/s 0.7681857943534851 v/s 0.812611592740917\n",
            "Batch 2980 of 6492. Elapsed 0:25:00\n",
            "Sample: 0.8317418098449707 v/s 0.862598717212677 v/s 0.9017338657519609\n",
            "Batch 2990 of 6492. Elapsed 0:25:06\n",
            "Sample: 0.8557509183883667 v/s 0.8667892217636108 v/s 0.9106020485771718\n",
            "Batch 3000 of 6492. Elapsed 0:25:10\n",
            "Sample: 0.88022381067276 v/s 0.892677366733551 v/s 0.9220012935676356\n",
            "Batch 3010 of 6492. Elapsed 0:25:15\n",
            "Sample: 0.8511682748794556 v/s 0.9289408326148987 v/s 0.9380489462247482\n",
            "Batch 3020 of 6492. Elapsed 0:25:19\n",
            "Sample: 0.8497962951660156 v/s 0.8160824179649353 v/s 0.8460188894356508\n",
            "Batch 3030 of 6492. Elapsed 0:25:25\n",
            "Sample: 0.7691196203231812 v/s 0.7668251991271973 v/s 0.8406986457970081\n",
            "Batch 3040 of 6492. Elapsed 0:25:30\n",
            "Sample: 0.7529548406600952 v/s 0.7153570652008057 v/s 0.7660670228005538\n",
            "Batch 3050 of 6492. Elapsed 0:25:35\n",
            "Sample: 0.7074416279792786 v/s 0.6634215712547302 v/s 0.7109445452941305\n",
            "Batch 3060 of 6492. Elapsed 0:25:39\n",
            "Sample: 0.7944260239601135 v/s 0.7542649507522583 v/s 0.8231367923843269\n",
            "Batch 3070 of 6492. Elapsed 0:25:44\n",
            "Sample: 0.8347179293632507 v/s 0.8824788928031921 v/s 0.8921719824830026\n",
            "Batch 3080 of 6492. Elapsed 0:25:49\n",
            "Sample: 0.8709229826927185 v/s 0.8741807341575623 v/s 0.9055820252552724\n",
            "Batch 3090 of 6492. Elapsed 0:25:54\n",
            "Sample: 0.7876744270324707 v/s 0.7995641231536865 v/s 0.837019063963009\n",
            "Batch 3100 of 6492. Elapsed 0:25:59\n",
            "Sample: 0.7642641067504883 v/s 0.7236015200614929 v/s 0.7669109901168245\n",
            "Batch 3110 of 6492. Elapsed 0:26:03\n",
            "Sample: 0.8123288154602051 v/s 0.7388121485710144 v/s 0.8154606307282862\n",
            "Batch 3120 of 6492. Elapsed 0:26:08\n",
            "Sample: 0.8711454272270203 v/s 0.8843271136283875 v/s 0.9058228032808026\n",
            "Batch 3130 of 6492. Elapsed 0:26:12\n",
            "Sample: 0.8056289553642273 v/s 0.7952475547790527 v/s 0.8530607184739513\n",
            "Batch 3140 of 6492. Elapsed 0:26:17\n",
            "Sample: 0.8154598474502563 v/s 0.8251366019248962 v/s 0.8520001392238437\n",
            "Batch 3150 of 6492. Elapsed 0:26:22\n",
            "Sample: 0.8595776557922363 v/s 0.8788422346115112 v/s 0.911923999603365\n",
            "Batch 3160 of 6492. Elapsed 0:26:27\n",
            "Sample: 0.8493762612342834 v/s 0.8836868405342102 v/s 0.906396464530367\n",
            "Batch 3170 of 6492. Elapsed 0:26:33\n",
            "Sample: 0.8355811238288879 v/s 0.8009964227676392 v/s 0.8300312628369597\n",
            "Batch 3180 of 6492. Elapsed 0:26:38\n",
            "Sample: 0.9111621379852295 v/s 0.8894351720809937 v/s 0.9034528062428998\n",
            "Batch 3190 of 6492. Elapsed 0:26:42\n",
            "Sample: 0.8128125667572021 v/s 0.835899293422699 v/s 0.8764997054654075\n",
            "Batch 3200 of 6492. Elapsed 0:26:48\n",
            "Sample: 0.7506924867630005 v/s 0.7170117497444153 v/s 0.8188640827793685\n",
            "Batch 3210 of 6492. Elapsed 0:26:53\n",
            "Sample: 0.8085328340530396 v/s 0.7957239747047424 v/s 0.8279743974599417\n",
            "Batch 3220 of 6492. Elapsed 0:26:57\n",
            "Sample: 0.8877745866775513 v/s 0.9180567860603333 v/s 0.9328961635707703\n",
            "Batch 3230 of 6492. Elapsed 0:27:01\n",
            "Sample: 0.8086073994636536 v/s 0.7300684452056885 v/s 0.8064782554400234\n",
            "Batch 3240 of 6492. Elapsed 0:27:06\n",
            "Sample: 0.8099947571754456 v/s 0.8581196665763855 v/s 0.8807648924003694\n",
            "Batch 3250 of 6492. Elapsed 0:27:11\n",
            "Sample: 0.8578755855560303 v/s 0.8952106237411499 v/s 0.9120450976092684\n",
            "Batch 3260 of 6492. Elapsed 0:27:15\n",
            "Sample: 0.8540169596672058 v/s 0.9285269379615784 v/s 0.942751431804498\n",
            "Batch 3270 of 6492. Elapsed 0:27:20\n",
            "Sample: 0.7515406608581543 v/s 0.7033982276916504 v/s 0.7539284963719375\n",
            "Batch 3280 of 6492. Elapsed 0:27:25\n",
            "Sample: 0.8862245678901672 v/s 0.907975971698761 v/s 0.9274605615180723\n",
            "Batch 3290 of 6492. Elapsed 0:27:30\n",
            "Sample: 0.8570480346679688 v/s 0.875571608543396 v/s 0.8903848326939526\n",
            "Batch 3300 of 6492. Elapsed 0:27:34\n",
            "Sample: 0.8465779423713684 v/s 0.8712120056152344 v/s 0.8869305645890464\n",
            "Batch 3310 of 6492. Elapsed 0:27:39\n",
            "Sample: 0.8806723952293396 v/s 0.9171237349510193 v/s 0.9495267335952108\n",
            "Batch 3320 of 6492. Elapsed 0:27:44\n",
            "Sample: 0.8793967962265015 v/s 0.8566546440124512 v/s 0.8879366008663312\n",
            "Batch 3330 of 6492. Elapsed 0:27:49\n",
            "Sample: 0.8376801013946533 v/s 0.7775800824165344 v/s 0.8414780940618957\n",
            "Batch 3340 of 6492. Elapsed 0:27:55\n",
            "Sample: 0.7074920535087585 v/s 0.6792383790016174 v/s 0.7330349076798836\n",
            "Batch 3350 of 6492. Elapsed 0:27:59\n",
            "Sample: 0.8262554407119751 v/s 0.7932597398757935 v/s 0.829754008584864\n",
            "Batch 3360 of 6492. Elapsed 0:28:04\n",
            "Sample: 0.8238025903701782 v/s 0.8183238506317139 v/s 0.8560451319946457\n",
            "Batch 3370 of 6492. Elapsed 0:28:10\n",
            "Sample: 0.7646245956420898 v/s 0.7634502053260803 v/s 0.8377536102616877\n",
            "Batch 3380 of 6492. Elapsed 0:28:14\n",
            "Sample: 0.7526161670684814 v/s 0.7464195489883423 v/s 0.8076955140090455\n",
            "Batch 3390 of 6492. Elapsed 0:28:18\n",
            "Sample: 0.8723873496055603 v/s 0.8354593515396118 v/s 0.883438217868084\n",
            "Batch 3400 of 6492. Elapsed 0:28:23\n",
            "Sample: 0.8252851963043213 v/s 0.8246793150901794 v/s 0.8532794192314394\n",
            "Batch 3410 of 6492. Elapsed 0:28:28\n",
            "Sample: 0.8324284553527832 v/s 0.7588152289390564 v/s 0.8310019026767228\n",
            "Batch 3420 of 6492. Elapsed 0:28:34\n",
            "Sample: 0.8006824254989624 v/s 0.7857356071472168 v/s 0.8482200057092274\n",
            "Batch 3430 of 6492. Elapsed 0:28:39\n",
            "Sample: 0.7533367872238159 v/s 0.8006230592727661 v/s 0.8361523353489412\n",
            "Batch 3440 of 6492. Elapsed 0:28:44\n",
            "Sample: 0.7978334426879883 v/s 0.8181171417236328 v/s 0.8812799184403625\n",
            "Batch 3450 of 6492. Elapsed 0:28:49\n",
            "Sample: 0.790355920791626 v/s 0.7794911861419678 v/s 0.8263115233464512\n",
            "Batch 3460 of 6492. Elapsed 0:28:54\n",
            "Sample: 0.8896453976631165 v/s 0.8776067495346069 v/s 0.9205836065862285\n",
            "Batch 3470 of 6492. Elapsed 0:28:58\n",
            "Sample: 0.8372149467468262 v/s 0.8987825512886047 v/s 0.9156040527909083\n",
            "Batch 3480 of 6492. Elapsed 0:29:03\n",
            "Sample: 0.871160626411438 v/s 0.9014173746109009 v/s 0.9339345265384389\n",
            "Batch 3490 of 6492. Elapsed 0:29:08\n",
            "Sample: 0.7955808043479919 v/s 0.8837947845458984 v/s 0.9057997113119697\n",
            "Batch 3500 of 6492. Elapsed 0:29:13\n",
            "Sample: 0.8477756977081299 v/s 0.876705527305603 v/s 0.9053468390253913\n",
            "Batch 3510 of 6492. Elapsed 0:29:17\n",
            "Sample: 0.8486388921737671 v/s 0.8153864145278931 v/s 0.8644582390126844\n",
            "Batch 3520 of 6492. Elapsed 0:29:22\n",
            "Sample: 0.7468471527099609 v/s 0.668961763381958 v/s 0.741025723297333\n",
            "Batch 3530 of 6492. Elapsed 0:29:27\n",
            "Sample: 0.7847520112991333 v/s 0.8095880150794983 v/s 0.8444342594822968\n",
            "Batch 3540 of 6492. Elapsed 0:29:32\n",
            "Sample: 0.7859402298927307 v/s 0.832779049873352 v/s 0.8655447285402824\n",
            "Batch 3550 of 6492. Elapsed 0:29:36\n",
            "Sample: 0.7531222701072693 v/s 0.7645787000656128 v/s 0.8414312830654925\n",
            "Batch 3560 of 6492. Elapsed 0:29:41\n",
            "Sample: 0.7784873843193054 v/s 0.8797674775123596 v/s 0.9052374628099249\n",
            "Batch 3570 of 6492. Elapsed 0:29:46\n",
            "Sample: 0.8232510685920715 v/s 0.8250241279602051 v/s 0.8687617258428126\n",
            "Batch 3580 of 6492. Elapsed 0:29:52\n",
            "Sample: 0.777004599571228 v/s 0.7882866263389587 v/s 0.8476343393396789\n",
            "Batch 3590 of 6492. Elapsed 0:29:57\n",
            "Sample: 0.8162848353385925 v/s 0.8584862947463989 v/s 0.8831591274971548\n",
            "Batch 3600 of 6492. Elapsed 0:30:02\n",
            "Sample: 0.8367320895195007 v/s 0.7661330103874207 v/s 0.7998157655976874\n",
            "Batch 3610 of 6492. Elapsed 0:30:06\n",
            "Sample: 0.7969589233398438 v/s 0.8161406517028809 v/s 0.8581585112514379\n",
            "Batch 3620 of 6492. Elapsed 0:30:11\n",
            "Sample: 0.8039126992225647 v/s 0.8062935471534729 v/s 0.8630706230066686\n",
            "Batch 3630 of 6492. Elapsed 0:30:15\n",
            "Sample: 0.8394852876663208 v/s 0.8480122685432434 v/s 0.8809764641173783\n",
            "Batch 3640 of 6492. Elapsed 0:30:20\n",
            "Sample: 0.7936673164367676 v/s 0.7750938534736633 v/s 0.8145128545005732\n",
            "Batch 3650 of 6492. Elapsed 0:30:25\n",
            "Sample: 0.789787232875824 v/s 0.8341096043586731 v/s 0.8891478332253818\n",
            "Batch 3660 of 6492. Elapsed 0:30:29\n",
            "Sample: 0.7371856570243835 v/s 0.6910297870635986 v/s 0.7375746929327992\n",
            "Batch 3670 of 6492. Elapsed 0:30:35\n",
            "Sample: 0.7837435603141785 v/s 0.7525855302810669 v/s 0.826640319116466\n",
            "Batch 3680 of 6492. Elapsed 0:30:40\n",
            "Sample: 0.876803994178772 v/s 0.9923332929611206 v/s 0.9894594256948963\n",
            "Batch 3690 of 6492. Elapsed 0:30:44\n",
            "Sample: 0.8386855125427246 v/s 0.8410817384719849 v/s 0.8656738057090726\n",
            "Batch 3700 of 6492. Elapsed 0:30:49\n",
            "Sample: 0.7136235237121582 v/s 0.7177377343177795 v/s 0.7835607389876402\n",
            "Batch 3710 of 6492. Elapsed 0:30:54\n",
            "Sample: 0.7793689370155334 v/s 0.7745081782341003 v/s 0.8475057247821759\n",
            "Batch 3720 of 6492. Elapsed 0:30:59\n",
            "Sample: 0.8484194278717041 v/s 0.8556214570999146 v/s 0.8802864442874987\n",
            "Batch 3730 of 6492. Elapsed 0:31:03\n",
            "Sample: 0.8476617336273193 v/s 0.8468277454376221 v/s 0.8828328692417358\n",
            "Batch 3740 of 6492. Elapsed 0:31:08\n",
            "Sample: 0.7560994625091553 v/s 0.7297248840332031 v/s 0.7620665227727874\n",
            "Batch 3750 of 6492. Elapsed 0:31:14\n",
            "Sample: 0.7906173467636108 v/s 0.7534608244895935 v/s 0.799584966481684\n",
            "Batch 3760 of 6492. Elapsed 0:31:18\n",
            "Sample: 0.8155983090400696 v/s 0.8277300000190735 v/s 0.8696203479086412\n",
            "Batch 3770 of 6492. Elapsed 0:31:23\n",
            "Sample: 0.88334721326828 v/s 0.8940237164497375 v/s 0.9216555059843142\n",
            "Batch 3780 of 6492. Elapsed 0:31:29\n",
            "Sample: 0.8401861190795898 v/s 0.8698288202285767 v/s 0.8999794887133449\n",
            "Batch 3790 of 6492. Elapsed 0:31:33\n",
            "Sample: 0.8287414312362671 v/s 0.8323608040809631 v/s 0.8826564654282762\n",
            "Batch 3800 of 6492. Elapsed 0:31:38\n",
            "Sample: 0.7604624032974243 v/s 0.7492198944091797 v/s 0.8108230050066725\n",
            "Batch 3810 of 6492. Elapsed 0:31:42\n",
            "Sample: 0.7521517276763916 v/s 0.7444300651550293 v/s 0.7950264855367426\n",
            "Batch 3820 of 6492. Elapsed 0:31:47\n",
            "Sample: 0.7906726002693176 v/s 0.7560089230537415 v/s 0.8147200932474357\n",
            "Batch 3830 of 6492. Elapsed 0:31:52\n",
            "Sample: 0.7973539233207703 v/s 0.7813115119934082 v/s 0.820150561561151\n",
            "Batch 3840 of 6492. Elapsed 0:31:57\n",
            "Sample: 0.8682600855827332 v/s 0.8972505927085876 v/s 0.921249260629201\n",
            "Batch 3850 of 6492. Elapsed 0:32:01\n",
            "Sample: 0.8833509683609009 v/s 0.9405476450920105 v/s 0.9550351116635901\n",
            "Batch 3860 of 6492. Elapsed 0:32:06\n",
            "Sample: 0.7376551032066345 v/s 0.8241464495658875 v/s 0.8529438131854631\n",
            "Batch 3870 of 6492. Elapsed 0:32:11\n",
            "Sample: 0.7563785910606384 v/s 0.7443207502365112 v/s 0.7864266805036888\n",
            "Batch 3880 of 6492. Elapsed 0:32:16\n",
            "Sample: 0.7792899012565613 v/s 0.7916481494903564 v/s 0.8404989702578304\n",
            "Batch 3890 of 6492. Elapsed 0:32:21\n",
            "Sample: 0.8353928923606873 v/s 0.7992556691169739 v/s 0.865002511997139\n",
            "Batch 3900 of 6492. Elapsed 0:32:26\n",
            "Sample: 0.756687581539154 v/s 0.7670114636421204 v/s 0.8254528107438434\n",
            "Batch 3910 of 6492. Elapsed 0:32:31\n",
            "Sample: 0.7233808636665344 v/s 0.7813475131988525 v/s 0.83237000663611\n",
            "Batch 3920 of 6492. Elapsed 0:32:36\n",
            "Sample: 0.7078053951263428 v/s 0.6903441548347473 v/s 0.7632398139532505\n",
            "Batch 3930 of 6492. Elapsed 0:32:41\n",
            "Sample: 0.8805893659591675 v/s 0.8914169073104858 v/s 0.9220734755421238\n",
            "Batch 3940 of 6492. Elapsed 0:32:46\n",
            "Sample: 0.8792068958282471 v/s 0.9452711939811707 v/s 0.9698395289658494\n",
            "Batch 3950 of 6492. Elapsed 0:32:51\n",
            "Sample: 0.8130091428756714 v/s 0.8032569289207458 v/s 0.8732841607286405\n",
            "Batch 3960 of 6492. Elapsed 0:32:54\n",
            "Sample: 0.8607991337776184 v/s 0.8046239614486694 v/s 0.8627239164618916\n",
            "Batch 3970 of 6492. Elapsed 0:32:59\n",
            "Sample: 0.8273986577987671 v/s 0.806756317615509 v/s 0.830666408233506\n",
            "Batch 3980 of 6492. Elapsed 0:33:04\n",
            "Sample: 0.8268414735794067 v/s 0.8108496069908142 v/s 0.8839366295054725\n",
            "Batch 3990 of 6492. Elapsed 0:33:09\n",
            "Sample: 0.7833127975463867 v/s 0.8171100616455078 v/s 0.858149873384414\n",
            "Batch 4000 of 6492. Elapsed 0:33:14\n",
            "Sample: 0.6584832668304443 v/s 0.639517605304718 v/s 0.6918197057192149\n",
            "Batch 4010 of 6492. Elapsed 0:33:18\n",
            "Sample: 0.7957267761230469 v/s 0.8290606141090393 v/s 0.8531012340706139\n",
            "Batch 4020 of 6492. Elapsed 0:33:23\n",
            "Sample: 0.7700915932655334 v/s 0.7831152081489563 v/s 0.8231037550698899\n",
            "Batch 4030 of 6492. Elapsed 0:33:27\n",
            "Sample: 0.7506980895996094 v/s 0.6999605298042297 v/s 0.7578055351273681\n",
            "Batch 4040 of 6492. Elapsed 0:33:31\n",
            "Sample: 0.7949137687683105 v/s 0.7152925133705139 v/s 0.7850638835543511\n",
            "Batch 4050 of 6492. Elapsed 0:33:36\n",
            "Sample: 0.8638105988502502 v/s 0.8761418461799622 v/s 0.9021490668100407\n",
            "Batch 4060 of 6492. Elapsed 0:33:41\n",
            "Sample: 0.8577967286109924 v/s 0.8376950621604919 v/s 0.8896771380748004\n",
            "Batch 4070 of 6492. Elapsed 0:33:46\n",
            "Sample: 0.8168548345565796 v/s 0.8094329833984375 v/s 0.8390755051693138\n",
            "Batch 4080 of 6492. Elapsed 0:33:51\n",
            "Sample: 0.8310633301734924 v/s 0.8391192555427551 v/s 0.8703891601936595\n",
            "Batch 4090 of 6492. Elapsed 0:33:56\n",
            "Sample: 0.8474641442298889 v/s 0.853440523147583 v/s 0.8973488716496568\n",
            "Batch 4100 of 6492. Elapsed 0:34:01\n",
            "Sample: 0.8050146102905273 v/s 0.810265302658081 v/s 0.8446508571548305\n",
            "Batch 4110 of 6492. Elapsed 0:34:06\n",
            "Sample: 0.7991645336151123 v/s 0.8148566484451294 v/s 0.8396140261789263\n",
            "Batch 4120 of 6492. Elapsed 0:34:11\n",
            "Sample: 0.8035292029380798 v/s 0.7876977920532227 v/s 0.8131353250793015\n",
            "Batch 4130 of 6492. Elapsed 0:34:16\n",
            "Sample: 0.7752956748008728 v/s 0.7960435748100281 v/s 0.8523336081118216\n",
            "Batch 4140 of 6492. Elapsed 0:34:21\n",
            "Sample: 0.8630203604698181 v/s 0.8301165103912354 v/s 0.8706224273923783\n",
            "Batch 4150 of 6492. Elapsed 0:34:25\n",
            "Sample: 0.8775395154953003 v/s 0.9261677265167236 v/s 0.9459745463338389\n",
            "Batch 4160 of 6492. Elapsed 0:34:31\n",
            "Sample: 0.7538269758224487 v/s 0.746494472026825 v/s 0.7867003016820279\n",
            "Batch 4170 of 6492. Elapsed 0:34:36\n",
            "Sample: 0.819736897945404 v/s 0.8655675053596497 v/s 0.8851910183800802\n",
            "Batch 4180 of 6492. Elapsed 0:34:41\n",
            "Sample: 0.8470613956451416 v/s 0.8358083367347717 v/s 0.8667511021608781\n",
            "Batch 4190 of 6492. Elapsed 0:34:46\n",
            "Sample: 0.9132536053657532 v/s 0.9058033227920532 v/s 0.9330650785466155\n",
            "Batch 4200 of 6492. Elapsed 0:34:51\n",
            "Sample: 0.8871320486068726 v/s 0.9209613800048828 v/s 0.9446164400110788\n",
            "Batch 4210 of 6492. Elapsed 0:34:55\n",
            "Sample: 0.865017294883728 v/s 0.8597215414047241 v/s 0.8919832841993208\n",
            "Batch 4220 of 6492. Elapsed 0:35:00\n",
            "Sample: 0.8120294809341431 v/s 0.7998390197753906 v/s 0.8255722670287574\n",
            "Batch 4230 of 6492. Elapsed 0:35:05\n",
            "Sample: 0.7672358155250549 v/s 0.7488589286804199 v/s 0.7880026932874025\n",
            "Batch 4240 of 6492. Elapsed 0:35:10\n",
            "Sample: 0.7804364562034607 v/s 0.8442592620849609 v/s 0.880714149449248\n",
            "Batch 4250 of 6492. Elapsed 0:35:15\n",
            "Sample: 0.8014163970947266 v/s 0.7810928821563721 v/s 0.8126183789408743\n",
            "Batch 4260 of 6492. Elapsed 0:35:20\n",
            "Sample: 0.8043445944786072 v/s 0.8492270112037659 v/s 0.878286149823388\n",
            "Batch 4270 of 6492. Elapsed 0:35:25\n",
            "Sample: 0.7279219031333923 v/s 0.7164471745491028 v/s 0.7887777474830714\n",
            "Batch 4280 of 6492. Elapsed 0:35:30\n",
            "Sample: 0.750356137752533 v/s 0.7833736538887024 v/s 0.820866799200119\n",
            "Batch 4290 of 6492. Elapsed 0:35:35\n",
            "Sample: 0.7901901602745056 v/s 0.8539557456970215 v/s 0.8835012853630257\n",
            "Batch 4300 of 6492. Elapsed 0:35:39\n",
            "Sample: 0.8446477055549622 v/s 0.8285378813743591 v/s 0.8652861643334787\n",
            "Batch 4310 of 6492. Elapsed 0:35:44\n",
            "Sample: 0.7851678133010864 v/s 0.7205151915550232 v/s 0.7665994396566672\n",
            "Batch 4320 of 6492. Elapsed 0:35:49\n",
            "Sample: 0.8084446787834167 v/s 0.8111358880996704 v/s 0.8447602105536687\n",
            "Batch 4330 of 6492. Elapsed 0:35:54\n",
            "Sample: 0.8350302577018738 v/s 0.840839684009552 v/s 0.8752701812612456\n",
            "Batch 4340 of 6492. Elapsed 0:35:59\n",
            "Sample: 0.7857643961906433 v/s 0.7535834312438965 v/s 0.7942572437000083\n",
            "Batch 4350 of 6492. Elapsed 0:36:04\n",
            "Sample: 0.7559423446655273 v/s 0.7785447239875793 v/s 0.8429025429999242\n",
            "Batch 4360 of 6492. Elapsed 0:36:09\n",
            "Sample: 0.7970094084739685 v/s 0.849802553653717 v/s 0.8851474457141116\n",
            "Batch 4370 of 6492. Elapsed 0:36:14\n",
            "Sample: 0.803642749786377 v/s 0.7820641994476318 v/s 0.8140834764608109\n",
            "Batch 4380 of 6492. Elapsed 0:36:18\n",
            "Sample: 0.8517571091651917 v/s 0.827572226524353 v/s 0.883284723622508\n",
            "Batch 4390 of 6492. Elapsed 0:36:23\n",
            "Sample: 0.829196035861969 v/s 0.8217462301254272 v/s 0.857457693087862\n",
            "Batch 4400 of 6492. Elapsed 0:36:28\n",
            "Sample: 0.8125118017196655 v/s 0.7827322483062744 v/s 0.8419839018178589\n",
            "Batch 4410 of 6492. Elapsed 0:36:32\n",
            "Sample: 0.7953205704689026 v/s 0.7781341671943665 v/s 0.8137149028877572\n",
            "Batch 4420 of 6492. Elapsed 0:36:37\n",
            "Sample: 0.7656011581420898 v/s 0.6689828634262085 v/s 0.7569626707158901\n",
            "Batch 4430 of 6492. Elapsed 0:36:42\n",
            "Sample: 0.8303266763687134 v/s 0.8885798454284668 v/s 0.9128998627460614\n",
            "Batch 4440 of 6492. Elapsed 0:36:47\n",
            "Sample: 0.8678096532821655 v/s 0.8156500458717346 v/s 0.8506386025082239\n",
            "Batch 4450 of 6492. Elapsed 0:36:52\n",
            "Sample: 0.8352428674697876 v/s 0.7937737107276917 v/s 0.8191309630170118\n",
            "Batch 4460 of 6492. Elapsed 0:36:57\n",
            "Sample: 0.8272114396095276 v/s 0.8071720004081726 v/s 0.8578109934283981\n",
            "Batch 4470 of 6492. Elapsed 0:37:02\n",
            "Sample: 0.8079004883766174 v/s 0.7535706758499146 v/s 0.8283743106469624\n",
            "Batch 4480 of 6492. Elapsed 0:37:07\n",
            "Sample: 0.7634171843528748 v/s 0.7778429985046387 v/s 0.8199067297930179\n",
            "Batch 4490 of 6492. Elapsed 0:37:11\n",
            "Sample: 0.883882999420166 v/s 0.8910531997680664 v/s 0.9241290037965731\n",
            "Batch 4500 of 6492. Elapsed 0:37:16\n",
            "Sample: 0.7842617034912109 v/s 0.7997552156448364 v/s 0.8541542968181253\n",
            "Batch 4510 of 6492. Elapsed 0:37:20\n",
            "Sample: 0.7673960328102112 v/s 0.7376829385757446 v/s 0.8096722759834726\n",
            "Batch 4520 of 6492. Elapsed 0:37:25\n",
            "Sample: 0.7155036926269531 v/s 0.7159417867660522 v/s 0.7856520460789791\n",
            "Batch 4530 of 6492. Elapsed 0:37:30\n",
            "Sample: 0.8089761137962341 v/s 0.8068263530731201 v/s 0.8618471281706253\n",
            "Batch 4540 of 6492. Elapsed 0:37:36\n",
            "Sample: 0.8519101142883301 v/s 0.7996906638145447 v/s 0.8410344846269814\n",
            "Batch 4550 of 6492. Elapsed 0:37:40\n",
            "Sample: 0.8179218173027039 v/s 0.8114022016525269 v/s 0.8625127182728171\n",
            "Batch 4560 of 6492. Elapsed 0:37:45\n",
            "Sample: 0.8196687698364258 v/s 0.8526514172554016 v/s 0.8985591616043985\n",
            "Batch 4570 of 6492. Elapsed 0:37:51\n",
            "Sample: 0.8179304599761963 v/s 0.85017991065979 v/s 0.8751370384619773\n",
            "Batch 4580 of 6492. Elapsed 0:37:56\n",
            "Sample: 0.8639876246452332 v/s 0.8452405333518982 v/s 0.875458629891695\n",
            "Batch 4590 of 6492. Elapsed 0:38:01\n",
            "Sample: 0.8431326150894165 v/s 0.8446636199951172 v/s 0.8841676307385248\n",
            "Batch 4600 of 6492. Elapsed 0:38:05\n",
            "Sample: 0.8557634353637695 v/s 0.8244000673294067 v/s 0.8692436704836661\n",
            "Batch 4610 of 6492. Elapsed 0:38:10\n",
            "Sample: 0.8059601187705994 v/s 0.8242948651313782 v/s 0.863247525016842\n",
            "Batch 4620 of 6492. Elapsed 0:38:16\n",
            "Sample: 0.8019723296165466 v/s 0.8212552666664124 v/s 0.8708362276123519\n",
            "Batch 4630 of 6492. Elapsed 0:38:21\n",
            "Sample: 0.7987838983535767 v/s 0.8207840919494629 v/s 0.8820242196798033\n",
            "Batch 4640 of 6492. Elapsed 0:38:26\n",
            "Sample: 0.8205695748329163 v/s 0.7764217853546143 v/s 0.8463389235634787\n",
            "Batch 4650 of 6492. Elapsed 0:38:29\n",
            "Sample: 0.8344441652297974 v/s 0.8116792440414429 v/s 0.8418771834236002\n",
            "Batch 4660 of 6492. Elapsed 0:38:34\n",
            "Sample: 0.8097748160362244 v/s 0.8201519846916199 v/s 0.8636642474847088\n",
            "Batch 4670 of 6492. Elapsed 0:38:38\n",
            "Sample: 0.7964990139007568 v/s 0.7531819939613342 v/s 0.8194937691384903\n",
            "Batch 4680 of 6492. Elapsed 0:38:43\n",
            "Sample: 0.8075097799301147 v/s 0.8546140193939209 v/s 0.885094402412817\n",
            "Batch 4690 of 6492. Elapsed 0:38:48\n",
            "Sample: 0.790574312210083 v/s 0.7842606902122498 v/s 0.843299435509999\n",
            "Batch 4700 of 6492. Elapsed 0:38:53\n",
            "Sample: 0.7112464308738708 v/s 0.7430943250656128 v/s 0.7943203413039\n",
            "Batch 4710 of 6492. Elapsed 0:38:58\n",
            "Sample: 0.8257167935371399 v/s 0.7667638063430786 v/s 0.7917014084239558\n",
            "Batch 4720 of 6492. Elapsed 0:39:03\n",
            "Sample: 0.8114497661590576 v/s 0.7877905964851379 v/s 0.850751572928718\n",
            "Batch 4730 of 6492. Elapsed 0:39:08\n",
            "Sample: 0.8066630363464355 v/s 0.7575187683105469 v/s 0.8299238583914421\n",
            "Batch 4740 of 6492. Elapsed 0:39:13\n",
            "Sample: 0.810146152973175 v/s 0.7820385098457336 v/s 0.8582422510479526\n",
            "Batch 4750 of 6492. Elapsed 0:39:18\n",
            "Sample: 0.7573196887969971 v/s 0.7449930310249329 v/s 0.8385399740317391\n",
            "Batch 4760 of 6492. Elapsed 0:39:23\n",
            "Sample: 0.8235863447189331 v/s 0.8384259939193726 v/s 0.8724367719161654\n",
            "Batch 4770 of 6492. Elapsed 0:39:28\n",
            "Sample: 0.763766348361969 v/s 0.7857173085212708 v/s 0.8290516046222762\n",
            "Batch 4780 of 6492. Elapsed 0:39:33\n",
            "Sample: 0.7748692035675049 v/s 0.7642950415611267 v/s 0.8002837979148439\n",
            "Batch 4790 of 6492. Elapsed 0:39:37\n",
            "Sample: 0.8385355472564697 v/s 0.8576826453208923 v/s 0.8875834251945529\n",
            "Batch 4800 of 6492. Elapsed 0:39:41\n",
            "Sample: 0.6928586959838867 v/s 0.686161994934082 v/s 0.7725766217043831\n",
            "Batch 4810 of 6492. Elapsed 0:39:46\n",
            "Sample: 0.8366424441337585 v/s 0.8042073845863342 v/s 0.834661806850539\n",
            "Batch 4820 of 6492. Elapsed 0:39:51\n",
            "Sample: 0.8006109595298767 v/s 0.8155924081802368 v/s 0.8671425758770261\n",
            "Batch 4830 of 6492. Elapsed 0:39:56\n",
            "Sample: 0.7356542944908142 v/s 0.675489604473114 v/s 0.7474414725336959\n",
            "Batch 4840 of 6492. Elapsed 0:40:01\n",
            "Sample: 0.9068319201469421 v/s 0.9480553269386292 v/s 0.9586851674378368\n",
            "Batch 4850 of 6492. Elapsed 0:40:05\n",
            "Sample: 0.8961792588233948 v/s 0.9536826014518738 v/s 0.9588152184141184\n",
            "Batch 4860 of 6492. Elapsed 0:40:10\n",
            "Sample: 0.7926287651062012 v/s 0.7082149386405945 v/s 0.7562535754210734\n",
            "Batch 4870 of 6492. Elapsed 0:40:15\n",
            "Sample: 0.8700589537620544 v/s 0.9037607908248901 v/s 0.914951034806073\n",
            "Batch 4880 of 6492. Elapsed 0:40:20\n",
            "Sample: 0.8582999110221863 v/s 0.877635657787323 v/s 0.9098727296384618\n",
            "Batch 4890 of 6492. Elapsed 0:40:23\n",
            "Sample: 0.8119361996650696 v/s 0.8694800734519958 v/s 0.8854845491371849\n",
            "Batch 4900 of 6492. Elapsed 0:40:28\n",
            "Sample: 0.7137206792831421 v/s 0.6715999245643616 v/s 0.7427811687096663\n",
            "Batch 4910 of 6492. Elapsed 0:40:33\n",
            "Sample: 0.8086153268814087 v/s 0.8180927038192749 v/s 0.8503909067205264\n",
            "Batch 4920 of 6492. Elapsed 0:40:38\n",
            "Sample: 0.8458373546600342 v/s 0.8433830738067627 v/s 0.876058309886453\n",
            "Batch 4930 of 6492. Elapsed 0:40:43\n",
            "Sample: 0.7784066200256348 v/s 0.7958346605300903 v/s 0.8360125523468408\n",
            "Batch 4940 of 6492. Elapsed 0:40:48\n",
            "Sample: 0.7767935991287231 v/s 0.7958893775939941 v/s 0.8202719017162999\n",
            "Batch 4950 of 6492. Elapsed 0:40:53\n",
            "Sample: 0.8590921759605408 v/s 0.871511697769165 v/s 0.8947012038758865\n",
            "Batch 4960 of 6492. Elapsed 0:40:58\n",
            "Sample: 0.759219765663147 v/s 0.7348628640174866 v/s 0.8049399353261313\n",
            "Batch 4970 of 6492. Elapsed 0:41:02\n",
            "Sample: 0.8369324803352356 v/s 0.8538739681243896 v/s 0.8914554605212397\n",
            "Batch 4980 of 6492. Elapsed 0:41:06\n",
            "Sample: 0.8227663636207581 v/s 0.8804029822349548 v/s 0.9207353555079505\n",
            "Batch 4990 of 6492. Elapsed 0:41:11\n",
            "Sample: 0.7904805541038513 v/s 0.7868249416351318 v/s 0.8431323905708259\n",
            "Batch 5000 of 6492. Elapsed 0:41:15\n",
            "Sample: 0.8141958713531494 v/s 0.856497585773468 v/s 0.9030761403181768\n",
            "Batch 5010 of 6492. Elapsed 0:41:20\n",
            "Sample: 0.8104498982429504 v/s 0.7714768052101135 v/s 0.8458220981805393\n",
            "Batch 5020 of 6492. Elapsed 0:41:25\n",
            "Sample: 0.8253385424613953 v/s 0.8363620638847351 v/s 0.8758705633388696\n",
            "Batch 5030 of 6492. Elapsed 0:41:30\n",
            "Sample: 0.8265200853347778 v/s 0.8782082200050354 v/s 0.91220645203455\n",
            "Batch 5040 of 6492. Elapsed 0:41:34\n",
            "Sample: 0.8501707315444946 v/s 0.7608200311660767 v/s 0.8309354371449874\n",
            "Batch 5050 of 6492. Elapsed 0:41:39\n",
            "Sample: 0.766118049621582 v/s 0.6656917333602905 v/s 0.7165795318463867\n",
            "Batch 5060 of 6492. Elapsed 0:41:44\n",
            "Sample: 0.8322443962097168 v/s 0.8851886987686157 v/s 0.9172977419099826\n",
            "Batch 5070 of 6492. Elapsed 0:41:48\n",
            "Sample: 0.8565678596496582 v/s 0.810592532157898 v/s 0.8722915562039838\n",
            "Batch 5080 of 6492. Elapsed 0:41:53\n",
            "Sample: 0.8592470288276672 v/s 0.8951130509376526 v/s 0.9193156015222617\n",
            "Batch 5090 of 6492. Elapsed 0:41:57\n",
            "Sample: 0.7114192247390747 v/s 0.689440906047821 v/s 0.7494750949643469\n",
            "Batch 5100 of 6492. Elapsed 0:42:03\n",
            "Sample: 0.8164536356925964 v/s 0.770187497138977 v/s 0.8439887996840707\n",
            "Batch 5110 of 6492. Elapsed 0:42:07\n",
            "Sample: 0.8904966711997986 v/s 0.8806854486465454 v/s 0.9154367358276058\n",
            "Batch 5120 of 6492. Elapsed 0:42:12\n",
            "Sample: 0.8316307663917542 v/s 0.8272354006767273 v/s 0.8699312896683764\n",
            "Batch 5130 of 6492. Elapsed 0:42:17\n",
            "Sample: 0.7874898314476013 v/s 0.86214280128479 v/s 0.8893711533708013\n",
            "Batch 5140 of 6492. Elapsed 0:42:22\n",
            "Sample: 0.7195613980293274 v/s 0.7754588723182678 v/s 0.8128745439606442\n",
            "Batch 5150 of 6492. Elapsed 0:42:27\n",
            "Sample: 0.8600910902023315 v/s 0.8523370623588562 v/s 0.8781857642538564\n",
            "Batch 5160 of 6492. Elapsed 0:42:33\n",
            "Sample: 0.8520865440368652 v/s 0.8906131982803345 v/s 0.9197968010819385\n",
            "Batch 5170 of 6492. Elapsed 0:42:37\n",
            "Sample: 0.7722671031951904 v/s 0.763924777507782 v/s 0.8293498253493667\n",
            "Batch 5180 of 6492. Elapsed 0:42:42\n",
            "Sample: 0.8048906922340393 v/s 0.7722468376159668 v/s 0.8217351134415625\n",
            "Batch 5190 of 6492. Elapsed 0:42:45\n",
            "Sample: 0.8116694688796997 v/s 0.7865339517593384 v/s 0.8431235606320596\n",
            "Batch 5200 of 6492. Elapsed 0:42:50\n",
            "Sample: 0.8107621073722839 v/s 0.7671281099319458 v/s 0.8415433046872681\n",
            "Batch 5210 of 6492. Elapsed 0:42:55\n",
            "Sample: 0.7244234681129456 v/s 0.7616133093833923 v/s 0.8031794498976184\n",
            "Batch 5220 of 6492. Elapsed 0:43:00\n",
            "Sample: 0.7743161916732788 v/s 0.8500739336013794 v/s 0.873704619389231\n",
            "Batch 5230 of 6492. Elapsed 0:43:04\n",
            "Sample: 0.8812070488929749 v/s 0.8446996808052063 v/s 0.8685541745235994\n",
            "Batch 5240 of 6492. Elapsed 0:43:09\n",
            "Sample: 0.7350601553916931 v/s 0.7016872763633728 v/s 0.7687864299184387\n",
            "Batch 5250 of 6492. Elapsed 0:43:13\n",
            "Sample: 0.8035224676132202 v/s 0.8017091155052185 v/s 0.8538735165843662\n",
            "Batch 5260 of 6492. Elapsed 0:43:18\n",
            "Sample: 0.8179734945297241 v/s 0.7689114809036255 v/s 0.8214925785905212\n",
            "Batch 5270 of 6492. Elapsed 0:43:23\n",
            "Sample: 0.8624769449234009 v/s 0.8681227564811707 v/s 0.9125136982336723\n",
            "Batch 5280 of 6492. Elapsed 0:43:28\n",
            "Sample: 0.8022273182868958 v/s 0.8769643902778625 v/s 0.8871536417709667\n",
            "Batch 5290 of 6492. Elapsed 0:43:33\n",
            "Sample: 0.7512249946594238 v/s 0.7055433988571167 v/s 0.7854758373675316\n",
            "Batch 5300 of 6492. Elapsed 0:43:38\n",
            "Sample: 0.6957184076309204 v/s 0.6874939799308777 v/s 0.7396987940363952\n",
            "Batch 5310 of 6492. Elapsed 0:43:43\n",
            "Sample: 0.8656525611877441 v/s 0.8937594890594482 v/s 0.905489353000528\n",
            "Batch 5320 of 6492. Elapsed 0:43:48\n",
            "Sample: 0.7104575634002686 v/s 0.6749776005744934 v/s 0.7326399946420998\n",
            "Batch 5330 of 6492. Elapsed 0:43:52\n",
            "Sample: 0.7894279360771179 v/s 0.7840977907180786 v/s 0.8225234869767629\n",
            "Batch 5340 of 6492. Elapsed 0:43:57\n",
            "Sample: 0.8473811149597168 v/s 0.873474657535553 v/s 0.9020941612113346\n",
            "Batch 5350 of 6492. Elapsed 0:44:02\n",
            "Sample: 0.8586222529411316 v/s 0.9486204981803894 v/s 0.9606911760493075\n",
            "Batch 5360 of 6492. Elapsed 0:44:06\n",
            "Sample: 0.8482791781425476 v/s 0.8210839033126831 v/s 0.8668113655799115\n",
            "Batch 5370 of 6492. Elapsed 0:44:11\n",
            "Sample: 0.8032937049865723 v/s 0.7148340344429016 v/s 0.8082478564900117\n",
            "Batch 5380 of 6492. Elapsed 0:44:16\n",
            "Sample: 0.8267168402671814 v/s 0.7854229211807251 v/s 0.8472924133660155\n",
            "Batch 5390 of 6492. Elapsed 0:44:21\n",
            "Sample: 0.7427764534950256 v/s 0.6873831152915955 v/s 0.7235760263521916\n",
            "Batch 5400 of 6492. Elapsed 0:44:27\n",
            "Sample: 0.7891443967819214 v/s 0.7237358689308167 v/s 0.7946109360812209\n",
            "Batch 5410 of 6492. Elapsed 0:44:32\n",
            "Sample: 0.8518004417419434 v/s 0.9527459740638733 v/s 0.971827400497672\n",
            "Batch 5420 of 6492. Elapsed 0:44:36\n",
            "Sample: 0.7543125748634338 v/s 0.7480705976486206 v/s 0.8410808011164738\n",
            "Batch 5430 of 6492. Elapsed 0:44:41\n",
            "Sample: 0.733022928237915 v/s 0.7454156279563904 v/s 0.7942781103626527\n",
            "Batch 5440 of 6492. Elapsed 0:44:46\n",
            "Sample: 0.8523233532905579 v/s 0.8805831670761108 v/s 0.9011751516439158\n",
            "Batch 5450 of 6492. Elapsed 0:44:51\n",
            "Sample: 0.7173546552658081 v/s 0.7074292898178101 v/s 0.7534160906525638\n",
            "Batch 5460 of 6492. Elapsed 0:44:56\n",
            "Sample: 0.804615318775177 v/s 0.8136270046234131 v/s 0.8481717507677823\n",
            "Batch 5470 of 6492. Elapsed 0:45:00\n",
            "Sample: 0.8740606307983398 v/s 0.804490864276886 v/s 0.8916769571412708\n",
            "Batch 5480 of 6492. Elapsed 0:45:05\n",
            "Sample: 0.7044166922569275 v/s 0.6953662633895874 v/s 0.7432523603572516\n",
            "Batch 5490 of 6492. Elapsed 0:45:10\n",
            "Sample: 0.7914479970932007 v/s 0.8294336795806885 v/s 0.8657757637271004\n",
            "Batch 5500 of 6492. Elapsed 0:45:15\n",
            "Sample: 0.7435185313224792 v/s 0.7207354307174683 v/s 0.7707803988923353\n",
            "Batch 5510 of 6492. Elapsed 0:45:20\n",
            "Sample: 0.7533783316612244 v/s 0.7272000312805176 v/s 0.7827048119670145\n",
            "Batch 5520 of 6492. Elapsed 0:45:24\n",
            "Sample: 0.9443082809448242 v/s 0.9498088359832764 v/s 0.9640348947534562\n",
            "Batch 5530 of 6492. Elapsed 0:45:29\n",
            "Sample: 0.8201589584350586 v/s 0.790727436542511 v/s 0.8448106743303404\n",
            "Batch 5540 of 6492. Elapsed 0:45:33\n",
            "Sample: 0.7530956864356995 v/s 0.7121928334236145 v/s 0.8050092791883368\n",
            "Batch 5550 of 6492. Elapsed 0:45:38\n",
            "Sample: 0.8394961953163147 v/s 0.814523458480835 v/s 0.8629961833043392\n",
            "Batch 5560 of 6492. Elapsed 0:45:43\n",
            "Sample: 0.7737515568733215 v/s 0.7785401344299316 v/s 0.8208696081195046\n",
            "Batch 5570 of 6492. Elapsed 0:45:48\n",
            "Sample: 0.7982277870178223 v/s 0.77354496717453 v/s 0.8303898226729726\n",
            "Batch 5580 of 6492. Elapsed 0:45:53\n",
            "Sample: 0.8766868710517883 v/s 0.8470261693000793 v/s 0.8964473458301109\n",
            "Batch 5590 of 6492. Elapsed 0:45:58\n",
            "Sample: 0.8269895911216736 v/s 0.7879696488380432 v/s 0.8430441492243862\n",
            "Batch 5600 of 6492. Elapsed 0:46:04\n",
            "Sample: 0.7805706262588501 v/s 0.8203989267349243 v/s 0.8649758796027223\n",
            "Batch 5610 of 6492. Elapsed 0:46:09\n",
            "Sample: 0.8388829231262207 v/s 0.7938556671142578 v/s 0.8425085527337408\n",
            "Batch 5620 of 6492. Elapsed 0:46:14\n",
            "Sample: 0.8079386949539185 v/s 0.8181344866752625 v/s 0.8521589183725611\n",
            "Batch 5630 of 6492. Elapsed 0:46:18\n",
            "Sample: 0.7924886345863342 v/s 0.7338066697120667 v/s 0.7905391102456049\n",
            "Batch 5640 of 6492. Elapsed 0:46:23\n",
            "Sample: 0.7568399310112 v/s 0.793925940990448 v/s 0.8272084485352255\n",
            "Batch 5650 of 6492. Elapsed 0:46:28\n",
            "Sample: 0.7898474931716919 v/s 0.7799800038337708 v/s 0.8453414772542733\n",
            "Batch 5660 of 6492. Elapsed 0:46:32\n",
            "Sample: 0.7094276547431946 v/s 0.7387730479240417 v/s 0.8108589540366302\n",
            "Batch 5670 of 6492. Elapsed 0:46:37\n",
            "Sample: 0.8312435150146484 v/s 0.8557358384132385 v/s 0.8967401023403552\n",
            "Batch 5680 of 6492. Elapsed 0:46:41\n",
            "Sample: 0.8824328780174255 v/s 0.8518220782279968 v/s 0.8904919237652668\n",
            "Batch 5690 of 6492. Elapsed 0:46:46\n",
            "Sample: 0.8338300585746765 v/s 0.8649787306785583 v/s 0.8895642811998037\n",
            "Batch 5700 of 6492. Elapsed 0:46:51\n",
            "Sample: 0.6872519850730896 v/s 0.671406626701355 v/s 0.7491425133095143\n",
            "Batch 5710 of 6492. Elapsed 0:46:55\n",
            "Sample: 0.7482925653457642 v/s 0.7287497520446777 v/s 0.7830462725140951\n",
            "Batch 5720 of 6492. Elapsed 0:47:01\n",
            "Sample: 0.8464723825454712 v/s 0.816458523273468 v/s 0.8608598418158884\n",
            "Batch 5730 of 6492. Elapsed 0:47:05\n",
            "Sample: 0.8220316171646118 v/s 0.8061882853507996 v/s 0.8311472302357551\n",
            "Batch 5740 of 6492. Elapsed 0:47:10\n",
            "Sample: 0.8762590885162354 v/s 0.8714686036109924 v/s 0.8924966661819347\n",
            "Batch 5750 of 6492. Elapsed 0:47:15\n",
            "Sample: 0.8190799355506897 v/s 0.808402419090271 v/s 0.8573034488674459\n",
            "Batch 5760 of 6492. Elapsed 0:47:20\n",
            "Sample: 0.7900548577308655 v/s 0.7708104252815247 v/s 0.8424142391333024\n",
            "Batch 5770 of 6492. Elapsed 0:47:24\n",
            "Sample: 0.8017990589141846 v/s 0.7976272106170654 v/s 0.8436988510696118\n",
            "Batch 5780 of 6492. Elapsed 0:47:29\n",
            "Sample: 0.7760925889015198 v/s 0.7677955627441406 v/s 0.8004067286505424\n",
            "Batch 5790 of 6492. Elapsed 0:47:34\n",
            "Sample: 0.8121808171272278 v/s 0.7719282507896423 v/s 0.8203499233516311\n",
            "Batch 5800 of 6492. Elapsed 0:47:39\n",
            "Sample: 0.7494993209838867 v/s 0.7489190101623535 v/s 0.8123821315038454\n",
            "Batch 5810 of 6492. Elapsed 0:47:44\n",
            "Sample: 0.8364917635917664 v/s 0.8388692736625671 v/s 0.8682489119230664\n",
            "Batch 5820 of 6492. Elapsed 0:47:48\n",
            "Sample: 0.7592208385467529 v/s 0.7833800315856934 v/s 0.8168137776870532\n",
            "Batch 5830 of 6492. Elapsed 0:47:53\n",
            "Sample: 0.8146650791168213 v/s 0.8387467861175537 v/s 0.8896177655604599\n",
            "Batch 5840 of 6492. Elapsed 0:47:58\n",
            "Sample: 0.8487721085548401 v/s 0.8451139330863953 v/s 0.8783884703195693\n",
            "Batch 5850 of 6492. Elapsed 0:48:03\n",
            "Sample: 0.8391282558441162 v/s 0.9105355143547058 v/s 0.9239922565322949\n",
            "Batch 5860 of 6492. Elapsed 0:48:08\n",
            "Sample: 0.7920508980751038 v/s 0.8308122158050537 v/s 0.8777147893012203\n",
            "Batch 5870 of 6492. Elapsed 0:48:13\n",
            "Sample: 0.7976051568984985 v/s 0.7507390975952148 v/s 0.792794300891503\n",
            "Batch 5880 of 6492. Elapsed 0:48:17\n",
            "Sample: 0.8399880528450012 v/s 0.8491942882537842 v/s 0.8630349441700231\n",
            "Batch 5890 of 6492. Elapsed 0:48:22\n",
            "Sample: 0.7923744320869446 v/s 0.7712056040763855 v/s 0.8136509752864235\n",
            "Batch 5900 of 6492. Elapsed 0:48:26\n",
            "Sample: 0.6611102223396301 v/s 0.6349583864212036 v/s 0.7018903622601983\n",
            "Batch 5910 of 6492. Elapsed 0:48:31\n",
            "Sample: 0.7167651057243347 v/s 0.6810873746871948 v/s 0.7695418594447536\n",
            "Batch 5920 of 6492. Elapsed 0:48:36\n",
            "Sample: 0.8302883505821228 v/s 0.8535932302474976 v/s 0.901775008624602\n",
            "Batch 5930 of 6492. Elapsed 0:48:42\n",
            "Sample: 0.8472944498062134 v/s 0.9463120698928833 v/s 0.9535373247589597\n",
            "Batch 5940 of 6492. Elapsed 0:48:46\n",
            "Sample: 0.9016591310501099 v/s 0.8855951428413391 v/s 0.9107079992542375\n",
            "Batch 5950 of 6492. Elapsed 0:48:51\n",
            "Sample: 0.7374241948127747 v/s 0.716574490070343 v/s 0.7645361516948297\n",
            "Batch 5960 of 6492. Elapsed 0:48:56\n",
            "Sample: 0.7616265416145325 v/s 0.7391769886016846 v/s 0.8046995564975616\n",
            "Batch 5970 of 6492. Elapsed 0:49:01\n",
            "Sample: 0.9027641415596008 v/s 0.9341282844543457 v/s 0.9496262337617694\n",
            "Batch 5980 of 6492. Elapsed 0:49:06\n",
            "Sample: 0.8262320756912231 v/s 0.8627175092697144 v/s 0.8798517418117214\n",
            "Batch 5990 of 6492. Elapsed 0:49:11\n",
            "Sample: 0.7715502977371216 v/s 0.7236312031745911 v/s 0.7737301279909182\n",
            "Batch 6000 of 6492. Elapsed 0:49:16\n",
            "Sample: 0.8345872163772583 v/s 0.7984204292297363 v/s 0.8425035415620549\n",
            "Batch 6010 of 6492. Elapsed 0:49:20\n",
            "Sample: 0.8308342695236206 v/s 0.8008715510368347 v/s 0.828956025389462\n",
            "Batch 6020 of 6492. Elapsed 0:49:25\n",
            "Sample: 0.7275740504264832 v/s 0.7046462893486023 v/s 0.8046143039441682\n",
            "Batch 6030 of 6492. Elapsed 0:49:30\n",
            "Sample: 0.868865966796875 v/s 0.9315196871757507 v/s 0.9524179678876946\n",
            "Batch 6040 of 6492. Elapsed 0:49:35\n",
            "Sample: 0.7991374135017395 v/s 0.8118886351585388 v/s 0.868089846148053\n",
            "Batch 6050 of 6492. Elapsed 0:49:39\n",
            "Sample: 0.8124103546142578 v/s 0.8713156580924988 v/s 0.8940805196923544\n",
            "Batch 6060 of 6492. Elapsed 0:49:45\n",
            "Sample: 0.8111048936843872 v/s 0.8003274202346802 v/s 0.8443634175399977\n",
            "Batch 6070 of 6492. Elapsed 0:49:50\n",
            "Sample: 0.8622947931289673 v/s 0.8345374464988708 v/s 0.8883169387225107\n",
            "Batch 6080 of 6492. Elapsed 0:49:55\n",
            "Sample: 0.8103262782096863 v/s 0.850837767124176 v/s 0.8850307648186968\n",
            "Batch 6090 of 6492. Elapsed 0:50:00\n",
            "Sample: 0.830406904220581 v/s 0.7980633974075317 v/s 0.8591940899793548\n",
            "Batch 6100 of 6492. Elapsed 0:50:05\n",
            "Sample: 0.807580828666687 v/s 0.7631982564926147 v/s 0.8501815555156\n",
            "Batch 6110 of 6492. Elapsed 0:50:10\n",
            "Sample: 0.7760064601898193 v/s 0.7897914052009583 v/s 0.8327886632401909\n",
            "Batch 6120 of 6492. Elapsed 0:50:15\n",
            "Sample: 0.8082931637763977 v/s 0.8428396582603455 v/s 0.8969944938381568\n",
            "Batch 6130 of 6492. Elapsed 0:50:20\n",
            "Sample: 0.828268826007843 v/s 0.8103331923484802 v/s 0.8598630782669631\n",
            "Batch 6140 of 6492. Elapsed 0:50:25\n",
            "Sample: 0.6993303894996643 v/s 0.7329409718513489 v/s 0.798787244548959\n",
            "Batch 6150 of 6492. Elapsed 0:50:29\n",
            "Sample: 0.8174369931221008 v/s 0.860394299030304 v/s 0.8889126509982896\n",
            "Batch 6160 of 6492. Elapsed 0:50:34\n",
            "Sample: 0.7354210615158081 v/s 0.7394734621047974 v/s 0.7891707045231157\n",
            "Batch 6170 of 6492. Elapsed 0:50:39\n",
            "Sample: 0.7407494187355042 v/s 0.6573631167411804 v/s 0.7274737713624155\n",
            "Batch 6180 of 6492. Elapsed 0:50:44\n",
            "Sample: 0.7696897983551025 v/s 0.7500669360160828 v/s 0.8100623962686232\n",
            "Batch 6190 of 6492. Elapsed 0:50:49\n",
            "Sample: 0.7519425749778748 v/s 0.7841442823410034 v/s 0.8334324224218668\n",
            "Batch 6200 of 6492. Elapsed 0:50:53\n",
            "Sample: 0.6682023406028748 v/s 0.6816783547401428 v/s 0.7590734546702266\n",
            "Batch 6210 of 6492. Elapsed 0:50:58\n",
            "Sample: 0.6865963935852051 v/s 0.7199671268463135 v/s 0.7923196800301225\n",
            "Batch 6220 of 6492. Elapsed 0:51:03\n",
            "Sample: 0.8609960675239563 v/s 0.8644821643829346 v/s 0.8846015026948342\n",
            "Batch 6230 of 6492. Elapsed 0:51:08\n",
            "Sample: 0.7991966009140015 v/s 0.7598685026168823 v/s 0.8262195291808643\n",
            "Batch 6240 of 6492. Elapsed 0:51:12\n",
            "Sample: 0.802580714225769 v/s 0.7601903080940247 v/s 0.8209193154038024\n",
            "Batch 6250 of 6492. Elapsed 0:51:17\n",
            "Sample: 0.7936350107192993 v/s 0.864141583442688 v/s 0.9088178687137304\n",
            "Batch 6260 of 6492. Elapsed 0:51:22\n",
            "Sample: 0.8907381892204285 v/s 0.8518680334091187 v/s 0.9002743602523312\n",
            "Batch 6270 of 6492. Elapsed 0:51:27\n",
            "Sample: 0.810660183429718 v/s 0.7865447402000427 v/s 0.8337204752305049\n",
            "Batch 6280 of 6492. Elapsed 0:51:31\n",
            "Sample: 0.8362786173820496 v/s 0.8992907404899597 v/s 0.92789715813636\n",
            "Batch 6290 of 6492. Elapsed 0:51:37\n",
            "Sample: 0.8565094470977783 v/s 0.9077613949775696 v/s 0.9239935172727709\n",
            "Batch 6300 of 6492. Elapsed 0:51:41\n",
            "Sample: 0.7897352576255798 v/s 0.7650080919265747 v/s 0.8097375580102412\n",
            "Batch 6310 of 6492. Elapsed 0:51:47\n",
            "Sample: 0.8863621950149536 v/s 0.8444178700447083 v/s 0.8969728191754622\n",
            "Batch 6320 of 6492. Elapsed 0:51:52\n",
            "Sample: 0.8702924847602844 v/s 0.8609247207641602 v/s 0.9010250276594555\n",
            "Batch 6330 of 6492. Elapsed 0:51:56\n",
            "Sample: 0.7390280365943909 v/s 0.7217734456062317 v/s 0.7833461114401573\n",
            "Batch 6340 of 6492. Elapsed 0:52:01\n",
            "Sample: 0.8755689263343811 v/s 0.9309664964675903 v/s 0.948025308449184\n",
            "Batch 6350 of 6492. Elapsed 0:52:05\n",
            "Sample: 0.7490488290786743 v/s 0.6833862066268921 v/s 0.7760553416437238\n",
            "Batch 6360 of 6492. Elapsed 0:52:11\n",
            "Sample: 0.8711511492729187 v/s 0.9416429400444031 v/s 0.9596372946213102\n",
            "Batch 6370 of 6492. Elapsed 0:52:16\n",
            "Sample: 0.7592307925224304 v/s 0.8173993229866028 v/s 0.8501840124838006\n",
            "Batch 6380 of 6492. Elapsed 0:52:20\n",
            "Sample: 0.7791101336479187 v/s 0.7382040619850159 v/s 0.7819034120044579\n",
            "Batch 6390 of 6492. Elapsed 0:52:25\n",
            "Sample: 0.7823562026023865 v/s 0.719933032989502 v/s 0.8192635669953459\n",
            "Batch 6400 of 6492. Elapsed 0:52:30\n",
            "Sample: 0.8023124933242798 v/s 0.8086823225021362 v/s 0.8318442637518705\n",
            "Batch 6410 of 6492. Elapsed 0:52:35\n",
            "Sample: 0.7594856023788452 v/s 0.7110541462898254 v/s 0.7720557734391927\n",
            "Batch 6420 of 6492. Elapsed 0:52:39\n",
            "Sample: 0.8509122729301453 v/s 0.7789736986160278 v/s 0.8147382803051222\n",
            "Batch 6430 of 6492. Elapsed 0:52:44\n",
            "Sample: 0.7608121037483215 v/s 0.7641525864601135 v/s 0.8366339117630817\n",
            "Batch 6440 of 6492. Elapsed 0:52:49\n",
            "Sample: 0.7941641807556152 v/s 0.8161563873291016 v/s 0.8656513365183209\n",
            "Batch 6450 of 6492. Elapsed 0:52:54\n",
            "Sample: 0.7716037034988403 v/s 0.7476944923400879 v/s 0.7934407159917597\n",
            "Batch 6460 of 6492. Elapsed 0:52:59\n",
            "Sample: 0.8699883818626404 v/s 0.8138002157211304 v/s 0.8677463740698038\n",
            "Batch 6470 of 6492. Elapsed 0:53:04\n",
            "Sample: 0.7547588348388672 v/s 0.7505615949630737 v/s 0.8014873634407556\n",
            "Batch 6480 of 6492. Elapsed 0:53:09\n",
            "Sample: 0.6589663624763489 v/s 0.6867080926895142 v/s 0.7590907567004053\n",
            "Batch 6490 of 6492. Elapsed 0:53:14\n",
            "Average discriminator training loss for epoch 1 : 0.001701052882708609\n",
            "Average True STOI for generated outputs last epoch: 0.8098105192184448\n",
            "Epoch took 0:53:15\n",
            "\n",
            "=============== Discriminator Epoch 2 / 2 =================\n",
            "Sample: 0.847710907459259 v/s 0.8902994990348816 v/s 0.903971384020595\n",
            "Batch 10 of 6492. Elapsed 0:00:03\n",
            "Sample: 0.7104352116584778 v/s 0.7145547270774841 v/s 0.7974035037845042\n",
            "Batch 20 of 6492. Elapsed 0:00:06\n",
            "Sample: 0.7966530323028564 v/s 0.8501741886138916 v/s 0.8732179446026407\n",
            "Batch 30 of 6492. Elapsed 0:00:09\n",
            "Sample: 0.8036261200904846 v/s 0.773361325263977 v/s 0.8213560734920377\n",
            "Batch 40 of 6492. Elapsed 0:00:12\n",
            "Sample: 0.8900195956230164 v/s 0.914674699306488 v/s 0.9431934062983834\n",
            "Batch 50 of 6492. Elapsed 0:00:15\n",
            "Sample: 0.8362115025520325 v/s 0.8211261034011841 v/s 0.8567785081384836\n",
            "Batch 60 of 6492. Elapsed 0:00:18\n",
            "Sample: 0.7827854752540588 v/s 0.8185967803001404 v/s 0.854486689640526\n",
            "Batch 70 of 6492. Elapsed 0:00:21\n",
            "Sample: 0.8171672224998474 v/s 0.7827322483062744 v/s 0.8419839018178589\n",
            "Batch 80 of 6492. Elapsed 0:00:24\n",
            "Sample: 0.7959160208702087 v/s 0.8309983015060425 v/s 0.8574707500736853\n",
            "Batch 90 of 6492. Elapsed 0:00:27\n",
            "Sample: 0.859611988067627 v/s 0.814397931098938 v/s 0.8765129363615541\n",
            "Batch 100 of 6492. Elapsed 0:00:29\n",
            "Sample: 0.827948272228241 v/s 0.8687335252761841 v/s 0.8954538437437068\n",
            "Batch 110 of 6492. Elapsed 0:00:32\n",
            "Sample: 0.7893078923225403 v/s 0.8490080237388611 v/s 0.8782510576270348\n",
            "Batch 120 of 6492. Elapsed 0:00:35\n",
            "Sample: 0.8331796526908875 v/s 0.894542932510376 v/s 0.9167236886555935\n",
            "Batch 130 of 6492. Elapsed 0:00:38\n",
            "Sample: 0.8338283896446228 v/s 0.7756398916244507 v/s 0.8365580743917597\n",
            "Batch 140 of 6492. Elapsed 0:00:41\n",
            "Sample: 0.8174412250518799 v/s 0.8315390348434448 v/s 0.8521033780819984\n",
            "Batch 150 of 6492. Elapsed 0:00:44\n",
            "Sample: 0.8089300394058228 v/s 0.8084676861763 v/s 0.882044170821895\n",
            "Batch 160 of 6492. Elapsed 0:00:47\n",
            "Sample: 0.8101158738136292 v/s 0.8282305002212524 v/s 0.8549089421033716\n",
            "Batch 170 of 6492. Elapsed 0:00:50\n",
            "Sample: 0.8323453068733215 v/s 0.7631670832633972 v/s 0.8289899603286752\n",
            "Batch 180 of 6492. Elapsed 0:00:53\n",
            "Sample: 0.8152369260787964 v/s 0.7864844799041748 v/s 0.8387147679760251\n",
            "Batch 190 of 6492. Elapsed 0:00:56\n",
            "Sample: 0.8097164630889893 v/s 0.8390471339225769 v/s 0.8747823873162619\n",
            "Batch 200 of 6492. Elapsed 0:00:59\n",
            "Sample: 0.8745371699333191 v/s 0.849412202835083 v/s 0.8702718291074122\n",
            "Batch 210 of 6492. Elapsed 0:01:02\n",
            "Sample: 0.8737908601760864 v/s 0.9101504683494568 v/s 0.93379557707873\n",
            "Batch 220 of 6492. Elapsed 0:01:05\n",
            "Sample: 0.7615277171134949 v/s 0.7645330429077148 v/s 0.8040037993071357\n",
            "Batch 230 of 6492. Elapsed 0:01:08\n",
            "Sample: 0.6922719478607178 v/s 0.7033402919769287 v/s 0.7741306946037635\n",
            "Batch 240 of 6492. Elapsed 0:01:11\n",
            "Sample: 0.7487081289291382 v/s 0.7170588374137878 v/s 0.7730629418685098\n",
            "Batch 250 of 6492. Elapsed 0:01:14\n",
            "Sample: 0.8794683218002319 v/s 0.8492349982261658 v/s 0.8640976326709726\n",
            "Batch 260 of 6492. Elapsed 0:01:17\n",
            "Sample: 0.838951587677002 v/s 0.838874876499176 v/s 0.88009154371333\n",
            "Batch 270 of 6492. Elapsed 0:01:20\n",
            "Sample: 0.8081193566322327 v/s 0.7804754376411438 v/s 0.8107759967418117\n",
            "Batch 280 of 6492. Elapsed 0:01:23\n",
            "Sample: 0.7844205498695374 v/s 0.796043336391449 v/s 0.8613046978835066\n",
            "Batch 290 of 6492. Elapsed 0:01:26\n",
            "Sample: 0.7983043193817139 v/s 0.7520458698272705 v/s 0.7870852701936236\n",
            "Batch 300 of 6492. Elapsed 0:01:28\n",
            "Sample: 0.8054413199424744 v/s 0.9378462433815002 v/s 0.9585611801283739\n",
            "Batch 310 of 6492. Elapsed 0:01:31\n",
            "Sample: 0.8231176137924194 v/s 0.9274640083312988 v/s 0.9557383886085237\n",
            "Batch 320 of 6492. Elapsed 0:01:34\n",
            "Sample: 0.7737669348716736 v/s 0.8455674052238464 v/s 0.8705864655868105\n",
            "Batch 330 of 6492. Elapsed 0:01:38\n",
            "Sample: 0.8002136945724487 v/s 0.7913116812705994 v/s 0.83560258824279\n",
            "Batch 340 of 6492. Elapsed 0:01:40\n",
            "Sample: 0.8362535238265991 v/s 0.8829495310783386 v/s 0.9205666830445203\n",
            "Batch 350 of 6492. Elapsed 0:01:43\n",
            "Sample: 0.7755187749862671 v/s 0.8421421647071838 v/s 0.8734952301330395\n",
            "Batch 360 of 6492. Elapsed 0:01:46\n",
            "Sample: 0.836490273475647 v/s 0.821013867855072 v/s 0.8733641855788183\n",
            "Batch 370 of 6492. Elapsed 0:01:49\n",
            "Sample: 0.8066562414169312 v/s 0.7631811499595642 v/s 0.8382697433355266\n",
            "Batch 380 of 6492. Elapsed 0:01:52\n",
            "Sample: 0.8451002836227417 v/s 0.8352897763252258 v/s 0.8752534323458971\n",
            "Batch 390 of 6492. Elapsed 0:01:55\n",
            "Sample: 0.810824453830719 v/s 0.7719282507896423 v/s 0.8203499233516311\n",
            "Batch 400 of 6492. Elapsed 0:01:58\n",
            "Sample: 0.8452942371368408 v/s 0.8422488570213318 v/s 0.8710244258062104\n",
            "Batch 410 of 6492. Elapsed 0:02:01\n",
            "Sample: 0.807618260383606 v/s 0.7966086864471436 v/s 0.843113033255566\n",
            "Batch 420 of 6492. Elapsed 0:02:04\n",
            "Sample: 0.8011065721511841 v/s 0.7682686448097229 v/s 0.8245636536839155\n",
            "Batch 430 of 6492. Elapsed 0:02:07\n",
            "Sample: 0.7965923547744751 v/s 0.7545253038406372 v/s 0.8230359978679258\n",
            "Batch 440 of 6492. Elapsed 0:02:10\n",
            "Sample: 0.833404004573822 v/s 0.8409104347229004 v/s 0.8840032993604147\n",
            "Batch 450 of 6492. Elapsed 0:02:13\n",
            "Sample: 0.8376558423042297 v/s 0.7833123803138733 v/s 0.8466898078110402\n",
            "Batch 460 of 6492. Elapsed 0:02:16\n",
            "Sample: 0.8110256195068359 v/s 0.7580799460411072 v/s 0.8238666251418005\n",
            "Batch 470 of 6492. Elapsed 0:02:19\n",
            "Sample: 0.827908992767334 v/s 0.8211169838905334 v/s 0.8718185604672373\n",
            "Batch 480 of 6492. Elapsed 0:02:22\n",
            "Sample: 0.7298195958137512 v/s 0.7647145986557007 v/s 0.8208961789245054\n",
            "Batch 490 of 6492. Elapsed 0:02:25\n",
            "Sample: 0.7940970659255981 v/s 0.7510973215103149 v/s 0.7954800644430979\n",
            "Batch 500 of 6492. Elapsed 0:02:28\n",
            "Sample: 0.7911176681518555 v/s 0.7747589349746704 v/s 0.7967625784868134\n",
            "Batch 510 of 6492. Elapsed 0:02:31\n",
            "Sample: 0.7605379223823547 v/s 0.7500220537185669 v/s 0.805248739203961\n",
            "Batch 520 of 6492. Elapsed 0:02:34\n",
            "Sample: 0.7635890245437622 v/s 0.7328895330429077 v/s 0.8218145406149551\n",
            "Batch 530 of 6492. Elapsed 0:02:37\n",
            "Sample: 0.8224198222160339 v/s 0.9075837731361389 v/s 0.9311228515277568\n",
            "Batch 540 of 6492. Elapsed 0:02:40\n",
            "Sample: 0.8581576943397522 v/s 0.881571352481842 v/s 0.9080768786049885\n",
            "Batch 550 of 6492. Elapsed 0:02:43\n",
            "Sample: 0.8325928449630737 v/s 0.8932639360427856 v/s 0.9311894467126018\n",
            "Batch 560 of 6492. Elapsed 0:02:46\n",
            "Sample: 0.8324964642524719 v/s 0.7694467902183533 v/s 0.8051440198376274\n",
            "Batch 570 of 6492. Elapsed 0:02:49\n",
            "Sample: 0.8708885312080383 v/s 0.9295408129692078 v/s 0.9449724201716594\n",
            "Batch 580 of 6492. Elapsed 0:02:52\n",
            "Sample: 0.7841432690620422 v/s 0.784720778465271 v/s 0.8342299818094022\n",
            "Batch 590 of 6492. Elapsed 0:02:55\n",
            "Sample: 0.7465353608131409 v/s 0.6739506125450134 v/s 0.7616657421198262\n",
            "Batch 600 of 6492. Elapsed 0:02:58\n",
            "Sample: 0.7586881518363953 v/s 0.8519291877746582 v/s 0.8845780749457519\n",
            "Batch 610 of 6492. Elapsed 0:03:01\n",
            "Sample: 0.8599696159362793 v/s 0.8473259806632996 v/s 0.8788189080945304\n",
            "Batch 620 of 6492. Elapsed 0:03:04\n",
            "Sample: 0.7801218628883362 v/s 0.7897932529449463 v/s 0.8216846744571054\n",
            "Batch 630 of 6492. Elapsed 0:03:07\n",
            "Sample: 0.7824466824531555 v/s 0.7553808689117432 v/s 0.8146170975364694\n",
            "Batch 640 of 6492. Elapsed 0:03:10\n",
            "Sample: 0.7812843322753906 v/s 0.7537717223167419 v/s 0.8380981071625357\n",
            "Batch 650 of 6492. Elapsed 0:03:13\n",
            "Sample: 0.8261633515357971 v/s 0.888486921787262 v/s 0.9027860111364987\n",
            "Batch 660 of 6492. Elapsed 0:03:16\n",
            "Sample: 0.8678618669509888 v/s 0.854957103729248 v/s 0.8740650456879224\n",
            "Batch 670 of 6492. Elapsed 0:03:18\n",
            "Sample: 0.8239849209785461 v/s 0.8285468220710754 v/s 0.8789485022599535\n",
            "Batch 680 of 6492. Elapsed 0:03:21\n",
            "Sample: 0.8278418183326721 v/s 0.7704372406005859 v/s 0.8108084787570707\n",
            "Batch 690 of 6492. Elapsed 0:03:24\n",
            "Sample: 0.8299839496612549 v/s 0.8189314007759094 v/s 0.8607276809951848\n",
            "Batch 700 of 6492. Elapsed 0:03:27\n",
            "Sample: 0.8353093266487122 v/s 0.8337140083312988 v/s 0.8660039538534583\n",
            "Batch 710 of 6492. Elapsed 0:03:30\n",
            "Sample: 0.8767278790473938 v/s 0.834932267665863 v/s 0.8618184451215726\n",
            "Batch 720 of 6492. Elapsed 0:03:33\n",
            "Sample: 0.8008099794387817 v/s 0.854508101940155 v/s 0.89654495239699\n",
            "Batch 730 of 6492. Elapsed 0:03:36\n",
            "Sample: 0.8107494711875916 v/s 0.8584715723991394 v/s 0.9052736479497479\n",
            "Batch 740 of 6492. Elapsed 0:03:39\n",
            "Sample: 0.76665198802948 v/s 0.7538042664527893 v/s 0.8126487456798621\n",
            "Batch 750 of 6492. Elapsed 0:03:42\n",
            "Sample: 0.8559597730636597 v/s 0.8236028552055359 v/s 0.8492283014089147\n",
            "Batch 760 of 6492. Elapsed 0:03:45\n",
            "Sample: 0.702243983745575 v/s 0.771539032459259 v/s 0.8195464480383912\n",
            "Batch 770 of 6492. Elapsed 0:03:48\n",
            "Sample: 0.7379426956176758 v/s 0.7791615724563599 v/s 0.820257824427978\n",
            "Batch 780 of 6492. Elapsed 0:03:51\n",
            "Sample: 0.7952296733856201 v/s 0.7872703075408936 v/s 0.8343309927395002\n",
            "Batch 790 of 6492. Elapsed 0:03:54\n",
            "Sample: 0.8460864424705505 v/s 0.8657971620559692 v/s 0.891869229433262\n",
            "Batch 800 of 6492. Elapsed 0:03:57\n",
            "Sample: 0.8155201077461243 v/s 0.8501701951026917 v/s 0.871123183885894\n",
            "Batch 810 of 6492. Elapsed 0:04:00\n",
            "Sample: 0.7725743651390076 v/s 0.7701110243797302 v/s 0.8287204215338696\n",
            "Batch 820 of 6492. Elapsed 0:04:02\n",
            "Sample: 0.8195138573646545 v/s 0.8046902418136597 v/s 0.8542385635253825\n",
            "Batch 830 of 6492. Elapsed 0:04:05\n",
            "Sample: 0.7404995560646057 v/s 0.7137013673782349 v/s 0.7839479508817103\n",
            "Batch 840 of 6492. Elapsed 0:04:08\n",
            "Sample: 0.8752900958061218 v/s 0.9296874403953552 v/s 0.954867430421573\n",
            "Batch 850 of 6492. Elapsed 0:04:11\n",
            "Sample: 0.8275036215782166 v/s 0.7927661538124084 v/s 0.8353275295423692\n",
            "Batch 860 of 6492. Elapsed 0:04:14\n",
            "Sample: 0.7903038263320923 v/s 0.7689176797866821 v/s 0.8097830952043048\n",
            "Batch 870 of 6492. Elapsed 0:04:17\n",
            "Sample: 0.9317922592163086 v/s 0.9209031462669373 v/s 0.9449983924533717\n",
            "Batch 880 of 6492. Elapsed 0:04:20\n",
            "Sample: 0.7405949831008911 v/s 0.6343428492546082 v/s 0.7425858746879875\n",
            "Batch 890 of 6492. Elapsed 0:04:23\n",
            "Sample: 0.8330666422843933 v/s 0.807166337966919 v/s 0.8314044107926606\n",
            "Batch 900 of 6492. Elapsed 0:04:26\n",
            "Sample: 0.8136165738105774 v/s 0.77354496717453 v/s 0.8303898226729726\n",
            "Batch 910 of 6492. Elapsed 0:04:29\n",
            "Sample: 0.8274823427200317 v/s 0.8949086666107178 v/s 0.918079456688501\n",
            "Batch 920 of 6492. Elapsed 0:04:32\n",
            "Sample: 0.8696936368942261 v/s 0.8408621549606323 v/s 0.8772377330199995\n",
            "Batch 930 of 6492. Elapsed 0:04:35\n",
            "Sample: 0.8275099992752075 v/s 0.759331226348877 v/s 0.8348016679545112\n",
            "Batch 940 of 6492. Elapsed 0:04:38\n",
            "Sample: 0.7657989263534546 v/s 0.7641351222991943 v/s 0.8112412136255266\n",
            "Batch 950 of 6492. Elapsed 0:04:41\n",
            "Sample: 0.8456737995147705 v/s 0.9289408326148987 v/s 0.9380489462247482\n",
            "Batch 960 of 6492. Elapsed 0:04:44\n",
            "Sample: 0.8471286296844482 v/s 0.8599998354911804 v/s 0.882346795356017\n",
            "Batch 970 of 6492. Elapsed 0:04:47\n",
            "Sample: 0.7729551792144775 v/s 0.7557883262634277 v/s 0.8367213149785632\n",
            "Batch 980 of 6492. Elapsed 0:04:50\n",
            "Sample: 0.778688907623291 v/s 0.8103535771369934 v/s 0.8604142183230967\n",
            "Batch 990 of 6492. Elapsed 0:04:53\n",
            "Sample: 0.8522277474403381 v/s 0.8445885181427002 v/s 0.8801780715001919\n",
            "Batch 1000 of 6492. Elapsed 0:04:56\n",
            "Sample: 0.762150764465332 v/s 0.8010078072547913 v/s 0.8347301195140276\n",
            "Batch 1010 of 6492. Elapsed 0:04:59\n",
            "Sample: 0.8590813279151917 v/s 0.8965722918510437 v/s 0.901964771180574\n",
            "Batch 1020 of 6492. Elapsed 0:05:02\n",
            "Sample: 0.9000784754753113 v/s 0.9677468538284302 v/s 0.9783602363359118\n",
            "Batch 1030 of 6492. Elapsed 0:05:04\n",
            "Sample: 0.7862528562545776 v/s 0.7920880317687988 v/s 0.8176380141155128\n",
            "Batch 1040 of 6492. Elapsed 0:05:07\n",
            "Sample: 0.8014458417892456 v/s 0.7899395227432251 v/s 0.8379532703815195\n",
            "Batch 1050 of 6492. Elapsed 0:05:10\n",
            "Sample: 0.8757737874984741 v/s 0.9317828416824341 v/s 0.9557147384962206\n",
            "Batch 1060 of 6492. Elapsed 0:05:13\n",
            "Sample: 0.8534183502197266 v/s 0.8273886442184448 v/s 0.8679581916451777\n",
            "Batch 1070 of 6492. Elapsed 0:05:16\n",
            "Sample: 0.7253552675247192 v/s 0.7123686671257019 v/s 0.8063641790807785\n",
            "Batch 1080 of 6492. Elapsed 0:05:19\n",
            "Sample: 0.8629565238952637 v/s 0.8394114971160889 v/s 0.8897960436705814\n",
            "Batch 1090 of 6492. Elapsed 0:05:22\n",
            "Sample: 0.8404014110565186 v/s 0.8116548657417297 v/s 0.8540602536820899\n",
            "Batch 1100 of 6492. Elapsed 0:05:25\n",
            "Sample: 0.666748583316803 v/s 0.6782122254371643 v/s 0.753556584666114\n",
            "Batch 1110 of 6492. Elapsed 0:05:28\n",
            "Sample: 0.7946330904960632 v/s 0.7446699142456055 v/s 0.8078816792063963\n",
            "Batch 1120 of 6492. Elapsed 0:05:31\n",
            "Sample: 0.8248159885406494 v/s 0.840411365032196 v/s 0.8802268233075952\n",
            "Batch 1130 of 6492. Elapsed 0:05:34\n",
            "Sample: 0.861542284488678 v/s 0.8776122331619263 v/s 0.8942440364896544\n",
            "Batch 1140 of 6492. Elapsed 0:05:37\n",
            "Sample: 0.8616876006126404 v/s 0.8334027528762817 v/s 0.873430568141733\n",
            "Batch 1150 of 6492. Elapsed 0:05:40\n",
            "Sample: 0.8457245230674744 v/s 0.8001390695571899 v/s 0.8428970416122871\n",
            "Batch 1160 of 6492. Elapsed 0:05:43\n",
            "Sample: 0.7553236484527588 v/s 0.7510841488838196 v/s 0.8063373067849071\n",
            "Batch 1170 of 6492. Elapsed 0:05:46\n",
            "Sample: 0.8457078337669373 v/s 0.8416521549224854 v/s 0.8755990209673796\n",
            "Batch 1180 of 6492. Elapsed 0:05:49\n",
            "Sample: 0.7795276045799255 v/s 0.7198968529701233 v/s 0.764803755355809\n",
            "Batch 1190 of 6492. Elapsed 0:05:51\n",
            "Sample: 0.8998875021934509 v/s 0.9430689215660095 v/s 0.9605406781564754\n",
            "Batch 1200 of 6492. Elapsed 0:05:54\n",
            "Sample: 0.8644863367080688 v/s 0.916696310043335 v/s 0.9356578782567093\n",
            "Batch 1210 of 6492. Elapsed 0:05:57\n",
            "Sample: 0.7677071690559387 v/s 0.7410381436347961 v/s 0.7777540271000157\n",
            "Batch 1220 of 6492. Elapsed 0:06:01\n",
            "Sample: 0.8364982008934021 v/s 0.8338073492050171 v/s 0.866624890220721\n",
            "Batch 1230 of 6492. Elapsed 0:06:03\n",
            "Sample: 0.8494508266448975 v/s 0.8731197118759155 v/s 0.9000112682996133\n",
            "Batch 1240 of 6492. Elapsed 0:06:06\n",
            "Sample: 0.852136492729187 v/s 0.8951130509376526 v/s 0.9193156015222617\n",
            "Batch 1250 of 6492. Elapsed 0:06:09\n",
            "Sample: 0.8196282982826233 v/s 0.8566213250160217 v/s 0.8853160689307259\n",
            "Batch 1260 of 6492. Elapsed 0:06:12\n",
            "Sample: 0.7337202429771423 v/s 0.7033438086509705 v/s 0.7833036599125949\n",
            "Batch 1270 of 6492. Elapsed 0:06:15\n",
            "Sample: 0.8079435229301453 v/s 0.8072320818901062 v/s 0.861448097177215\n",
            "Batch 1280 of 6492. Elapsed 0:06:18\n",
            "Sample: 0.8131481409072876 v/s 0.8860148191452026 v/s 0.9220340884122608\n",
            "Batch 1290 of 6492. Elapsed 0:06:21\n",
            "Sample: 0.8490530252456665 v/s 0.8050315976142883 v/s 0.8692436210202045\n",
            "Batch 1300 of 6492. Elapsed 0:06:24\n",
            "Sample: 0.842863142490387 v/s 0.8592235445976257 v/s 0.884416391662279\n",
            "Batch 1310 of 6492. Elapsed 0:06:27\n",
            "Sample: 0.785127580165863 v/s 0.835878849029541 v/s 0.8827227240733001\n",
            "Batch 1320 of 6492. Elapsed 0:06:30\n",
            "Sample: 0.865800678730011 v/s 0.8741450905799866 v/s 0.9022878419736847\n",
            "Batch 1330 of 6492. Elapsed 0:06:33\n",
            "Sample: 0.8640791177749634 v/s 0.8785093426704407 v/s 0.8956607817371498\n",
            "Batch 1340 of 6492. Elapsed 0:06:36\n",
            "Sample: 0.8343809843063354 v/s 0.8301665782928467 v/s 0.882156337924855\n",
            "Batch 1350 of 6492. Elapsed 0:06:40\n",
            "Sample: 0.8486964106559753 v/s 0.808104932308197 v/s 0.8651129290679083\n",
            "Batch 1360 of 6492. Elapsed 0:06:43\n",
            "Sample: 0.8701245784759521 v/s 0.8978567719459534 v/s 0.9141638076003523\n",
            "Batch 1370 of 6492. Elapsed 0:06:46\n",
            "Sample: 0.8436349034309387 v/s 0.918757438659668 v/s 0.9357934650772376\n",
            "Batch 1380 of 6492. Elapsed 0:06:49\n",
            "Sample: 0.7743452191352844 v/s 0.793925940990448 v/s 0.8272084485352255\n",
            "Batch 1390 of 6492. Elapsed 0:06:52\n",
            "Sample: 0.8235556483268738 v/s 0.7963830232620239 v/s 0.8601234556630574\n",
            "Batch 1400 of 6492. Elapsed 0:06:55\n",
            "Sample: 0.8382652401924133 v/s 0.7300684452056885 v/s 0.8064782554400234\n",
            "Batch 1410 of 6492. Elapsed 0:06:57\n",
            "Sample: 0.8285983800888062 v/s 0.783399224281311 v/s 0.8443279002241785\n",
            "Batch 1420 of 6492. Elapsed 0:07:00\n",
            "Sample: 0.8462509512901306 v/s 0.7848154306411743 v/s 0.82015470832886\n",
            "Batch 1430 of 6492. Elapsed 0:07:03\n",
            "Sample: 0.7122864723205566 v/s 0.6689170002937317 v/s 0.7803926396872813\n",
            "Batch 1440 of 6492. Elapsed 0:07:06\n",
            "Sample: 0.8055142760276794 v/s 0.7980647683143616 v/s 0.8380120243041763\n",
            "Batch 1450 of 6492. Elapsed 0:07:09\n",
            "Sample: 0.8116892576217651 v/s 0.7594276070594788 v/s 0.7955103070049239\n",
            "Batch 1460 of 6492. Elapsed 0:07:12\n",
            "Sample: 0.7470516562461853 v/s 0.7586881518363953 v/s 0.8078369526304742\n",
            "Batch 1470 of 6492. Elapsed 0:07:15\n",
            "Sample: 0.7183238863945007 v/s 0.7589243054389954 v/s 0.8186934230050894\n",
            "Batch 1480 of 6492. Elapsed 0:07:18\n",
            "Sample: 0.7694724798202515 v/s 0.71268630027771 v/s 0.7690914801080666\n",
            "Batch 1490 of 6492. Elapsed 0:07:21\n",
            "Sample: 0.8027431964874268 v/s 0.8310513496398926 v/s 0.8630782364505415\n",
            "Batch 1500 of 6492. Elapsed 0:07:24\n",
            "Sample: 0.8329465389251709 v/s 0.8295034766197205 v/s 0.8539762290811631\n",
            "Batch 1510 of 6492. Elapsed 0:07:27\n",
            "Sample: 0.8236958980560303 v/s 0.7934587001800537 v/s 0.8448479002566793\n",
            "Batch 1520 of 6492. Elapsed 0:07:30\n",
            "Sample: 0.8304727077484131 v/s 0.8314691185951233 v/s 0.8576859832195409\n",
            "Batch 1530 of 6492. Elapsed 0:07:33\n",
            "Sample: 0.8054929375648499 v/s 0.8021577000617981 v/s 0.8406628270289005\n",
            "Batch 1540 of 6492. Elapsed 0:07:36\n",
            "Sample: 0.7738892436027527 v/s 0.7484275698661804 v/s 0.7910906526671474\n",
            "Batch 1550 of 6492. Elapsed 0:07:39\n",
            "Sample: 0.7500846982002258 v/s 0.7453116178512573 v/s 0.7983943527057505\n",
            "Batch 1560 of 6492. Elapsed 0:07:42\n",
            "Sample: 0.8150560855865479 v/s 0.8264409899711609 v/s 0.8705505742099312\n",
            "Batch 1570 of 6492. Elapsed 0:07:44\n",
            "Sample: 0.8245235681533813 v/s 0.8259541988372803 v/s 0.8495595535427272\n",
            "Batch 1580 of 6492. Elapsed 0:07:47\n",
            "Sample: 0.7961378693580627 v/s 0.7645574808120728 v/s 0.8025177059294704\n",
            "Batch 1590 of 6492. Elapsed 0:07:50\n",
            "Sample: 0.8038794994354248 v/s 0.7950660586357117 v/s 0.8192013406460904\n",
            "Batch 1600 of 6492. Elapsed 0:07:53\n",
            "Sample: 0.8221850991249084 v/s 0.808289110660553 v/s 0.8286298507553994\n",
            "Batch 1610 of 6492. Elapsed 0:07:56\n",
            "Sample: 0.8447499871253967 v/s 0.8333576321601868 v/s 0.8665109377010004\n",
            "Batch 1620 of 6492. Elapsed 0:07:59\n",
            "Sample: 0.8059599995613098 v/s 0.8356698155403137 v/s 0.8608867273713657\n",
            "Batch 1630 of 6492. Elapsed 0:08:02\n",
            "Sample: 0.7929661273956299 v/s 0.7448368072509766 v/s 0.7870314240814621\n",
            "Batch 1640 of 6492. Elapsed 0:08:05\n",
            "Sample: 0.9300009608268738 v/s 0.9833807945251465 v/s 0.9886119092681617\n",
            "Batch 1650 of 6492. Elapsed 0:08:08\n",
            "Sample: 0.8975361585617065 v/s 0.9643888473510742 v/s 0.9739724000528843\n",
            "Batch 1660 of 6492. Elapsed 0:08:11\n",
            "Sample: 0.7395586967468262 v/s 0.7434794306755066 v/s 0.8106804002291484\n",
            "Batch 1670 of 6492. Elapsed 0:08:14\n",
            "Sample: 0.7834351062774658 v/s 0.754692554473877 v/s 0.7987187854982466\n",
            "Batch 1680 of 6492. Elapsed 0:08:17\n",
            "Sample: 0.7097809910774231 v/s 0.6331334710121155 v/s 0.7226534167352078\n",
            "Batch 1690 of 6492. Elapsed 0:08:20\n",
            "Sample: 0.7382197380065918 v/s 0.7721594572067261 v/s 0.8420699256133258\n",
            "Batch 1700 of 6492. Elapsed 0:08:23\n",
            "Sample: 0.7933924198150635 v/s 0.7829806208610535 v/s 0.832808744338626\n",
            "Batch 1710 of 6492. Elapsed 0:08:26\n",
            "Sample: 0.7870061993598938 v/s 0.8165515661239624 v/s 0.8821458795029509\n",
            "Batch 1720 of 6492. Elapsed 0:08:29\n",
            "Sample: 0.798204243183136 v/s 0.864141583442688 v/s 0.9088178687137304\n",
            "Batch 1730 of 6492. Elapsed 0:08:32\n",
            "Sample: 0.7798562049865723 v/s 0.7074615955352783 v/s 0.797675515400739\n",
            "Batch 1740 of 6492. Elapsed 0:08:35\n",
            "Sample: 0.8959149122238159 v/s 0.8910531997680664 v/s 0.9241290037965731\n",
            "Batch 1750 of 6492. Elapsed 0:08:38\n",
            "Sample: 0.8368571400642395 v/s 0.8521491885185242 v/s 0.8815168643559882\n",
            "Batch 1760 of 6492. Elapsed 0:08:41\n",
            "Sample: 0.879491925239563 v/s 0.8202812671661377 v/s 0.8833638531956399\n",
            "Batch 1770 of 6492. Elapsed 0:08:44\n",
            "Sample: 0.9017106890678406 v/s 0.8561522364616394 v/s 0.8965493489365213\n",
            "Batch 1780 of 6492. Elapsed 0:08:47\n",
            "Sample: 0.8291678428649902 v/s 0.8200280666351318 v/s 0.8534169090796296\n",
            "Batch 1790 of 6492. Elapsed 0:08:50\n",
            "Sample: 0.8121106028556824 v/s 0.7724781036376953 v/s 0.825168875726137\n",
            "Batch 1800 of 6492. Elapsed 0:08:53\n",
            "Sample: 0.8529329299926758 v/s 0.8870465755462646 v/s 0.8989311890658849\n",
            "Batch 1810 of 6492. Elapsed 0:08:56\n",
            "Sample: 0.754356324672699 v/s 0.8639569282531738 v/s 0.8962669104887961\n",
            "Batch 1820 of 6492. Elapsed 0:08:59\n",
            "Sample: 0.7572967410087585 v/s 0.7974672317504883 v/s 0.8366070225848818\n",
            "Batch 1830 of 6492. Elapsed 0:09:02\n",
            "Sample: 0.7861732244491577 v/s 0.8074262142181396 v/s 0.835107572088963\n",
            "Batch 1840 of 6492. Elapsed 0:09:04\n",
            "Sample: 0.7615535855293274 v/s 0.7519515752792358 v/s 0.827840036490037\n",
            "Batch 1850 of 6492. Elapsed 0:09:07\n",
            "Sample: 0.8341310024261475 v/s 0.7606810927391052 v/s 0.7859843297572598\n",
            "Batch 1860 of 6492. Elapsed 0:09:10\n",
            "Sample: 0.7755159735679626 v/s 0.7877087593078613 v/s 0.8186936514404967\n",
            "Batch 1870 of 6492. Elapsed 0:09:13\n",
            "Sample: 0.8774369359016418 v/s 0.8639365434646606 v/s 0.9227503615608611\n",
            "Batch 1880 of 6492. Elapsed 0:09:16\n",
            "Sample: 0.9082342982292175 v/s 0.9849831461906433 v/s 0.9861224358859771\n",
            "Batch 1890 of 6492. Elapsed 0:09:19\n",
            "Sample: 0.8739258646965027 v/s 0.8044314384460449 v/s 0.8456279805287165\n",
            "Batch 1900 of 6492. Elapsed 0:09:22\n",
            "Sample: 0.7737200856208801 v/s 0.7470977306365967 v/s 0.8085977251262472\n",
            "Batch 1910 of 6492. Elapsed 0:09:25\n",
            "Sample: 0.7694956660270691 v/s 0.7796534299850464 v/s 0.8187663826573865\n",
            "Batch 1920 of 6492. Elapsed 0:09:28\n",
            "Sample: 0.8589230179786682 v/s 0.8846436142921448 v/s 0.9162168001090596\n",
            "Batch 1930 of 6492. Elapsed 0:09:31\n",
            "Sample: 0.8280739784240723 v/s 0.8444541096687317 v/s 0.8759090903416449\n",
            "Batch 1940 of 6492. Elapsed 0:09:34\n",
            "Sample: 0.8251026272773743 v/s 0.8021841049194336 v/s 0.8585397564475653\n",
            "Batch 1950 of 6492. Elapsed 0:09:37\n",
            "Sample: 0.8140146136283875 v/s 0.8181697130203247 v/s 0.8701440249530753\n",
            "Batch 1960 of 6492. Elapsed 0:09:40\n",
            "Sample: 0.8768416047096252 v/s 0.9107635021209717 v/s 0.9200113509028741\n",
            "Batch 1970 of 6492. Elapsed 0:09:43\n",
            "Sample: 0.8414623737335205 v/s 0.8627175092697144 v/s 0.8798517418117214\n",
            "Batch 1980 of 6492. Elapsed 0:09:46\n",
            "Sample: 0.8509504795074463 v/s 0.8345796465873718 v/s 0.8770190859143752\n",
            "Batch 1990 of 6492. Elapsed 0:09:49\n",
            "Sample: 0.7638469338417053 v/s 0.7903105020523071 v/s 0.8234454939165725\n",
            "Batch 2000 of 6492. Elapsed 0:09:52\n",
            "Sample: 0.8085301518440247 v/s 0.7152563333511353 v/s 0.7889405833146942\n",
            "Batch 2010 of 6492. Elapsed 0:09:55\n",
            "Sample: 0.8944361209869385 v/s 0.9126902222633362 v/s 0.9314037728046696\n",
            "Batch 2020 of 6492. Elapsed 0:09:58\n",
            "Sample: 0.8046660423278809 v/s 0.7853625416755676 v/s 0.8285619829449583\n",
            "Batch 2030 of 6492. Elapsed 0:10:01\n",
            "Sample: 0.8170068264007568 v/s 0.8888801336288452 v/s 0.912806448905282\n",
            "Batch 2040 of 6492. Elapsed 0:10:03\n",
            "Sample: 0.8268203139305115 v/s 0.8601702451705933 v/s 0.891181627477678\n",
            "Batch 2050 of 6492. Elapsed 0:10:06\n",
            "Sample: 0.8460447192192078 v/s 0.892724871635437 v/s 0.9186602914705254\n",
            "Batch 2060 of 6492. Elapsed 0:10:09\n",
            "Sample: 0.8752039074897766 v/s 0.9488321542739868 v/s 0.9601034065954909\n",
            "Batch 2070 of 6492. Elapsed 0:10:12\n",
            "Sample: 0.75199955701828 v/s 0.7934938073158264 v/s 0.8452648871125007\n",
            "Batch 2080 of 6492. Elapsed 0:10:15\n",
            "Sample: 0.7609243988990784 v/s 0.6921555995941162 v/s 0.7742839487516736\n",
            "Batch 2090 of 6492. Elapsed 0:10:18\n",
            "Sample: 0.7812568545341492 v/s 0.824998676776886 v/s 0.8534152812066974\n",
            "Batch 2100 of 6492. Elapsed 0:10:21\n",
            "Sample: 0.7691887021064758 v/s 0.6969727873802185 v/s 0.7378692933181493\n",
            "Batch 2110 of 6492. Elapsed 0:10:24\n",
            "Sample: 0.848937451839447 v/s 0.9023532867431641 v/s 0.9371078533212599\n",
            "Batch 2120 of 6492. Elapsed 0:10:27\n",
            "Sample: 0.845672607421875 v/s 0.8292957544326782 v/s 0.8757353842643928\n",
            "Batch 2130 of 6492. Elapsed 0:10:30\n",
            "Sample: 0.7601165771484375 v/s 0.743114173412323 v/s 0.8104986203590183\n",
            "Batch 2140 of 6492. Elapsed 0:10:33\n",
            "Sample: 0.8542091250419617 v/s 0.8712469935417175 v/s 0.9049060323057707\n",
            "Batch 2150 of 6492. Elapsed 0:10:36\n",
            "Sample: 0.8357310891151428 v/s 0.8123408555984497 v/s 0.8349074595119136\n",
            "Batch 2160 of 6492. Elapsed 0:10:39\n",
            "Sample: 0.7943784594535828 v/s 0.7857356071472168 v/s 0.8482200057092274\n",
            "Batch 2170 of 6492. Elapsed 0:10:42\n",
            "Sample: 0.8621684312820435 v/s 0.9213401675224304 v/s 0.9398443411786485\n",
            "Batch 2180 of 6492. Elapsed 0:10:45\n",
            "Sample: 0.8247889876365662 v/s 0.8540881276130676 v/s 0.8804079610684183\n",
            "Batch 2190 of 6492. Elapsed 0:10:47\n",
            "Sample: 0.7378819584846497 v/s 0.7042084336280823 v/s 0.7483862896888754\n",
            "Batch 2200 of 6492. Elapsed 0:10:51\n",
            "Sample: 0.8140808939933777 v/s 0.8233884572982788 v/s 0.8530236884581053\n",
            "Batch 2210 of 6492. Elapsed 0:10:54\n",
            "Sample: 0.9026421308517456 v/s 0.9232656955718994 v/s 0.9414177898006346\n",
            "Batch 2220 of 6492. Elapsed 0:10:56\n",
            "Sample: 0.7907305359840393 v/s 0.7706667184829712 v/s 0.8233761606609468\n",
            "Batch 2230 of 6492. Elapsed 0:10:59\n",
            "Sample: 0.8581698536872864 v/s 0.9573641419410706 v/s 0.9680684190969318\n",
            "Batch 2240 of 6492. Elapsed 0:11:03\n",
            "Sample: 0.6536640524864197 v/s 0.6750730276107788 v/s 0.7662436066138301\n",
            "Batch 2250 of 6492. Elapsed 0:11:06\n",
            "Sample: 0.7798164486885071 v/s 0.7960435748100281 v/s 0.8523336081118216\n",
            "Batch 2260 of 6492. Elapsed 0:11:08\n",
            "Sample: 0.8674799203872681 v/s 0.8859891891479492 v/s 0.905348250328102\n",
            "Batch 2270 of 6492. Elapsed 0:11:11\n",
            "Sample: 0.8280814290046692 v/s 0.8158397078514099 v/s 0.8702394246851718\n",
            "Batch 2280 of 6492. Elapsed 0:11:14\n",
            "Sample: 0.8861788511276245 v/s 0.9166439175605774 v/s 0.9313646535206638\n",
            "Batch 2290 of 6492. Elapsed 0:11:17\n",
            "Sample: 0.7446364164352417 v/s 0.6748302578926086 v/s 0.7419395690963967\n",
            "Batch 2300 of 6492. Elapsed 0:11:20\n",
            "Sample: 0.7863874435424805 v/s 0.7422851920127869 v/s 0.7943660035026878\n",
            "Batch 2310 of 6492. Elapsed 0:11:23\n",
            "Sample: 0.8508304357528687 v/s 0.8568909168243408 v/s 0.8794659847040965\n",
            "Batch 2320 of 6492. Elapsed 0:11:26\n",
            "Sample: 0.7779955863952637 v/s 0.6952311396598816 v/s 0.7586404605788901\n",
            "Batch 2330 of 6492. Elapsed 0:11:29\n",
            "Sample: 0.801446259021759 v/s 0.8039635419845581 v/s 0.8536415688596437\n",
            "Batch 2340 of 6492. Elapsed 0:11:32\n",
            "Sample: 0.7303242683410645 v/s 0.7081230282783508 v/s 0.7656053387858468\n",
            "Batch 2350 of 6492. Elapsed 0:11:35\n",
            "Sample: 0.785203218460083 v/s 0.7515245676040649 v/s 0.8093066702659459\n",
            "Batch 2360 of 6492. Elapsed 0:11:38\n",
            "Sample: 0.6814248561859131 v/s 0.6005547046661377 v/s 0.7137090363012351\n",
            "Batch 2370 of 6492. Elapsed 0:11:41\n",
            "Sample: 0.8025949001312256 v/s 0.81000816822052 v/s 0.8457567573312456\n",
            "Batch 2380 of 6492. Elapsed 0:11:44\n",
            "Sample: 0.7025978565216064 v/s 0.7484560012817383 v/s 0.7919322347678822\n",
            "Batch 2390 of 6492. Elapsed 0:11:47\n",
            "Sample: 0.8325504064559937 v/s 0.8798269629478455 v/s 0.8940344716771021\n",
            "Batch 2400 of 6492. Elapsed 0:11:50\n",
            "Sample: 0.8474146127700806 v/s 0.8589363098144531 v/s 0.8883897042877279\n",
            "Batch 2410 of 6492. Elapsed 0:11:53\n",
            "Sample: 0.8410320281982422 v/s 0.7978800535202026 v/s 0.8226664171041228\n",
            "Batch 2420 of 6492. Elapsed 0:11:55\n",
            "Sample: 0.8864079117774963 v/s 0.913686990737915 v/s 0.9342982573659203\n",
            "Batch 2430 of 6492. Elapsed 0:11:58\n",
            "Sample: 0.8722107410430908 v/s 0.8589944243431091 v/s 0.9006456957563015\n",
            "Batch 2440 of 6492. Elapsed 0:12:01\n",
            "Sample: 0.8311066031455994 v/s 0.8028361797332764 v/s 0.84968646247518\n",
            "Batch 2450 of 6492. Elapsed 0:12:04\n",
            "Sample: 0.8184098601341248 v/s 0.8211622834205627 v/s 0.867506216170549\n",
            "Batch 2460 of 6492. Elapsed 0:12:08\n",
            "Sample: 0.8128646612167358 v/s 0.8526527881622314 v/s 0.8789858305152944\n",
            "Batch 2470 of 6492. Elapsed 0:12:10\n",
            "Sample: 0.8247696757316589 v/s 0.850837767124176 v/s 0.8850307648186968\n",
            "Batch 2480 of 6492. Elapsed 0:12:13\n",
            "Sample: 0.790084183216095 v/s 0.7623184323310852 v/s 0.8170093314446858\n",
            "Batch 2490 of 6492. Elapsed 0:12:16\n",
            "Sample: 0.7731738686561584 v/s 0.6818349361419678 v/s 0.7271525216456499\n",
            "Batch 2500 of 6492. Elapsed 0:12:19\n",
            "Sample: 0.9198914766311646 v/s 0.9440784454345703 v/s 0.9581032821365533\n",
            "Batch 2510 of 6492. Elapsed 0:12:22\n",
            "Sample: 0.8734095692634583 v/s 0.8314467668533325 v/s 0.8880155472783741\n",
            "Batch 2520 of 6492. Elapsed 0:12:25\n",
            "Sample: 0.7212442755699158 v/s 0.6953662633895874 v/s 0.7432523603572516\n",
            "Batch 2530 of 6492. Elapsed 0:12:28\n",
            "Sample: 0.7473857998847961 v/s 0.6968281865119934 v/s 0.7609940941762302\n",
            "Batch 2540 of 6492. Elapsed 0:12:31\n",
            "Sample: 0.8032944798469543 v/s 0.7164347767829895 v/s 0.7424610562288834\n",
            "Batch 2550 of 6492. Elapsed 0:12:34\n",
            "Sample: 0.8333582878112793 v/s 0.889449954032898 v/s 0.9188643615306529\n",
            "Batch 2560 of 6492. Elapsed 0:12:37\n",
            "Sample: 0.8760353326797485 v/s 0.8937594890594482 v/s 0.905489353000528\n",
            "Batch 2570 of 6492. Elapsed 0:12:40\n",
            "Sample: 0.9120314121246338 v/s 0.9532296061515808 v/s 0.968679764933582\n",
            "Batch 2580 of 6492. Elapsed 0:12:43\n",
            "Sample: 0.8213067650794983 v/s 0.7779464721679688 v/s 0.8527763463161562\n",
            "Batch 2590 of 6492. Elapsed 0:12:46\n",
            "Sample: 0.7687074542045593 v/s 0.7395836114883423 v/s 0.7730806424545215\n",
            "Batch 2600 of 6492. Elapsed 0:12:49\n",
            "Sample: 0.7941113710403442 v/s 0.7803595662117004 v/s 0.8545514214731573\n",
            "Batch 2610 of 6492. Elapsed 0:12:52\n",
            "Sample: 0.8391115069389343 v/s 0.8121744394302368 v/s 0.8344998530895016\n",
            "Batch 2620 of 6492. Elapsed 0:12:55\n",
            "Sample: 0.8300018310546875 v/s 0.7770344614982605 v/s 0.8202056884547465\n",
            "Batch 2630 of 6492. Elapsed 0:12:58\n",
            "Sample: 0.8214829564094543 v/s 0.8039602637290955 v/s 0.8615333716152748\n",
            "Batch 2640 of 6492. Elapsed 0:13:01\n",
            "Sample: 0.8840258717536926 v/s 0.8843271136283875 v/s 0.9058228032808026\n",
            "Batch 2650 of 6492. Elapsed 0:13:04\n",
            "Sample: 0.7737187743186951 v/s 0.7551536560058594 v/s 0.8196531443654105\n",
            "Batch 2660 of 6492. Elapsed 0:13:07\n",
            "Sample: 0.8225592970848083 v/s 0.8628483414649963 v/s 0.8920281535539255\n",
            "Batch 2670 of 6492. Elapsed 0:13:10\n",
            "Sample: 0.844778299331665 v/s 0.8414379954338074 v/s 0.8906150669839674\n",
            "Batch 2680 of 6492. Elapsed 0:13:13\n",
            "Sample: 0.8399549126625061 v/s 0.8116067051887512 v/s 0.8461139495064494\n",
            "Batch 2690 of 6492. Elapsed 0:13:16\n",
            "Sample: 0.8210330009460449 v/s 0.7431850433349609 v/s 0.7928443405327966\n",
            "Batch 2700 of 6492. Elapsed 0:13:19\n",
            "Sample: 0.6994117498397827 v/s 0.7100925445556641 v/s 0.7913014757237488\n",
            "Batch 2710 of 6492. Elapsed 0:13:22\n",
            "Sample: 0.7386480569839478 v/s 0.734140932559967 v/s 0.7814652108150002\n",
            "Batch 2720 of 6492. Elapsed 0:13:25\n",
            "Sample: 0.8347037434577942 v/s 0.7588152289390564 v/s 0.8310019026767228\n",
            "Batch 2730 of 6492. Elapsed 0:13:28\n",
            "Sample: 0.845654308795929 v/s 0.8161525130271912 v/s 0.8619483755190641\n",
            "Batch 2740 of 6492. Elapsed 0:13:31\n",
            "Sample: 0.822155237197876 v/s 0.8992907404899597 v/s 0.92789715813636\n",
            "Batch 2750 of 6492. Elapsed 0:13:34\n",
            "Sample: 0.7624368071556091 v/s 0.727249801158905 v/s 0.7703181088759322\n",
            "Batch 2760 of 6492. Elapsed 0:13:37\n",
            "Sample: 0.8244816660881042 v/s 0.8437926173210144 v/s 0.8805547128061019\n",
            "Batch 2770 of 6492. Elapsed 0:13:40\n",
            "Sample: 0.6933207511901855 v/s 0.667232096195221 v/s 0.7556200893560749\n",
            "Batch 2780 of 6492. Elapsed 0:13:43\n",
            "Sample: 0.8605972528457642 v/s 0.921805202960968 v/s 0.9371827827004661\n",
            "Batch 2790 of 6492. Elapsed 0:13:46\n",
            "Sample: 0.8713549971580505 v/s 0.83570796251297 v/s 0.8801575116547672\n",
            "Batch 2800 of 6492. Elapsed 0:13:49\n",
            "Sample: 0.7913066744804382 v/s 0.7496028542518616 v/s 0.7768153230300535\n",
            "Batch 2810 of 6492. Elapsed 0:13:52\n",
            "Sample: 0.811803936958313 v/s 0.78426593542099 v/s 0.8257301688587927\n",
            "Batch 2820 of 6492. Elapsed 0:13:55\n",
            "Sample: 0.8108649849891663 v/s 0.7537609338760376 v/s 0.7855543308821338\n",
            "Batch 2830 of 6492. Elapsed 0:13:58\n",
            "Sample: 0.8204728364944458 v/s 0.7472261190414429 v/s 0.8222238340792069\n",
            "Batch 2840 of 6492. Elapsed 0:14:01\n",
            "Sample: 0.8153671622276306 v/s 0.7463009357452393 v/s 0.7949637945324932\n",
            "Batch 2850 of 6492. Elapsed 0:14:04\n",
            "Sample: 0.8219631910324097 v/s 0.7992867827415466 v/s 0.8560594148348467\n",
            "Batch 2860 of 6492. Elapsed 0:14:07\n",
            "Sample: 0.8263505101203918 v/s 0.873406171798706 v/s 0.8931844468206726\n",
            "Batch 2870 of 6492. Elapsed 0:14:10\n",
            "Sample: 0.7528852224349976 v/s 0.7342174649238586 v/s 0.7902166942467802\n",
            "Batch 2880 of 6492. Elapsed 0:14:13\n",
            "Sample: 0.8432498574256897 v/s 0.8178927302360535 v/s 0.8562174715773229\n",
            "Batch 2890 of 6492. Elapsed 0:14:16\n",
            "Sample: 0.7890239953994751 v/s 0.7820641994476318 v/s 0.8140834764608109\n",
            "Batch 2900 of 6492. Elapsed 0:14:19\n",
            "Sample: 0.7372887134552002 v/s 0.6880462765693665 v/s 0.7523520183854432\n",
            "Batch 2910 of 6492. Elapsed 0:14:22\n",
            "Sample: 0.8363795876502991 v/s 0.8621366024017334 v/s 0.887561079362711\n",
            "Batch 2920 of 6492. Elapsed 0:14:25\n",
            "Sample: 0.8067530989646912 v/s 0.8363760709762573 v/s 0.8662299112682507\n",
            "Batch 2930 of 6492. Elapsed 0:14:28\n",
            "Sample: 0.8566952347755432 v/s 0.8874855637550354 v/s 0.9179323760976685\n",
            "Batch 2940 of 6492. Elapsed 0:14:31\n",
            "Sample: 0.8265188932418823 v/s 0.9029706120491028 v/s 0.9235288523578814\n",
            "Batch 2950 of 6492. Elapsed 0:14:34\n",
            "Sample: 0.7869052886962891 v/s 0.7697550654411316 v/s 0.8164579920458501\n",
            "Batch 2960 of 6492. Elapsed 0:14:37\n",
            "Sample: 0.8557078242301941 v/s 0.845996618270874 v/s 0.8930295659113916\n",
            "Batch 2970 of 6492. Elapsed 0:14:40\n",
            "Sample: 0.8260623812675476 v/s 0.8769643902778625 v/s 0.8871536417709667\n",
            "Batch 2980 of 6492. Elapsed 0:14:43\n",
            "Sample: 0.814448893070221 v/s 0.8705099821090698 v/s 0.8990753553587011\n",
            "Batch 2990 of 6492. Elapsed 0:14:46\n",
            "Sample: 0.8095999360084534 v/s 0.8212552666664124 v/s 0.8708362276123519\n",
            "Batch 3000 of 6492. Elapsed 0:14:49\n",
            "Sample: 0.8709270358085632 v/s 0.8345374464988708 v/s 0.8883169387225107\n",
            "Batch 3010 of 6492. Elapsed 0:14:52\n",
            "Sample: 0.7800611257553101 v/s 0.8401234149932861 v/s 0.8613236106066795\n",
            "Batch 3020 of 6492. Elapsed 0:14:55\n",
            "Sample: 0.8184559345245361 v/s 0.8722753524780273 v/s 0.9098177120819898\n",
            "Batch 3030 of 6492. Elapsed 0:14:58\n",
            "Sample: 0.8025511503219604 v/s 0.8216423392295837 v/s 0.8525022618010021\n",
            "Batch 3040 of 6492. Elapsed 0:15:01\n",
            "Sample: 0.6860843300819397 v/s 0.6583743691444397 v/s 0.7204620165253988\n",
            "Batch 3050 of 6492. Elapsed 0:15:04\n",
            "Sample: 0.8059980273246765 v/s 0.7725629210472107 v/s 0.8197553555992162\n",
            "Batch 3060 of 6492. Elapsed 0:15:07\n",
            "Sample: 0.8380646109580994 v/s 0.8321738243103027 v/s 0.8740133102493479\n",
            "Batch 3070 of 6492. Elapsed 0:15:10\n",
            "Sample: 0.6444013118743896 v/s 0.6816783547401428 v/s 0.7590734546702266\n",
            "Batch 3080 of 6492. Elapsed 0:15:13\n",
            "Sample: 0.860609233379364 v/s 0.8301165103912354 v/s 0.8706224273923783\n",
            "Batch 3090 of 6492. Elapsed 0:15:16\n",
            "Sample: 0.7314943671226501 v/s 0.7436818480491638 v/s 0.8029158492487098\n",
            "Batch 3100 of 6492. Elapsed 0:15:19\n",
            "Sample: 0.7681670188903809 v/s 0.7261666059494019 v/s 0.7846710860314172\n",
            "Batch 3110 of 6492. Elapsed 0:15:21\n",
            "Sample: 0.816072940826416 v/s 0.849904477596283 v/s 0.8761811263579771\n",
            "Batch 3120 of 6492. Elapsed 0:15:24\n",
            "Sample: 0.8305158615112305 v/s 0.8245363831520081 v/s 0.8662400766978052\n",
            "Batch 3130 of 6492. Elapsed 0:15:27\n",
            "Sample: 0.860990583896637 v/s 0.8575462698936462 v/s 0.9027237255742376\n",
            "Batch 3140 of 6492. Elapsed 0:15:30\n",
            "Sample: 0.8187296390533447 v/s 0.854000449180603 v/s 0.877698614892422\n",
            "Batch 3150 of 6492. Elapsed 0:15:33\n",
            "Sample: 0.8700079321861267 v/s 0.8846877217292786 v/s 0.9008736602688823\n",
            "Batch 3160 of 6492. Elapsed 0:15:36\n",
            "Sample: 0.762204110622406 v/s 0.7276953458786011 v/s 0.7780791648265117\n",
            "Batch 3170 of 6492. Elapsed 0:15:39\n",
            "Sample: 0.8131730556488037 v/s 0.8484840393066406 v/s 0.8773188308451677\n",
            "Batch 3180 of 6492. Elapsed 0:15:42\n",
            "Sample: 0.7525726556777954 v/s 0.7730411887168884 v/s 0.8324980158300246\n",
            "Batch 3190 of 6492. Elapsed 0:15:45\n",
            "Sample: 0.7071695327758789 v/s 0.7366406917572021 v/s 0.7904494196499626\n",
            "Batch 3200 of 6492. Elapsed 0:15:48\n",
            "Sample: 0.8092352747917175 v/s 0.8463202714920044 v/s 0.8855885192372842\n",
            "Batch 3210 of 6492. Elapsed 0:15:51\n",
            "Sample: 0.8133789300918579 v/s 0.7869113683700562 v/s 0.8244638407703365\n",
            "Batch 3220 of 6492. Elapsed 0:15:54\n",
            "Sample: 0.740250289440155 v/s 0.6859545707702637 v/s 0.7749899773128445\n",
            "Batch 3230 of 6492. Elapsed 0:15:57\n",
            "Sample: 0.8056227564811707 v/s 0.7741941213607788 v/s 0.8400511803983287\n",
            "Batch 3240 of 6492. Elapsed 0:16:00\n",
            "Sample: 0.7854567170143127 v/s 0.7514774203300476 v/s 0.7977371258307212\n",
            "Batch 3250 of 6492. Elapsed 0:16:03\n",
            "Sample: 0.880684494972229 v/s 0.8797340989112854 v/s 0.927175434396278\n",
            "Batch 3260 of 6492. Elapsed 0:16:06\n",
            "Sample: 0.8459653854370117 v/s 0.9119850397109985 v/s 0.9290625425366242\n",
            "Batch 3270 of 6492. Elapsed 0:16:09\n",
            "Sample: 0.8127135038375854 v/s 0.8207089900970459 v/s 0.8648675379920231\n",
            "Batch 3280 of 6492. Elapsed 0:16:12\n",
            "Sample: 0.819607138633728 v/s 0.8182939887046814 v/s 0.8560614030234924\n",
            "Batch 3290 of 6492. Elapsed 0:16:14\n",
            "Sample: 0.8115090727806091 v/s 0.8330062627792358 v/s 0.8691486933586536\n",
            "Batch 3300 of 6492. Elapsed 0:16:17\n",
            "Sample: 0.8404825329780579 v/s 0.8125218749046326 v/s 0.8623473620219702\n",
            "Batch 3310 of 6492. Elapsed 0:16:20\n",
            "Sample: 0.8008807897567749 v/s 0.7492278218269348 v/s 0.7930714444070722\n",
            "Batch 3320 of 6492. Elapsed 0:16:23\n",
            "Sample: 0.8541892170906067 v/s 0.8931716084480286 v/s 0.930318057406523\n",
            "Batch 3330 of 6492. Elapsed 0:16:26\n",
            "Sample: 0.7997297644615173 v/s 0.8604778051376343 v/s 0.8869280295689412\n",
            "Batch 3340 of 6492. Elapsed 0:16:29\n",
            "Sample: 0.7752717137336731 v/s 0.8139854669570923 v/s 0.8734482764732407\n",
            "Batch 3350 of 6492. Elapsed 0:16:32\n",
            "Sample: 0.7581547498703003 v/s 0.7583136558532715 v/s 0.7930030972121188\n",
            "Batch 3360 of 6492. Elapsed 0:16:35\n",
            "Sample: 0.8380548357963562 v/s 0.8632558584213257 v/s 0.8856335259454058\n",
            "Batch 3370 of 6492. Elapsed 0:16:38\n",
            "Sample: 0.6895001530647278 v/s 0.6792864799499512 v/s 0.7507370829836862\n",
            "Batch 3380 of 6492. Elapsed 0:16:41\n",
            "Sample: 0.884141743183136 v/s 0.8789598941802979 v/s 0.9003249206194986\n",
            "Batch 3390 of 6492. Elapsed 0:16:44\n",
            "Sample: 0.8155735731124878 v/s 0.9159522652626038 v/s 0.9328877271521472\n",
            "Batch 3400 of 6492. Elapsed 0:16:47\n",
            "Sample: 0.8605154156684875 v/s 0.934954822063446 v/s 0.9596997721094143\n",
            "Batch 3410 of 6492. Elapsed 0:16:50\n",
            "Sample: 0.8150014877319336 v/s 0.7908635139465332 v/s 0.8579350917472304\n",
            "Batch 3420 of 6492. Elapsed 0:16:53\n",
            "Sample: 0.8137537837028503 v/s 0.8243506550788879 v/s 0.8693859550589067\n",
            "Batch 3430 of 6492. Elapsed 0:16:56\n",
            "Sample: 0.8307099342346191 v/s 0.7867270708084106 v/s 0.8406084322598277\n",
            "Batch 3440 of 6492. Elapsed 0:16:58\n",
            "Sample: 0.8172815442085266 v/s 0.7633596658706665 v/s 0.7901319526232039\n",
            "Batch 3450 of 6492. Elapsed 0:17:02\n",
            "Sample: 0.8261748552322388 v/s 0.8758759498596191 v/s 0.8930523638821964\n",
            "Batch 3460 of 6492. Elapsed 0:17:04\n",
            "Sample: 0.7408181428909302 v/s 0.7327727675437927 v/s 0.8029250983570763\n",
            "Batch 3470 of 6492. Elapsed 0:17:07\n",
            "Sample: 0.775888979434967 v/s 0.7309927940368652 v/s 0.788024769848497\n",
            "Batch 3480 of 6492. Elapsed 0:17:10\n",
            "Sample: 0.836503267288208 v/s 0.861344575881958 v/s 0.8862452955104965\n",
            "Batch 3490 of 6492. Elapsed 0:17:13\n",
            "Sample: 0.7805538177490234 v/s 0.7907966375350952 v/s 0.8542658852421645\n",
            "Batch 3500 of 6492. Elapsed 0:17:16\n",
            "Sample: 0.8154381513595581 v/s 0.8017168641090393 v/s 0.8453540684500435\n",
            "Batch 3510 of 6492. Elapsed 0:17:19\n",
            "Sample: 0.7765132188796997 v/s 0.7694879770278931 v/s 0.8265982053815427\n",
            "Batch 3520 of 6492. Elapsed 0:17:22\n",
            "Sample: 0.7730265855789185 v/s 0.7947614789009094 v/s 0.8300687248685875\n",
            "Batch 3530 of 6492. Elapsed 0:17:25\n",
            "Sample: 0.7847834825515747 v/s 0.8003813624382019 v/s 0.8342104285572765\n",
            "Batch 3540 of 6492. Elapsed 0:17:28\n",
            "Sample: 0.7980275750160217 v/s 0.7863866090774536 v/s 0.8198868434165849\n",
            "Batch 3550 of 6492. Elapsed 0:17:31\n",
            "Sample: 0.7834503054618835 v/s 0.7389957904815674 v/s 0.8129827033753653\n",
            "Batch 3560 of 6492. Elapsed 0:17:34\n",
            "Sample: 0.839645266532898 v/s 0.8350277543067932 v/s 0.8833108381963133\n",
            "Batch 3570 of 6492. Elapsed 0:17:37\n",
            "Sample: 0.7530234456062317 v/s 0.6618135571479797 v/s 0.7671689486187786\n",
            "Batch 3580 of 6492. Elapsed 0:17:40\n",
            "Sample: 0.7346174716949463 v/s 0.721397340297699 v/s 0.7772119912939117\n",
            "Batch 3590 of 6492. Elapsed 0:17:43\n",
            "Sample: 0.8643715977668762 v/s 0.8816571831703186 v/s 0.9135650073473968\n",
            "Batch 3600 of 6492. Elapsed 0:17:46\n",
            "Sample: 0.8204339146614075 v/s 0.7799118757247925 v/s 0.8513550572269838\n",
            "Batch 3610 of 6492. Elapsed 0:17:49\n",
            "Sample: 0.8098307847976685 v/s 0.8593223690986633 v/s 0.8894053138577925\n",
            "Batch 3620 of 6492. Elapsed 0:17:52\n",
            "Sample: 0.783655047416687 v/s 0.7740506529808044 v/s 0.8193111310090933\n",
            "Batch 3630 of 6492. Elapsed 0:17:55\n",
            "Sample: 0.8132389783859253 v/s 0.7957658767700195 v/s 0.8254667429493533\n",
            "Batch 3640 of 6492. Elapsed 0:17:58\n",
            "Sample: 0.7835825681686401 v/s 0.8423123955726624 v/s 0.8858074252049947\n",
            "Batch 3650 of 6492. Elapsed 0:18:01\n",
            "Sample: 0.7981221675872803 v/s 0.8020915985107422 v/s 0.8395682570982197\n",
            "Batch 3660 of 6492. Elapsed 0:18:04\n",
            "Sample: 0.8966478705406189 v/s 0.8860230445861816 v/s 0.9190532625900678\n",
            "Batch 3670 of 6492. Elapsed 0:18:07\n",
            "Sample: 0.7927848100662231 v/s 0.7442561388015747 v/s 0.7983289485378409\n",
            "Batch 3680 of 6492. Elapsed 0:18:10\n",
            "Sample: 0.8982762098312378 v/s 0.9280932545661926 v/s 0.9441717100172976\n",
            "Batch 3690 of 6492. Elapsed 0:18:13\n",
            "Sample: 0.8168969750404358 v/s 0.7732875347137451 v/s 0.8521458867566313\n",
            "Batch 3700 of 6492. Elapsed 0:18:16\n",
            "Sample: 0.8280101418495178 v/s 0.9053527116775513 v/s 0.9233540540595471\n",
            "Batch 3710 of 6492. Elapsed 0:18:19\n",
            "Sample: 0.8796341419219971 v/s 0.9201195240020752 v/s 0.9378712203681432\n",
            "Batch 3720 of 6492. Elapsed 0:18:22\n",
            "Sample: 0.8323609232902527 v/s 0.8231865763664246 v/s 0.8933856569064479\n",
            "Batch 3730 of 6492. Elapsed 0:18:25\n",
            "Sample: 0.7772502899169922 v/s 0.6895621418952942 v/s 0.7735501929093908\n",
            "Batch 3740 of 6492. Elapsed 0:18:28\n",
            "Sample: 0.8179494142532349 v/s 0.8605271577835083 v/s 0.8950770801949433\n",
            "Batch 3750 of 6492. Elapsed 0:18:31\n",
            "Sample: 0.8249018788337708 v/s 0.8428463339805603 v/s 0.8808815645482275\n",
            "Batch 3760 of 6492. Elapsed 0:18:34\n",
            "Sample: 0.86650151014328 v/s 0.9460605978965759 v/s 0.9633833501474234\n",
            "Batch 3770 of 6492. Elapsed 0:18:37\n",
            "Sample: 0.8641690015792847 v/s 0.810592532157898 v/s 0.8722915562039838\n",
            "Batch 3780 of 6492. Elapsed 0:18:40\n",
            "Sample: 0.7748067378997803 v/s 0.7836247682571411 v/s 0.8348918174973079\n",
            "Batch 3790 of 6492. Elapsed 0:18:43\n",
            "Sample: 0.6471163034439087 v/s 0.6930655241012573 v/s 0.7793693301373597\n",
            "Batch 3800 of 6492. Elapsed 0:18:46\n",
            "Sample: 0.7470094561576843 v/s 0.7531647086143494 v/s 0.7833684959397849\n",
            "Batch 3810 of 6492. Elapsed 0:18:49\n",
            "Sample: 0.828801691532135 v/s 0.7600986361503601 v/s 0.7915492961506381\n",
            "Batch 3820 of 6492. Elapsed 0:18:52\n",
            "Sample: 0.7954579591751099 v/s 0.7538925409317017 v/s 0.7988940920580565\n",
            "Batch 3830 of 6492. Elapsed 0:18:54\n",
            "Sample: 0.7460299730300903 v/s 0.712678849697113 v/s 0.7798028927412375\n",
            "Batch 3840 of 6492. Elapsed 0:18:57\n",
            "Sample: 0.8583284616470337 v/s 0.8773400783538818 v/s 0.8982581134138752\n",
            "Batch 3850 of 6492. Elapsed 0:19:01\n",
            "Sample: 0.7950043678283691 v/s 0.8074195981025696 v/s 0.8566709115016581\n",
            "Batch 3860 of 6492. Elapsed 0:19:04\n",
            "Sample: 0.8258084058761597 v/s 0.8123200535774231 v/s 0.8325266447186375\n",
            "Batch 3870 of 6492. Elapsed 0:19:07\n",
            "Sample: 0.7872542142868042 v/s 0.7579406499862671 v/s 0.8478756349708476\n",
            "Batch 3880 of 6492. Elapsed 0:19:10\n",
            "Sample: 0.7419634461402893 v/s 0.7730892300605774 v/s 0.8223287095696067\n",
            "Batch 3890 of 6492. Elapsed 0:19:13\n",
            "Sample: 0.8862574696540833 v/s 0.9793688654899597 v/s 0.9651511826765379\n",
            "Batch 3900 of 6492. Elapsed 0:19:16\n",
            "Sample: 0.8745428323745728 v/s 0.8736391067504883 v/s 0.8896734326157482\n",
            "Batch 3910 of 6492. Elapsed 0:19:18\n",
            "Sample: 0.7343078255653381 v/s 0.7249901294708252 v/s 0.7928212163169109\n",
            "Batch 3920 of 6492. Elapsed 0:19:21\n",
            "Sample: 0.8699822425842285 v/s 0.8488584160804749 v/s 0.8669175943938161\n",
            "Batch 3930 of 6492. Elapsed 0:19:24\n",
            "Sample: 0.7678627371788025 v/s 0.7360623478889465 v/s 0.8011124403426074\n",
            "Batch 3940 of 6492. Elapsed 0:19:27\n",
            "Sample: 0.7864630222320557 v/s 0.7746305465698242 v/s 0.8581709911248957\n",
            "Batch 3950 of 6492. Elapsed 0:19:30\n",
            "Sample: 0.8006893992424011 v/s 0.8704458475112915 v/s 0.8938434768956011\n",
            "Batch 3960 of 6492. Elapsed 0:19:33\n",
            "Sample: 0.7549983859062195 v/s 0.7492504715919495 v/s 0.7902474972034912\n",
            "Batch 3970 of 6492. Elapsed 0:19:36\n",
            "Sample: 0.8234111070632935 v/s 0.8699949383735657 v/s 0.8906421039706983\n",
            "Batch 3980 of 6492. Elapsed 0:19:39\n",
            "Sample: 0.8236588835716248 v/s 0.7784824967384338 v/s 0.8366470116255587\n",
            "Batch 3990 of 6492. Elapsed 0:19:42\n",
            "Sample: 0.8729469180107117 v/s 0.8790267109870911 v/s 0.9056093712672377\n",
            "Batch 4000 of 6492. Elapsed 0:19:45\n",
            "Sample: 0.7598994970321655 v/s 0.6730461716651917 v/s 0.7761937972318838\n",
            "Batch 4010 of 6492. Elapsed 0:19:48\n",
            "Sample: 0.7777155041694641 v/s 0.6575576066970825 v/s 0.7326097758783348\n",
            "Batch 4020 of 6492. Elapsed 0:19:51\n",
            "Sample: 0.8373000025749207 v/s 0.8289787769317627 v/s 0.8505875445542163\n",
            "Batch 4030 of 6492. Elapsed 0:19:53\n",
            "Sample: 0.9107577204704285 v/s 0.9934963583946228 v/s 0.9922886369603076\n",
            "Batch 4040 of 6492. Elapsed 0:19:56\n",
            "Sample: 0.8411007523536682 v/s 0.9120658040046692 v/s 0.9274751328912869\n",
            "Batch 4050 of 6492. Elapsed 0:19:59\n",
            "Sample: 0.8114127516746521 v/s 0.7998112440109253 v/s 0.8302451749225627\n",
            "Batch 4060 of 6492. Elapsed 0:20:02\n",
            "Sample: 0.7886831164360046 v/s 0.7739779353141785 v/s 0.809642791596223\n",
            "Batch 4070 of 6492. Elapsed 0:20:05\n",
            "Sample: 0.8070847392082214 v/s 0.799156904220581 v/s 0.8577314388093324\n",
            "Batch 4080 of 6492. Elapsed 0:20:08\n",
            "Sample: 0.9356912970542908 v/s 0.9431779980659485 v/s 0.9586418445369542\n",
            "Batch 4090 of 6492. Elapsed 0:20:11\n",
            "Sample: 0.8129311203956604 v/s 0.8442042469978333 v/s 0.8829611360809743\n",
            "Batch 4100 of 6492. Elapsed 0:20:14\n",
            "Sample: 0.8532607555389404 v/s 0.8908110857009888 v/s 0.9209441620732396\n",
            "Batch 4110 of 6492. Elapsed 0:20:17\n",
            "Sample: 0.8825598955154419 v/s 0.8535494804382324 v/s 0.877238807558934\n",
            "Batch 4120 of 6492. Elapsed 0:20:20\n",
            "Sample: 0.7318223714828491 v/s 0.7657433152198792 v/s 0.8059150982428496\n",
            "Batch 4130 of 6492. Elapsed 0:20:23\n",
            "Sample: 0.799506664276123 v/s 0.8093857765197754 v/s 0.8422748136855852\n",
            "Batch 4140 of 6492. Elapsed 0:20:26\n",
            "Sample: 0.7841514945030212 v/s 0.7449593544006348 v/s 0.8001875878964946\n",
            "Batch 4150 of 6492. Elapsed 0:20:29\n",
            "Sample: 0.8372045755386353 v/s 0.8870480060577393 v/s 0.9046610524543127\n",
            "Batch 4160 of 6492. Elapsed 0:20:32\n",
            "Sample: 0.8217770457267761 v/s 0.8505991697311401 v/s 0.8937240315586313\n",
            "Batch 4170 of 6492. Elapsed 0:20:35\n",
            "Sample: 0.8426549434661865 v/s 0.7608200311660767 v/s 0.8309354371449874\n",
            "Batch 4180 of 6492. Elapsed 0:20:38\n",
            "Sample: 0.8161653876304626 v/s 0.7917239665985107 v/s 0.8161240035105469\n",
            "Batch 4190 of 6492. Elapsed 0:20:41\n",
            "Sample: 0.8181750178337097 v/s 0.7071859240531921 v/s 0.7989616062757873\n",
            "Batch 4200 of 6492. Elapsed 0:20:44\n",
            "Sample: 0.8436405062675476 v/s 0.8599685430526733 v/s 0.8902991790188498\n",
            "Batch 4210 of 6492. Elapsed 0:20:47\n",
            "Sample: 0.7937846779823303 v/s 0.8118581771850586 v/s 0.845766860584411\n",
            "Batch 4220 of 6492. Elapsed 0:20:50\n",
            "Sample: 0.8417311310768127 v/s 0.8427760601043701 v/s 0.8628707540636082\n",
            "Batch 4230 of 6492. Elapsed 0:20:53\n",
            "Sample: 0.8135812878608704 v/s 0.7761351466178894 v/s 0.8337282935208125\n",
            "Batch 4240 of 6492. Elapsed 0:20:56\n",
            "Sample: 0.7630923390388489 v/s 0.860209047794342 v/s 0.8841768372945819\n",
            "Batch 4250 of 6492. Elapsed 0:20:59\n",
            "Sample: 0.6401807069778442 v/s 0.6652007102966309 v/s 0.7680792289996976\n",
            "Batch 4260 of 6492. Elapsed 0:21:02\n",
            "Sample: 0.8604947328567505 v/s 0.8260713219642639 v/s 0.8483578124186073\n",
            "Batch 4270 of 6492. Elapsed 0:21:05\n",
            "Sample: 0.7762778997421265 v/s 0.774867594242096 v/s 0.831504653061346\n",
            "Batch 4280 of 6492. Elapsed 0:21:08\n",
            "Sample: 0.7807328701019287 v/s 0.7348848581314087 v/s 0.7942162058293316\n",
            "Batch 4290 of 6492. Elapsed 0:21:11\n",
            "Sample: 0.8786686062812805 v/s 0.8851144909858704 v/s 0.9242629050755191\n",
            "Batch 4300 of 6492. Elapsed 0:21:14\n",
            "Sample: 0.8564608097076416 v/s 0.8565720915794373 v/s 0.9150157711433304\n",
            "Batch 4310 of 6492. Elapsed 0:21:17\n",
            "Sample: 0.8870425820350647 v/s 0.8526300191879272 v/s 0.9056488779660984\n",
            "Batch 4320 of 6492. Elapsed 0:21:20\n",
            "Sample: 0.8181592226028442 v/s 0.7954870462417603 v/s 0.8370483761094096\n",
            "Batch 4330 of 6492. Elapsed 0:21:23\n",
            "Sample: 0.7623132467269897 v/s 0.76602703332901 v/s 0.8156302266802552\n",
            "Batch 4340 of 6492. Elapsed 0:21:26\n",
            "Sample: 0.7729931473731995 v/s 0.6888387799263 v/s 0.737323850723702\n",
            "Batch 4350 of 6492. Elapsed 0:21:29\n",
            "Sample: 0.8032158613204956 v/s 0.7945186495780945 v/s 0.8544037490969469\n",
            "Batch 4360 of 6492. Elapsed 0:21:31\n",
            "Sample: 0.7870848178863525 v/s 0.779600203037262 v/s 0.8378543166774884\n",
            "Batch 4370 of 6492. Elapsed 0:21:34\n",
            "Sample: 0.8725502490997314 v/s 0.8289819359779358 v/s 0.8932349048495576\n",
            "Batch 4380 of 6492. Elapsed 0:21:37\n",
            "Sample: 0.81766676902771 v/s 0.8570497632026672 v/s 0.8867989817510827\n",
            "Batch 4390 of 6492. Elapsed 0:21:40\n",
            "Sample: 0.8654801845550537 v/s 0.8114495277404785 v/s 0.861022090513169\n",
            "Batch 4400 of 6492. Elapsed 0:21:43\n",
            "Sample: 0.8452692031860352 v/s 0.9158377051353455 v/s 0.9483593362801958\n",
            "Batch 4410 of 6492. Elapsed 0:21:46\n",
            "Sample: 0.7988105416297913 v/s 0.8238428235054016 v/s 0.8545345653331808\n",
            "Batch 4420 of 6492. Elapsed 0:21:49\n",
            "Sample: 0.8285852074623108 v/s 0.8712787628173828 v/s 0.9063126049997952\n",
            "Batch 4430 of 6492. Elapsed 0:21:52\n",
            "Sample: 0.7911289930343628 v/s 0.7400325536727905 v/s 0.7859443668523247\n",
            "Batch 4440 of 6492. Elapsed 0:21:55\n",
            "Sample: 0.7806326150894165 v/s 0.8602201342582703 v/s 0.8894334283254964\n",
            "Batch 4450 of 6492. Elapsed 0:21:58\n",
            "Sample: 0.7983590960502625 v/s 0.7781563997268677 v/s 0.8537598860645684\n",
            "Batch 4460 of 6492. Elapsed 0:22:01\n",
            "Sample: 0.8406206965446472 v/s 0.8743889331817627 v/s 0.8991554117922093\n",
            "Batch 4470 of 6492. Elapsed 0:22:04\n",
            "Sample: 0.7630738615989685 v/s 0.8213018178939819 v/s 0.8593789485969208\n",
            "Batch 4480 of 6492. Elapsed 0:22:07\n",
            "Sample: 0.8164276480674744 v/s 0.833694338798523 v/s 0.8799462328900145\n",
            "Batch 4490 of 6492. Elapsed 0:22:10\n",
            "Sample: 0.7389347553253174 v/s 0.7105038166046143 v/s 0.7832541174187392\n",
            "Batch 4500 of 6492. Elapsed 0:22:13\n",
            "Sample: 0.9045852422714233 v/s 0.969356119632721 v/s 0.976158737894502\n",
            "Batch 4510 of 6492. Elapsed 0:22:16\n",
            "Sample: 0.8268570899963379 v/s 0.8069857954978943 v/s 0.8593203456299007\n",
            "Batch 4520 of 6492. Elapsed 0:22:19\n",
            "Sample: 0.7820611000061035 v/s 0.7836658358573914 v/s 0.8151634215993965\n",
            "Batch 4530 of 6492. Elapsed 0:22:22\n",
            "Sample: 0.8158465027809143 v/s 0.8595187067985535 v/s 0.8911385995153274\n",
            "Batch 4540 of 6492. Elapsed 0:22:25\n",
            "Sample: 0.8103906512260437 v/s 0.7975305914878845 v/s 0.844576664639505\n",
            "Batch 4550 of 6492. Elapsed 0:22:28\n",
            "Sample: 0.8181594014167786 v/s 0.847038209438324 v/s 0.8854782153114252\n",
            "Batch 4560 of 6492. Elapsed 0:22:30\n",
            "Sample: 0.8782650232315063 v/s 0.8993321657180786 v/s 0.9231720834361458\n",
            "Batch 4570 of 6492. Elapsed 0:22:33\n",
            "Sample: 0.834162712097168 v/s 0.8552685976028442 v/s 0.8774905121283826\n",
            "Batch 4580 of 6492. Elapsed 0:22:36\n",
            "Sample: 0.7627643942832947 v/s 0.7449930310249329 v/s 0.8385399740317391\n",
            "Batch 4590 of 6492. Elapsed 0:22:39\n",
            "Sample: 0.7733038067817688 v/s 0.7671677470207214 v/s 0.8086540429386823\n",
            "Batch 4600 of 6492. Elapsed 0:22:42\n",
            "Sample: 0.861466109752655 v/s 0.8624492287635803 v/s 0.8817758075170256\n",
            "Batch 4610 of 6492. Elapsed 0:22:45\n",
            "Sample: 0.7707147002220154 v/s 0.7596336007118225 v/s 0.8121016997734408\n",
            "Batch 4620 of 6492. Elapsed 0:22:48\n",
            "Sample: 0.720889151096344 v/s 0.673987865447998 v/s 0.7331237284297746\n",
            "Batch 4630 of 6492. Elapsed 0:22:51\n",
            "Sample: 0.8220584988594055 v/s 0.8728627562522888 v/s 0.9048384110040762\n",
            "Batch 4640 of 6492. Elapsed 0:22:54\n",
            "Sample: 0.8348804116249084 v/s 0.8728575110435486 v/s 0.9002773620405424\n",
            "Batch 4650 of 6492. Elapsed 0:22:57\n",
            "Sample: 0.8829514980316162 v/s 0.8786457180976868 v/s 0.9068303810615868\n",
            "Batch 4660 of 6492. Elapsed 0:23:00\n",
            "Sample: 0.7109163999557495 v/s 0.7132689356803894 v/s 0.7680429085607011\n",
            "Batch 4670 of 6492. Elapsed 0:23:03\n",
            "Sample: 0.7662030458450317 v/s 0.7825184464454651 v/s 0.839051875836105\n",
            "Batch 4680 of 6492. Elapsed 0:23:06\n",
            "Sample: 0.7950950860977173 v/s 0.7536002397537231 v/s 0.8059177252616347\n",
            "Batch 4690 of 6492. Elapsed 0:23:09\n",
            "Sample: 0.8113136291503906 v/s 0.8230303525924683 v/s 0.87828506021432\n",
            "Batch 4700 of 6492. Elapsed 0:23:12\n",
            "Sample: 0.790448009967804 v/s 0.7890167832374573 v/s 0.8308730514414062\n",
            "Batch 4710 of 6492. Elapsed 0:23:15\n",
            "Sample: 0.7916859984397888 v/s 0.8021681904792786 v/s 0.8416435268591631\n",
            "Batch 4720 of 6492. Elapsed 0:23:18\n",
            "Sample: 0.8891916275024414 v/s 0.9405476450920105 v/s 0.9550351116635901\n",
            "Batch 4730 of 6492. Elapsed 0:23:21\n",
            "Sample: 0.7241292595863342 v/s 0.7287933230400085 v/s 0.7969568087226935\n",
            "Batch 4740 of 6492. Elapsed 0:23:23\n",
            "Sample: 0.8816021680831909 v/s 0.8498292565345764 v/s 0.8879619541708054\n",
            "Batch 4750 of 6492. Elapsed 0:23:26\n",
            "Sample: 0.7479733824729919 v/s 0.7912790775299072 v/s 0.8438693800921679\n",
            "Batch 4760 of 6492. Elapsed 0:23:29\n",
            "Sample: 0.839873194694519 v/s 0.8523690104484558 v/s 0.890146436206219\n",
            "Batch 4770 of 6492. Elapsed 0:23:32\n",
            "Sample: 0.8266575336456299 v/s 0.8234788775444031 v/s 0.8698006631141263\n",
            "Batch 4780 of 6492. Elapsed 0:23:35\n",
            "Sample: 0.8407782912254333 v/s 0.8258411884307861 v/s 0.8588356026585916\n",
            "Batch 4790 of 6492. Elapsed 0:23:38\n",
            "Sample: 0.8433148264884949 v/s 0.8423194289207458 v/s 0.8683618539110484\n",
            "Batch 4800 of 6492. Elapsed 0:23:41\n",
            "Sample: 0.8553339242935181 v/s 0.8369876742362976 v/s 0.8919738785968208\n",
            "Batch 4810 of 6492. Elapsed 0:23:44\n",
            "Sample: 0.8639252781867981 v/s 0.8869224786758423 v/s 0.9025957550777541\n",
            "Batch 4820 of 6492. Elapsed 0:23:47\n",
            "Sample: 0.8258231282234192 v/s 0.8353728652000427 v/s 0.8735152971558013\n",
            "Batch 4830 of 6492. Elapsed 0:23:50\n",
            "Sample: 0.8706722259521484 v/s 0.8892366886138916 v/s 0.9144252544304171\n",
            "Batch 4840 of 6492. Elapsed 0:23:53\n",
            "Sample: 0.7857539653778076 v/s 0.8096449375152588 v/s 0.8256112114702208\n",
            "Batch 4850 of 6492. Elapsed 0:23:56\n",
            "Sample: 0.7309895753860474 v/s 0.725448727607727 v/s 0.7778479007751484\n",
            "Batch 4860 of 6492. Elapsed 0:23:59\n",
            "Sample: 0.7802019119262695 v/s 0.7315256595611572 v/s 0.7885501232890684\n",
            "Batch 4870 of 6492. Elapsed 0:24:02\n",
            "Sample: 0.821638822555542 v/s 0.7984204292297363 v/s 0.8425035415620549\n",
            "Batch 4880 of 6492. Elapsed 0:24:05\n",
            "Sample: 0.7952864766120911 v/s 0.7789048552513123 v/s 0.8311110927484062\n",
            "Batch 4890 of 6492. Elapsed 0:24:08\n",
            "Sample: 0.6717714071273804 v/s 0.6953997015953064 v/s 0.7794006424929744\n",
            "Batch 4900 of 6492. Elapsed 0:24:11\n",
            "Sample: 0.7770874500274658 v/s 0.7280986309051514 v/s 0.8003936981522121\n",
            "Batch 4910 of 6492. Elapsed 0:24:14\n",
            "Sample: 0.807172954082489 v/s 0.8215560913085938 v/s 0.8639398799381958\n",
            "Batch 4920 of 6492. Elapsed 0:24:16\n",
            "Sample: 0.8338524103164673 v/s 0.84707111120224 v/s 0.8794931166351331\n",
            "Batch 4930 of 6492. Elapsed 0:24:19\n",
            "Sample: 0.7986083626747131 v/s 0.8546140193939209 v/s 0.885094402412817\n",
            "Batch 4940 of 6492. Elapsed 0:24:22\n",
            "Sample: 0.8754027485847473 v/s 0.842051088809967 v/s 0.8716532160750614\n",
            "Batch 4950 of 6492. Elapsed 0:24:25\n",
            "Sample: 0.7319161891937256 v/s 0.7025526762008667 v/s 0.7702092217717358\n",
            "Batch 4960 of 6492. Elapsed 0:24:28\n",
            "Sample: 0.8601263761520386 v/s 0.8964011669158936 v/s 0.9297477098340249\n",
            "Batch 4970 of 6492. Elapsed 0:24:31\n",
            "Sample: 0.7987152934074402 v/s 0.7388121485710144 v/s 0.8154606307282862\n",
            "Batch 4980 of 6492. Elapsed 0:24:34\n",
            "Sample: 0.8030529618263245 v/s 0.8179360628128052 v/s 0.8544038462503977\n",
            "Batch 4990 of 6492. Elapsed 0:24:37\n",
            "Sample: 0.8601509928703308 v/s 0.8810030817985535 v/s 0.9121904538198075\n",
            "Batch 5000 of 6492. Elapsed 0:24:40\n",
            "Sample: 0.8208265900611877 v/s 0.8250757455825806 v/s 0.844823769881503\n",
            "Batch 5010 of 6492. Elapsed 0:24:43\n",
            "Sample: 0.8095030188560486 v/s 0.7570108771324158 v/s 0.7994506069684731\n",
            "Batch 5020 of 6492. Elapsed 0:24:46\n",
            "Sample: 0.6989542245864868 v/s 0.6702137589454651 v/s 0.7409941727687336\n",
            "Batch 5030 of 6492. Elapsed 0:24:49\n",
            "Sample: 0.8529842495918274 v/s 0.7894718647003174 v/s 0.8622890245672129\n",
            "Batch 5040 of 6492. Elapsed 0:24:52\n",
            "Sample: 0.8063355684280396 v/s 0.7876790165901184 v/s 0.839205564919382\n",
            "Batch 5050 of 6492. Elapsed 0:24:55\n",
            "Sample: 0.7693445086479187 v/s 0.8205238580703735 v/s 0.8696311911297874\n",
            "Batch 5060 of 6492. Elapsed 0:24:58\n",
            "Sample: 0.8288807272911072 v/s 0.8625465631484985 v/s 0.8988405806602903\n",
            "Batch 5070 of 6492. Elapsed 0:25:00\n",
            "Sample: 0.7928265929222107 v/s 0.7495454549789429 v/s 0.7955913903853596\n",
            "Batch 5080 of 6492. Elapsed 0:25:03\n",
            "Sample: 0.7200137376785278 v/s 0.7464841604232788 v/s 0.7875919536144096\n",
            "Batch 5090 of 6492. Elapsed 0:25:06\n",
            "Sample: 0.6695458889007568 v/s 0.6908307671546936 v/s 0.7661236513572696\n",
            "Batch 5100 of 6492. Elapsed 0:25:09\n",
            "Sample: 0.8149858117103577 v/s 0.8405852317810059 v/s 0.863206170073211\n",
            "Batch 5110 of 6492. Elapsed 0:25:12\n",
            "Sample: 0.85979825258255 v/s 0.8505381345748901 v/s 0.8817787578971891\n",
            "Batch 5120 of 6492. Elapsed 0:25:15\n",
            "Sample: 0.811847448348999 v/s 0.8056352138519287 v/s 0.8427694364357582\n",
            "Batch 5130 of 6492. Elapsed 0:25:18\n",
            "Sample: 0.8011067509651184 v/s 0.780717134475708 v/s 0.8263153634409047\n",
            "Batch 5140 of 6492. Elapsed 0:25:21\n",
            "Sample: 0.7423149943351746 v/s 0.7537252902984619 v/s 0.799717551681654\n",
            "Batch 5150 of 6492. Elapsed 0:25:24\n",
            "Sample: 0.7546599507331848 v/s 0.7214502692222595 v/s 0.7876146771249439\n",
            "Batch 5160 of 6492. Elapsed 0:25:27\n",
            "Sample: 0.9212318062782288 v/s 0.9036785364151001 v/s 0.9365826456549787\n",
            "Batch 5170 of 6492. Elapsed 0:25:31\n",
            "Sample: 0.8969774842262268 v/s 0.8774051070213318 v/s 0.9127747162189318\n",
            "Batch 5180 of 6492. Elapsed 0:25:34\n",
            "Sample: 0.8132242560386658 v/s 0.7384253740310669 v/s 0.7939432339353067\n",
            "Batch 5190 of 6492. Elapsed 0:25:37\n",
            "Sample: 0.6737523078918457 v/s 0.7014670968055725 v/s 0.7703076344911164\n",
            "Batch 5200 of 6492. Elapsed 0:25:40\n",
            "Sample: 0.8849066495895386 v/s 0.9556108713150024 v/s 0.9641435135007766\n",
            "Batch 5210 of 6492. Elapsed 0:25:43\n",
            "Sample: 0.82172030210495 v/s 0.8086307644844055 v/s 0.8762869234903832\n",
            "Batch 5220 of 6492. Elapsed 0:25:46\n",
            "Sample: 0.7889658212661743 v/s 0.8127204775810242 v/s 0.8481467074386754\n",
            "Batch 5230 of 6492. Elapsed 0:25:49\n",
            "Sample: 0.7517685890197754 v/s 0.8036805391311646 v/s 0.8611250205259083\n",
            "Batch 5240 of 6492. Elapsed 0:25:52\n",
            "Sample: 0.8664273023605347 v/s 0.8919026851654053 v/s 0.9080597025641652\n",
            "Batch 5250 of 6492. Elapsed 0:25:55\n",
            "Sample: 0.7959145307540894 v/s 0.8064157962799072 v/s 0.8343105435010049\n",
            "Batch 5260 of 6492. Elapsed 0:25:58\n",
            "Sample: 0.8258572816848755 v/s 0.8411577939987183 v/s 0.8701511100592673\n",
            "Batch 5270 of 6492. Elapsed 0:26:01\n",
            "Sample: 0.7034508585929871 v/s 0.7192535996437073 v/s 0.7914814222905164\n",
            "Batch 5280 of 6492. Elapsed 0:26:04\n",
            "Sample: 0.738376259803772 v/s 0.7628273367881775 v/s 0.8123005696189105\n",
            "Batch 5290 of 6492. Elapsed 0:26:06\n",
            "Sample: 0.8662655353546143 v/s 0.865355372428894 v/s 0.9085005447375064\n",
            "Batch 5300 of 6492. Elapsed 0:26:09\n",
            "Sample: 0.8143088221549988 v/s 0.8450176119804382 v/s 0.8685120496937908\n",
            "Batch 5310 of 6492. Elapsed 0:26:12\n",
            "Sample: 0.8119668960571289 v/s 0.7687591910362244 v/s 0.80574349791002\n",
            "Batch 5320 of 6492. Elapsed 0:26:15\n",
            "Sample: 0.83268141746521 v/s 0.8445954918861389 v/s 0.880142735024746\n",
            "Batch 5330 of 6492. Elapsed 0:26:18\n",
            "Sample: 0.8014447093009949 v/s 0.7617464065551758 v/s 0.8277478469751063\n",
            "Batch 5340 of 6492. Elapsed 0:26:21\n",
            "Sample: 0.7742859125137329 v/s 0.7814443111419678 v/s 0.8149496337533857\n",
            "Batch 5350 of 6492. Elapsed 0:26:24\n",
            "Sample: 0.8026790022850037 v/s 0.8120217323303223 v/s 0.853041863035643\n",
            "Batch 5360 of 6492. Elapsed 0:26:27\n",
            "Sample: 0.7704916596412659 v/s 0.7432434558868408 v/s 0.7963389453598423\n",
            "Batch 5370 of 6492. Elapsed 0:26:30\n",
            "Sample: 0.876809298992157 v/s 0.8510781526565552 v/s 0.8891570367838699\n",
            "Batch 5380 of 6492. Elapsed 0:26:33\n",
            "Sample: 0.7112338542938232 v/s 0.6591126918792725 v/s 0.7602064704525132\n",
            "Batch 5390 of 6492. Elapsed 0:26:36\n",
            "Sample: 0.7536969780921936 v/s 0.7759495973587036 v/s 0.8463989001660905\n",
            "Batch 5400 of 6492. Elapsed 0:26:39\n",
            "Sample: 0.8988831043243408 v/s 0.9180567860603333 v/s 0.9328961635707703\n",
            "Batch 5410 of 6492. Elapsed 0:26:42\n",
            "Sample: 0.7244075536727905 v/s 0.7404084801673889 v/s 0.7880282246172443\n",
            "Batch 5420 of 6492. Elapsed 0:26:45\n",
            "Sample: 0.841119110584259 v/s 0.8536465764045715 v/s 0.8908367213629228\n",
            "Batch 5430 of 6492. Elapsed 0:26:48\n",
            "Sample: 0.8504021763801575 v/s 0.8503336906433105 v/s 0.8961293064425034\n",
            "Batch 5440 of 6492. Elapsed 0:26:51\n",
            "Sample: 0.7852300405502319 v/s 0.8387418985366821 v/s 0.8735468737468762\n",
            "Batch 5450 of 6492. Elapsed 0:26:54\n",
            "Sample: 0.8673207759857178 v/s 0.897977888584137 v/s 0.9137849767875855\n",
            "Batch 5460 of 6492. Elapsed 0:26:56\n",
            "Sample: 0.7860046029090881 v/s 0.7933289408683777 v/s 0.8436949142502713\n",
            "Batch 5470 of 6492. Elapsed 0:26:59\n",
            "Sample: 0.8423458933830261 v/s 0.8757308721542358 v/s 0.9010417924435502\n",
            "Batch 5480 of 6492. Elapsed 0:27:02\n",
            "Sample: 0.8551440834999084 v/s 0.8144174814224243 v/s 0.8699148988608185\n",
            "Batch 5490 of 6492. Elapsed 0:27:05\n",
            "Sample: 0.7597671151161194 v/s 0.7012261748313904 v/s 0.7676816251199637\n",
            "Batch 5500 of 6492. Elapsed 0:27:08\n",
            "Sample: 0.8173234462738037 v/s 0.7923084497451782 v/s 0.8229654879189293\n",
            "Batch 5510 of 6492. Elapsed 0:27:11\n",
            "Sample: 0.8045248985290527 v/s 0.8227993249893188 v/s 0.8505784045027227\n",
            "Batch 5520 of 6492. Elapsed 0:27:14\n",
            "Sample: 0.7738670110702515 v/s 0.7809210419654846 v/s 0.8210012426005174\n",
            "Batch 5530 of 6492. Elapsed 0:27:17\n",
            "Sample: 0.75209641456604 v/s 0.794966995716095 v/s 0.8627398855975617\n",
            "Batch 5540 of 6492. Elapsed 0:27:20\n",
            "Sample: 0.823326826095581 v/s 0.8947095274925232 v/s 0.9176558729261721\n",
            "Batch 5550 of 6492. Elapsed 0:27:23\n",
            "Sample: 0.8678303956985474 v/s 0.7843955159187317 v/s 0.8038521912171923\n",
            "Batch 5560 of 6492. Elapsed 0:27:26\n",
            "Sample: 0.7125599384307861 v/s 0.7070799469947815 v/s 0.7957824182888091\n",
            "Batch 5570 of 6492. Elapsed 0:27:29\n",
            "Sample: 0.7082740664482117 v/s 0.6630687117576599 v/s 0.7686092034769028\n",
            "Batch 5580 of 6492. Elapsed 0:27:32\n",
            "Sample: 0.8775556683540344 v/s 0.9416429400444031 v/s 0.9596372946213102\n",
            "Batch 5590 of 6492. Elapsed 0:27:35\n",
            "Sample: 0.8691614270210266 v/s 0.8878535628318787 v/s 0.9226228924174876\n",
            "Batch 5600 of 6492. Elapsed 0:27:38\n",
            "Sample: 0.7991905808448792 v/s 0.816442608833313 v/s 0.8602082438821315\n",
            "Batch 5610 of 6492. Elapsed 0:27:41\n",
            "Sample: 0.8598307967185974 v/s 0.8727197647094727 v/s 0.893291479136819\n",
            "Batch 5620 of 6492. Elapsed 0:27:44\n",
            "Sample: 0.8474346399307251 v/s 0.8517577052116394 v/s 0.8757407344807778\n",
            "Batch 5630 of 6492. Elapsed 0:27:46\n",
            "Sample: 0.7940722703933716 v/s 0.7466992139816284 v/s 0.8027284518386273\n",
            "Batch 5640 of 6492. Elapsed 0:27:50\n",
            "Sample: 0.7260923981666565 v/s 0.7647672295570374 v/s 0.8463081315366455\n",
            "Batch 5650 of 6492. Elapsed 0:27:52\n",
            "Sample: 0.7897260785102844 v/s 0.8308860063552856 v/s 0.8765679949475729\n",
            "Batch 5660 of 6492. Elapsed 0:27:55\n",
            "Sample: 0.9424651265144348 v/s 0.9538206458091736 v/s 0.967214413633567\n",
            "Batch 5670 of 6492. Elapsed 0:27:58\n",
            "Sample: 0.8589519262313843 v/s 0.8732512593269348 v/s 0.9047455687272185\n",
            "Batch 5680 of 6492. Elapsed 0:28:01\n",
            "Sample: 0.7883028984069824 v/s 0.7312983274459839 v/s 0.7799999008069781\n",
            "Batch 5690 of 6492. Elapsed 0:28:04\n",
            "Sample: 0.7277247309684753 v/s 0.6614871025085449 v/s 0.7306389623936671\n",
            "Batch 5700 of 6492. Elapsed 0:28:07\n",
            "Sample: 0.764816403388977 v/s 0.7878974080085754 v/s 0.8401838980760513\n",
            "Batch 5710 of 6492. Elapsed 0:28:10\n",
            "Sample: 0.7565357089042664 v/s 0.8054313063621521 v/s 0.8403756445630471\n",
            "Batch 5720 of 6492. Elapsed 0:28:13\n",
            "Sample: 0.8396183252334595 v/s 0.8515421748161316 v/s 0.8906403013833939\n",
            "Batch 5730 of 6492. Elapsed 0:28:16\n",
            "Sample: 0.7620714902877808 v/s 0.74593186378479 v/s 0.8030969125237997\n",
            "Batch 5740 of 6492. Elapsed 0:28:19\n",
            "Sample: 0.8238090872764587 v/s 0.7857217788696289 v/s 0.854987874082391\n",
            "Batch 5750 of 6492. Elapsed 0:28:22\n",
            "Sample: 0.7402509450912476 v/s 0.7177231311798096 v/s 0.7625949828124815\n",
            "Batch 5760 of 6492. Elapsed 0:28:25\n",
            "Sample: 0.8137884140014648 v/s 0.8300749063491821 v/s 0.8623819802791757\n",
            "Batch 5770 of 6492. Elapsed 0:28:28\n",
            "Sample: 0.797607421875 v/s 0.8229431509971619 v/s 0.8633112422483152\n",
            "Batch 5780 of 6492. Elapsed 0:28:31\n",
            "Sample: 0.7400341033935547 v/s 0.7739425897598267 v/s 0.8162197130904753\n",
            "Batch 5790 of 6492. Elapsed 0:28:34\n",
            "Sample: 0.8068380355834961 v/s 0.8104106783866882 v/s 0.8409647868716496\n",
            "Batch 5800 of 6492. Elapsed 0:28:37\n",
            "Sample: 0.8225016593933105 v/s 0.7932597398757935 v/s 0.829754008584864\n",
            "Batch 5810 of 6492. Elapsed 0:28:40\n",
            "Sample: 0.8447942733764648 v/s 0.8357223868370056 v/s 0.8527600198264549\n",
            "Batch 5820 of 6492. Elapsed 0:28:43\n",
            "Sample: 0.7554661631584167 v/s 0.7957951426506042 v/s 0.849137384509486\n",
            "Batch 5830 of 6492. Elapsed 0:28:46\n",
            "Sample: 0.8027082085609436 v/s 0.7826110124588013 v/s 0.8549791137320426\n",
            "Batch 5840 of 6492. Elapsed 0:28:49\n",
            "Sample: 0.6927008032798767 v/s 0.7151839137077332 v/s 0.7772009196997243\n",
            "Batch 5850 of 6492. Elapsed 0:28:52\n",
            "Sample: 0.8221109509468079 v/s 0.8659803867340088 v/s 0.9073000056000606\n",
            "Batch 5860 of 6492. Elapsed 0:28:55\n",
            "Sample: 0.7704917788505554 v/s 0.7614641189575195 v/s 0.8080506893960199\n",
            "Batch 5870 of 6492. Elapsed 0:28:58\n",
            "Sample: 0.7399659752845764 v/s 0.8084096908569336 v/s 0.8403128600622665\n",
            "Batch 5880 of 6492. Elapsed 0:29:01\n",
            "Sample: 0.8494131565093994 v/s 0.8210652470588684 v/s 0.8795477971784893\n",
            "Batch 5890 of 6492. Elapsed 0:29:04\n",
            "Sample: 0.8081693649291992 v/s 0.8339164853096008 v/s 0.8740188886647827\n",
            "Batch 5900 of 6492. Elapsed 0:29:07\n",
            "Sample: 0.8053585290908813 v/s 0.7852190136909485 v/s 0.8232884653809365\n",
            "Batch 5910 of 6492. Elapsed 0:29:10\n",
            "Sample: 0.8020526766777039 v/s 0.7809182405471802 v/s 0.8083917120312757\n",
            "Batch 5920 of 6492. Elapsed 0:29:13\n",
            "Sample: 0.867537260055542 v/s 0.8467552065849304 v/s 0.8974499687020562\n",
            "Batch 5930 of 6492. Elapsed 0:29:16\n",
            "Sample: 0.8139343857765198 v/s 0.7494871616363525 v/s 0.7920409063374312\n",
            "Batch 5940 of 6492. Elapsed 0:29:19\n",
            "Sample: 0.7972350120544434 v/s 0.8317389488220215 v/s 0.8609706632413685\n",
            "Batch 5950 of 6492. Elapsed 0:29:22\n",
            "Sample: 0.7365231513977051 v/s 0.6735237836837769 v/s 0.7553390669332303\n",
            "Batch 5960 of 6492. Elapsed 0:29:25\n",
            "Sample: 0.8501723408699036 v/s 0.9047487378120422 v/s 0.9311783798534995\n",
            "Batch 5970 of 6492. Elapsed 0:29:28\n",
            "Sample: 0.770234227180481 v/s 0.7062423229217529 v/s 0.7522541014218611\n",
            "Batch 5980 of 6492. Elapsed 0:29:31\n",
            "Sample: 0.8255146741867065 v/s 0.8217145800590515 v/s 0.8563590892621527\n",
            "Batch 5990 of 6492. Elapsed 0:29:34\n",
            "Sample: 0.7968052625656128 v/s 0.8214897513389587 v/s 0.8546471819267836\n",
            "Batch 6000 of 6492. Elapsed 0:29:37\n",
            "Sample: 0.8504152297973633 v/s 0.8009964227676392 v/s 0.8300312628369597\n",
            "Batch 6010 of 6492. Elapsed 0:29:40\n",
            "Sample: 0.7877447605133057 v/s 0.7831759452819824 v/s 0.8278617934982804\n",
            "Batch 6020 of 6492. Elapsed 0:29:43\n",
            "Sample: 0.7711189985275269 v/s 0.7690826058387756 v/s 0.8194221747942473\n",
            "Batch 6030 of 6492. Elapsed 0:29:46\n",
            "Sample: 0.8108533620834351 v/s 0.7700961232185364 v/s 0.8058617607551346\n",
            "Batch 6040 of 6492. Elapsed 0:29:49\n",
            "Sample: 0.7493752241134644 v/s 0.6604981422424316 v/s 0.7545474213482118\n",
            "Batch 6050 of 6492. Elapsed 0:29:51\n",
            "Sample: 0.7817252278327942 v/s 0.7580174803733826 v/s 0.7980412338086789\n",
            "Batch 6060 of 6492. Elapsed 0:29:54\n",
            "Sample: 0.8972930908203125 v/s 0.9628509283065796 v/s 0.9729703360051626\n",
            "Batch 6070 of 6492. Elapsed 0:29:57\n",
            "Sample: 0.7443527579307556 v/s 0.7201026082038879 v/s 0.7726798890272818\n",
            "Batch 6080 of 6492. Elapsed 0:30:00\n",
            "Sample: 0.8006314635276794 v/s 0.7587776184082031 v/s 0.7925323821118392\n",
            "Batch 6090 of 6492. Elapsed 0:30:03\n",
            "Sample: 0.7777324914932251 v/s 0.7652384638786316 v/s 0.8129158370470747\n",
            "Batch 6100 of 6492. Elapsed 0:30:06\n",
            "Sample: 0.8875259757041931 v/s 0.8885676264762878 v/s 0.9152551312008301\n",
            "Batch 6110 of 6492. Elapsed 0:30:09\n",
            "Sample: 0.868293046951294 v/s 0.8031986951828003 v/s 0.8747025939231986\n",
            "Batch 6120 of 6492. Elapsed 0:30:12\n",
            "Sample: 0.8126941323280334 v/s 0.860614001750946 v/s 0.8939669400390001\n",
            "Batch 6130 of 6492. Elapsed 0:30:15\n",
            "Sample: 0.8620949387550354 v/s 0.8459859490394592 v/s 0.8765318807748824\n",
            "Batch 6140 of 6492. Elapsed 0:30:18\n",
            "Sample: 0.7850939631462097 v/s 0.7878636121749878 v/s 0.8351473373747168\n",
            "Batch 6150 of 6492. Elapsed 0:30:21\n",
            "Sample: 0.8696781992912292 v/s 0.8800821304321289 v/s 0.9084094846780096\n",
            "Batch 6160 of 6492. Elapsed 0:30:24\n",
            "Sample: 0.6781234741210938 v/s 0.720740020275116 v/s 0.7735646680400817\n",
            "Batch 6170 of 6492. Elapsed 0:30:27\n",
            "Sample: 0.8313347101211548 v/s 0.8815795183181763 v/s 0.9101750415963815\n",
            "Batch 6180 of 6492. Elapsed 0:30:30\n",
            "Sample: 0.8608991503715515 v/s 0.8367832899093628 v/s 0.853920769159268\n",
            "Batch 6190 of 6492. Elapsed 0:30:33\n",
            "Sample: 0.7989994883537292 v/s 0.7926056981086731 v/s 0.8468101170490082\n",
            "Batch 6200 of 6492. Elapsed 0:30:36\n",
            "Sample: 0.8265262246131897 v/s 0.8486404418945312 v/s 0.8778637364432121\n",
            "Batch 6210 of 6492. Elapsed 0:30:39\n",
            "Sample: 0.8391123414039612 v/s 0.8027175664901733 v/s 0.8701875920046075\n",
            "Batch 6220 of 6492. Elapsed 0:30:42\n",
            "Sample: 0.7980167865753174 v/s 0.7741261720657349 v/s 0.8128847693792325\n",
            "Batch 6230 of 6492. Elapsed 0:30:45\n",
            "Sample: 0.7982783317565918 v/s 0.7991284728050232 v/s 0.8335873558234062\n",
            "Batch 6240 of 6492. Elapsed 0:30:48\n",
            "Sample: 0.7885515093803406 v/s 0.8269394636154175 v/s 0.8541145957297014\n",
            "Batch 6250 of 6492. Elapsed 0:30:51\n",
            "Sample: 0.7870846390724182 v/s 0.8013067841529846 v/s 0.8522074877741606\n",
            "Batch 6260 of 6492. Elapsed 0:30:54\n",
            "Sample: 0.8738731145858765 v/s 0.9264906644821167 v/s 0.9393955444953493\n",
            "Batch 6270 of 6492. Elapsed 0:30:56\n",
            "Sample: 0.8105540871620178 v/s 0.7575187683105469 v/s 0.8299238583914421\n",
            "Batch 6280 of 6492. Elapsed 0:30:59\n",
            "Sample: 0.7753587365150452 v/s 0.7565953731536865 v/s 0.8185927359740024\n",
            "Batch 6290 of 6492. Elapsed 0:31:02\n",
            "Sample: 0.8437591791152954 v/s 0.8472926616668701 v/s 0.8797301581969935\n",
            "Batch 6300 of 6492. Elapsed 0:31:05\n",
            "Sample: 0.8674036860466003 v/s 0.8475682139396667 v/s 0.8889902106494227\n",
            "Batch 6310 of 6492. Elapsed 0:31:09\n",
            "Sample: 0.767814040184021 v/s 0.7630408406257629 v/s 0.8351354062924399\n",
            "Batch 6320 of 6492. Elapsed 0:31:12\n",
            "Sample: 0.8284558057785034 v/s 0.7592913508415222 v/s 0.8216490421668537\n",
            "Batch 6330 of 6492. Elapsed 0:31:15\n",
            "Sample: 0.7983949780464172 v/s 0.8251437544822693 v/s 0.8616649327726122\n",
            "Batch 6340 of 6492. Elapsed 0:31:17\n",
            "Sample: 0.8004094362258911 v/s 0.8309024572372437 v/s 0.8772735947575805\n",
            "Batch 6350 of 6492. Elapsed 0:31:20\n",
            "Sample: 0.9010255336761475 v/s 0.8855951428413391 v/s 0.9107079992542375\n",
            "Batch 6360 of 6492. Elapsed 0:31:23\n",
            "Sample: 0.8279136419296265 v/s 0.871641993522644 v/s 0.8957336924322116\n",
            "Batch 6370 of 6492. Elapsed 0:31:26\n",
            "Sample: 0.7786791324615479 v/s 0.8136712908744812 v/s 0.8604358627893628\n",
            "Batch 6380 of 6492. Elapsed 0:31:29\n",
            "Sample: 0.7891129851341248 v/s 0.7149877548217773 v/s 0.7769877495745012\n",
            "Batch 6390 of 6492. Elapsed 0:31:32\n",
            "Sample: 0.807889997959137 v/s 0.8421830534934998 v/s 0.8854350884352855\n",
            "Batch 6400 of 6492. Elapsed 0:31:34\n",
            "Sample: 0.8583874702453613 v/s 0.933502733707428 v/s 0.9475396587729149\n",
            "Batch 6410 of 6492. Elapsed 0:31:37\n",
            "Sample: 0.761716902256012 v/s 0.7252610921859741 v/s 0.8183975269078742\n",
            "Batch 6420 of 6492. Elapsed 0:31:40\n",
            "Sample: 0.8607736825942993 v/s 0.7838206887245178 v/s 0.8466974091118886\n",
            "Batch 6430 of 6492. Elapsed 0:31:43\n",
            "Sample: 0.8567861318588257 v/s 0.9008296132087708 v/s 0.9261067317693061\n",
            "Batch 6440 of 6492. Elapsed 0:31:46\n",
            "Sample: 0.7610403299331665 v/s 0.767860472202301 v/s 0.8296742857738639\n",
            "Batch 6450 of 6492. Elapsed 0:31:49\n",
            "Sample: 0.7761924266815186 v/s 0.7701398134231567 v/s 0.8164098905775987\n",
            "Batch 6460 of 6492. Elapsed 0:31:52\n",
            "Sample: 0.8620145320892334 v/s 0.8816295266151428 v/s 0.9048180664170764\n",
            "Batch 6470 of 6492. Elapsed 0:31:55\n",
            "Sample: 0.7633577585220337 v/s 0.7579461336135864 v/s 0.7963737516010923\n",
            "Batch 6480 of 6492. Elapsed 0:31:58\n",
            "Sample: 0.7950442433357239 v/s 0.8312689661979675 v/s 0.8607260102692903\n",
            "Batch 6490 of 6492. Elapsed 0:32:01\n",
            "Average discriminator training loss for epoch 2 : 0.0016312988009303808\n",
            "Average True STOI for generated outputs last epoch: 0.8098114728927612\n",
            "Epoch took 0:32:02\n",
            "\n",
            "============= Generator Epoch 1 / 2 =================\n",
            "Sample: 0.8044458627700806 v/s 0.8479112630726715\n",
            "Batch 10 of 4869. Elapsed 0:00:04\n",
            "Sample: 0.8388840556144714 v/s 0.8231939977538211\n",
            "Batch 20 of 4869. Elapsed 0:00:08\n",
            "Sample: 0.783208429813385 v/s 0.783582929041094\n",
            "Batch 30 of 4869. Elapsed 0:00:12\n",
            "Sample: 0.8875088095664978 v/s 0.8883520600904229\n",
            "Batch 40 of 4869. Elapsed 0:00:16\n",
            "Sample: 0.865432620048523 v/s 0.869002228781112\n",
            "Batch 50 of 4869. Elapsed 0:00:20\n",
            "Sample: 0.7780753970146179 v/s 0.7999029940192157\n",
            "Batch 60 of 4869. Elapsed 0:00:24\n",
            "Sample: 0.9001979231834412 v/s 0.9359750529949371\n",
            "Batch 70 of 4869. Elapsed 0:00:28\n",
            "Sample: 0.7980369925498962 v/s 0.8495598064919618\n",
            "Batch 80 of 4869. Elapsed 0:00:32\n",
            "Sample: 0.8589738607406616 v/s 0.8600107471316103\n",
            "Batch 90 of 4869. Elapsed 0:00:36\n",
            "Sample: 0.8766223788261414 v/s 0.9120519841735237\n",
            "Batch 100 of 4869. Elapsed 0:00:40\n",
            "Sample: 0.8374755382537842 v/s 0.8893455526666473\n",
            "Batch 110 of 4869. Elapsed 0:00:44\n",
            "Sample: 0.7878106832504272 v/s 0.7943359209047678\n",
            "Batch 120 of 4869. Elapsed 0:00:48\n",
            "Sample: 0.9136282801628113 v/s 0.9050196525385816\n",
            "Batch 130 of 4869. Elapsed 0:00:52\n",
            "Sample: 0.7648783326148987 v/s 0.7786293105222932\n",
            "Batch 140 of 4869. Elapsed 0:00:56\n",
            "Sample: 0.8332646489143372 v/s 0.837305223646938\n",
            "Batch 150 of 4869. Elapsed 0:00:59\n",
            "Sample: 0.8169967532157898 v/s 0.8789439387526978\n",
            "Batch 160 of 4869. Elapsed 0:01:03\n",
            "Sample: 0.9131193161010742 v/s 0.9435324634215713\n",
            "Batch 170 of 4869. Elapsed 0:01:07\n",
            "Sample: 0.8316329717636108 v/s 0.8043093608458557\n",
            "Batch 180 of 4869. Elapsed 0:01:11\n",
            "Sample: 0.8419104814529419 v/s 0.851721434056798\n",
            "Batch 190 of 4869. Elapsed 0:01:15\n",
            "Sample: 0.8359344601631165 v/s 0.8201612735336459\n",
            "Batch 200 of 4869. Elapsed 0:01:19\n",
            "Sample: 0.7353897094726562 v/s 0.810731680214168\n",
            "Batch 210 of 4869. Elapsed 0:01:23\n",
            "Sample: 0.8538501262664795 v/s 0.8966073113328089\n",
            "Batch 220 of 4869. Elapsed 0:01:27\n",
            "Sample: 0.8642985820770264 v/s 0.8201911481227931\n",
            "Batch 230 of 4869. Elapsed 0:01:32\n",
            "Sample: 0.8196967244148254 v/s 0.8510254553554644\n",
            "Batch 240 of 4869. Elapsed 0:01:36\n",
            "Sample: 0.8070942759513855 v/s 0.8501387565558148\n",
            "Batch 250 of 4869. Elapsed 0:01:40\n",
            "Sample: 0.7364429831504822 v/s 0.7396811851954355\n",
            "Batch 260 of 4869. Elapsed 0:01:44\n",
            "Sample: 0.7955033779144287 v/s 0.9206066524747437\n",
            "Batch 270 of 4869. Elapsed 0:01:47\n",
            "Sample: 0.8039922714233398 v/s 0.7954590272859373\n",
            "Batch 280 of 4869. Elapsed 0:01:52\n",
            "Sample: 0.757964015007019 v/s 0.8151292614074146\n",
            "Batch 290 of 4869. Elapsed 0:01:55\n",
            "Sample: 0.7860473990440369 v/s 0.8209053693822884\n",
            "Batch 300 of 4869. Elapsed 0:01:59\n",
            "Sample: 0.8612964749336243 v/s 0.8958898768045506\n",
            "Batch 310 of 4869. Elapsed 0:02:03\n",
            "Sample: 0.8870380520820618 v/s 0.8755271039277669\n",
            "Batch 320 of 4869. Elapsed 0:02:07\n",
            "Sample: 0.8275415897369385 v/s 0.8338267123171922\n",
            "Batch 330 of 4869. Elapsed 0:02:11\n",
            "Sample: 0.7128299474716187 v/s 0.6705029649037191\n",
            "Batch 340 of 4869. Elapsed 0:02:15\n",
            "Sample: 0.7343214750289917 v/s 0.6968214808267867\n",
            "Batch 350 of 4869. Elapsed 0:02:19\n",
            "Sample: 0.8249815702438354 v/s 0.8919579878516667\n",
            "Batch 360 of 4869. Elapsed 0:02:23\n",
            "Sample: 0.8593247532844543 v/s 0.8415974508642245\n",
            "Batch 370 of 4869. Elapsed 0:02:27\n",
            "Sample: 0.838866114616394 v/s 0.8842146132629908\n",
            "Batch 380 of 4869. Elapsed 0:02:31\n",
            "Sample: 0.7926519513130188 v/s 0.7263394705580737\n",
            "Batch 390 of 4869. Elapsed 0:02:35\n",
            "Sample: 0.8475944995880127 v/s 0.8534301915239606\n",
            "Batch 400 of 4869. Elapsed 0:02:39\n",
            "Sample: 0.852798581123352 v/s 0.9096875507518365\n",
            "Batch 410 of 4869. Elapsed 0:02:42\n",
            "Sample: 0.8626894950866699 v/s 0.8642054201710044\n",
            "Batch 420 of 4869. Elapsed 0:02:46\n",
            "Sample: 0.8086315393447876 v/s 0.8741283732549887\n",
            "Batch 430 of 4869. Elapsed 0:02:50\n",
            "Sample: 0.8601042628288269 v/s 0.88898994623353\n",
            "Batch 440 of 4869. Elapsed 0:02:54\n",
            "Sample: 0.8381537199020386 v/s 0.8678397538245666\n",
            "Batch 450 of 4869. Elapsed 0:02:58\n",
            "Sample: 0.8684039115905762 v/s 0.885090925452705\n",
            "Batch 460 of 4869. Elapsed 0:03:02\n",
            "Sample: 0.7997373342514038 v/s 0.7917894485754713\n",
            "Batch 470 of 4869. Elapsed 0:03:06\n",
            "Sample: 0.8053374886512756 v/s 0.8047433805913433\n",
            "Batch 480 of 4869. Elapsed 0:03:10\n",
            "Sample: 0.8427127599716187 v/s 0.8188856780644657\n",
            "Batch 490 of 4869. Elapsed 0:03:14\n",
            "Sample: 0.8389186859130859 v/s 0.8534456226569644\n",
            "Batch 500 of 4869. Elapsed 0:03:18\n",
            "Sample: 0.8342203497886658 v/s 0.8075184685890164\n",
            "Batch 510 of 4869. Elapsed 0:03:22\n",
            "Sample: 0.8147645592689514 v/s 0.80818569840953\n",
            "Batch 520 of 4869. Elapsed 0:03:26\n",
            "Sample: 0.8559568524360657 v/s 0.8431330423579815\n",
            "Batch 530 of 4869. Elapsed 0:03:30\n",
            "Sample: 0.8754468560218811 v/s 0.9195506852624892\n",
            "Batch 540 of 4869. Elapsed 0:03:34\n",
            "Sample: 0.8332107067108154 v/s 0.9274991400384031\n",
            "Batch 550 of 4869. Elapsed 0:03:37\n",
            "Sample: 0.8672833442687988 v/s 0.873248901294514\n",
            "Batch 560 of 4869. Elapsed 0:03:41\n",
            "Sample: 0.8257051706314087 v/s 0.9115068247647131\n",
            "Batch 570 of 4869. Elapsed 0:03:45\n",
            "Sample: 0.774355947971344 v/s 0.7177811984743327\n",
            "Batch 580 of 4869. Elapsed 0:03:49\n",
            "Sample: 0.7886897325515747 v/s 0.7811640948150763\n",
            "Batch 590 of 4869. Elapsed 0:03:53\n",
            "Sample: 0.8077334761619568 v/s 0.8025135315178688\n",
            "Batch 600 of 4869. Elapsed 0:03:57\n",
            "Sample: 0.8269376754760742 v/s 0.8496459436565115\n",
            "Batch 610 of 4869. Elapsed 0:04:01\n",
            "Sample: 0.8933554887771606 v/s 0.8869051441197902\n",
            "Batch 620 of 4869. Elapsed 0:04:05\n",
            "Sample: 0.7695398926734924 v/s 0.8967671729004812\n",
            "Batch 630 of 4869. Elapsed 0:04:09\n",
            "Sample: 0.8254567980766296 v/s 0.8445960747681506\n",
            "Batch 640 of 4869. Elapsed 0:04:13\n",
            "Sample: 0.8436709046363831 v/s 0.849728537917863\n",
            "Batch 650 of 4869. Elapsed 0:04:17\n",
            "Sample: 0.7918429970741272 v/s 0.8082010266531857\n",
            "Batch 660 of 4869. Elapsed 0:04:21\n",
            "Sample: 0.7025209069252014 v/s 0.7287759473114935\n",
            "Batch 670 of 4869. Elapsed 0:04:25\n",
            "Sample: 0.7676360607147217 v/s 0.7945107059960209\n",
            "Batch 680 of 4869. Elapsed 0:04:29\n",
            "Sample: 0.7323541045188904 v/s 0.7519810821495314\n",
            "Batch 690 of 4869. Elapsed 0:04:33\n",
            "Sample: 0.8391552567481995 v/s 0.8752892568060237\n",
            "Batch 700 of 4869. Elapsed 0:04:37\n",
            "Sample: 0.7373742461204529 v/s 0.7505330857760724\n",
            "Batch 710 of 4869. Elapsed 0:04:41\n",
            "Sample: 0.7721432447433472 v/s 0.7832884593169659\n",
            "Batch 720 of 4869. Elapsed 0:04:45\n",
            "Sample: 0.8127739429473877 v/s 0.8331873929279302\n",
            "Batch 730 of 4869. Elapsed 0:04:49\n",
            "Sample: 0.8691052198410034 v/s 0.900772630533767\n",
            "Batch 740 of 4869. Elapsed 0:04:53\n",
            "Sample: 0.8463301658630371 v/s 0.8662146608455453\n",
            "Batch 750 of 4869. Elapsed 0:04:57\n",
            "Sample: 0.7223018407821655 v/s 0.717745702312441\n",
            "Batch 760 of 4869. Elapsed 0:05:01\n",
            "Sample: 0.8439306020736694 v/s 0.8450852362499977\n",
            "Batch 770 of 4869. Elapsed 0:05:04\n",
            "Sample: 0.8883967399597168 v/s 0.8867075139786613\n",
            "Batch 780 of 4869. Elapsed 0:05:08\n",
            "Sample: 0.780843198299408 v/s 0.8477896218383166\n",
            "Batch 790 of 4869. Elapsed 0:05:12\n",
            "Sample: 0.8495511412620544 v/s 0.8274940807588359\n",
            "Batch 800 of 4869. Elapsed 0:05:17\n",
            "Sample: 0.8030399084091187 v/s 0.8793974754470352\n",
            "Batch 810 of 4869. Elapsed 0:05:20\n",
            "Sample: 0.8705217838287354 v/s 0.8638832874585302\n",
            "Batch 820 of 4869. Elapsed 0:05:24\n",
            "Sample: 0.817077100276947 v/s 0.8317236104827391\n",
            "Batch 830 of 4869. Elapsed 0:05:28\n",
            "Sample: 0.9090519547462463 v/s 0.9700450500753695\n",
            "Batch 840 of 4869. Elapsed 0:05:32\n",
            "Sample: 0.7726014852523804 v/s 0.8426187301299436\n",
            "Batch 850 of 4869. Elapsed 0:05:36\n",
            "Sample: 0.8389246463775635 v/s 0.7863036021294955\n",
            "Batch 860 of 4869. Elapsed 0:05:40\n",
            "Sample: 0.8552926182746887 v/s 0.8127261014154704\n",
            "Batch 870 of 4869. Elapsed 0:05:44\n",
            "Sample: 0.8595722913742065 v/s 0.873274061349454\n",
            "Batch 880 of 4869. Elapsed 0:05:48\n",
            "Sample: 0.797688901424408 v/s 0.7559009050866855\n",
            "Batch 890 of 4869. Elapsed 0:05:52\n",
            "Sample: 0.8438679575920105 v/s 0.890235906003872\n",
            "Batch 900 of 4869. Elapsed 0:05:56\n",
            "Sample: 0.8388507962226868 v/s 0.8511733652067462\n",
            "Batch 910 of 4869. Elapsed 0:06:00\n",
            "Sample: 0.8391178250312805 v/s 0.8387028907221636\n",
            "Batch 920 of 4869. Elapsed 0:06:04\n",
            "Sample: 0.6935734152793884 v/s 0.7644491766804323\n",
            "Batch 930 of 4869. Elapsed 0:06:08\n",
            "Sample: 0.8743883371353149 v/s 0.8651846400672696\n",
            "Batch 940 of 4869. Elapsed 0:06:12\n",
            "Sample: 0.8240630030632019 v/s 0.8758891842441465\n",
            "Batch 950 of 4869. Elapsed 0:06:16\n",
            "Sample: 0.7401655316352844 v/s 0.7866376321157735\n",
            "Batch 960 of 4869. Elapsed 0:06:20\n",
            "Sample: 0.7405139803886414 v/s 0.7726695353786398\n",
            "Batch 970 of 4869. Elapsed 0:06:24\n",
            "Sample: 0.798339307308197 v/s 0.7834997943275878\n",
            "Batch 980 of 4869. Elapsed 0:06:28\n",
            "Sample: 0.8748975396156311 v/s 0.9206645844050463\n",
            "Batch 990 of 4869. Elapsed 0:06:32\n",
            "Sample: 0.862490177154541 v/s 0.9074190642917733\n",
            "Batch 1000 of 4869. Elapsed 0:06:36\n",
            "Sample: 0.8434483408927917 v/s 0.8740456668580745\n",
            "Batch 1010 of 4869. Elapsed 0:06:39\n",
            "Sample: 0.8478836417198181 v/s 0.8901509384937103\n",
            "Batch 1020 of 4869. Elapsed 0:06:43\n",
            "Sample: 0.8370542526245117 v/s 0.9018189773731797\n",
            "Batch 1030 of 4869. Elapsed 0:06:47\n",
            "Sample: 0.8623435497283936 v/s 0.8402677277768694\n",
            "Batch 1040 of 4869. Elapsed 0:06:51\n",
            "Sample: 0.827913224697113 v/s 0.7784826901461028\n",
            "Batch 1050 of 4869. Elapsed 0:06:55\n",
            "Sample: 0.8385967016220093 v/s 0.9185458159284118\n",
            "Batch 1060 of 4869. Elapsed 0:06:59\n",
            "Sample: 0.739797830581665 v/s 0.740472270521476\n",
            "Batch 1070 of 4869. Elapsed 0:07:03\n",
            "Sample: 0.8347545862197876 v/s 0.775382038421732\n",
            "Batch 1080 of 4869. Elapsed 0:07:07\n",
            "Sample: 0.8226566314697266 v/s 0.8169117337847714\n",
            "Batch 1090 of 4869. Elapsed 0:07:10\n",
            "Sample: 0.8501402139663696 v/s 0.8422808073034411\n",
            "Batch 1100 of 4869. Elapsed 0:07:15\n",
            "Sample: 0.7964596152305603 v/s 0.7627225807119135\n",
            "Batch 1110 of 4869. Elapsed 0:07:18\n",
            "Sample: 0.7843543887138367 v/s 0.7847247729937767\n",
            "Batch 1120 of 4869. Elapsed 0:07:22\n",
            "Sample: 0.8488183617591858 v/s 0.9082173549643278\n",
            "Batch 1130 of 4869. Elapsed 0:07:26\n",
            "Sample: 0.7768009901046753 v/s 0.7815960426021283\n",
            "Batch 1140 of 4869. Elapsed 0:07:31\n",
            "Sample: 0.7927991151809692 v/s 0.7910870106375039\n",
            "Batch 1150 of 4869. Elapsed 0:07:35\n",
            "Sample: 0.7507458925247192 v/s 0.8016199454614625\n",
            "Batch 1160 of 4869. Elapsed 0:07:39\n",
            "Sample: 0.7918046712875366 v/s 0.8075117590043093\n",
            "Batch 1170 of 4869. Elapsed 0:07:42\n",
            "Sample: 0.7859534621238708 v/s 0.7536078055616744\n",
            "Batch 1180 of 4869. Elapsed 0:07:46\n",
            "Sample: 0.8497387170791626 v/s 0.8514809257057894\n",
            "Batch 1190 of 4869. Elapsed 0:07:50\n",
            "Sample: 0.8795264959335327 v/s 0.85812966155395\n",
            "Batch 1200 of 4869. Elapsed 0:07:54\n",
            "Sample: 0.8329312205314636 v/s 0.8357211536448865\n",
            "Batch 1210 of 4869. Elapsed 0:07:58\n",
            "Sample: 0.8068762421607971 v/s 0.804422929920443\n",
            "Batch 1220 of 4869. Elapsed 0:08:02\n",
            "Sample: 0.8622921109199524 v/s 0.924163496974935\n",
            "Batch 1230 of 4869. Elapsed 0:08:06\n",
            "Sample: 0.8682181239128113 v/s 0.8745066926840624\n",
            "Batch 1240 of 4869. Elapsed 0:08:10\n",
            "Sample: 0.851818859577179 v/s 0.8369190733462086\n",
            "Batch 1250 of 4869. Elapsed 0:08:13\n",
            "Sample: 0.8700935244560242 v/s 0.9407552573292061\n",
            "Batch 1260 of 4869. Elapsed 0:08:17\n",
            "Sample: 0.8575781583786011 v/s 0.9071433499010915\n",
            "Batch 1270 of 4869. Elapsed 0:08:21\n",
            "Sample: 0.8838276267051697 v/s 0.9089798375614153\n",
            "Batch 1280 of 4869. Elapsed 0:08:25\n",
            "Sample: 0.8706425428390503 v/s 0.9029047229266568\n",
            "Batch 1290 of 4869. Elapsed 0:08:29\n",
            "Sample: 0.8546934723854065 v/s 0.8727639301500569\n",
            "Batch 1300 of 4869. Elapsed 0:08:33\n",
            "Sample: 0.8668493032455444 v/s 0.9039260696468037\n",
            "Batch 1310 of 4869. Elapsed 0:08:37\n",
            "Sample: 0.8813088536262512 v/s 0.8916216527777154\n",
            "Batch 1320 of 4869. Elapsed 0:08:42\n",
            "Sample: 0.812091588973999 v/s 0.7900864267569193\n",
            "Batch 1330 of 4869. Elapsed 0:08:45\n",
            "Sample: 0.7669379711151123 v/s 0.749073709421219\n",
            "Batch 1340 of 4869. Elapsed 0:08:49\n",
            "Sample: 0.8122731447219849 v/s 0.7997536605342701\n",
            "Batch 1350 of 4869. Elapsed 0:08:53\n",
            "Sample: 0.7572795748710632 v/s 0.7787930740343717\n",
            "Batch 1360 of 4869. Elapsed 0:08:57\n",
            "Sample: 0.8341653943061829 v/s 0.8152356474239769\n",
            "Batch 1370 of 4869. Elapsed 0:09:01\n",
            "Sample: 0.8398244976997375 v/s 0.8091907738110449\n",
            "Batch 1380 of 4869. Elapsed 0:09:05\n",
            "Sample: 0.8391293883323669 v/s 0.8038167527985772\n",
            "Batch 1390 of 4869. Elapsed 0:09:09\n",
            "Sample: 0.8456194400787354 v/s 0.8964780193221463\n",
            "Batch 1400 of 4869. Elapsed 0:09:13\n",
            "Sample: 0.8523194193840027 v/s 0.8886028093958065\n",
            "Batch 1410 of 4869. Elapsed 0:09:16\n",
            "Sample: 0.8547418117523193 v/s 0.8524557462307384\n",
            "Batch 1420 of 4869. Elapsed 0:09:20\n",
            "Sample: 0.8464343547821045 v/s 0.8999565056545704\n",
            "Batch 1430 of 4869. Elapsed 0:09:24\n",
            "Sample: 0.7769950032234192 v/s 0.7440844340097069\n",
            "Batch 1440 of 4869. Elapsed 0:09:28\n",
            "Sample: 0.8433025479316711 v/s 0.8599755187925083\n",
            "Batch 1450 of 4869. Elapsed 0:09:32\n",
            "Sample: 0.8383628129959106 v/s 0.7978694415964579\n",
            "Batch 1460 of 4869. Elapsed 0:09:36\n",
            "Sample: 0.813073992729187 v/s 0.7498077051174646\n",
            "Batch 1470 of 4869. Elapsed 0:09:40\n",
            "Sample: 0.8374183177947998 v/s 0.799869283427542\n",
            "Batch 1480 of 4869. Elapsed 0:09:44\n",
            "Sample: 0.8078038692474365 v/s 0.8309595811519116\n",
            "Batch 1490 of 4869. Elapsed 0:09:48\n",
            "Sample: 0.8167842030525208 v/s 0.8087324423033517\n",
            "Batch 1500 of 4869. Elapsed 0:09:52\n",
            "Sample: 0.7934703826904297 v/s 0.8187589944383846\n",
            "Batch 1510 of 4869. Elapsed 0:09:56\n",
            "Sample: 0.8632804751396179 v/s 0.8592070137547343\n",
            "Batch 1520 of 4869. Elapsed 0:09:59\n",
            "Sample: 0.7474166750907898 v/s 0.7665487589200323\n",
            "Batch 1530 of 4869. Elapsed 0:10:03\n",
            "Sample: 0.868319571018219 v/s 0.8788761539192327\n",
            "Batch 1540 of 4869. Elapsed 0:10:07\n",
            "Sample: 0.7742902040481567 v/s 0.7747329487336411\n",
            "Batch 1550 of 4869. Elapsed 0:10:11\n",
            "Sample: 0.8039453029632568 v/s 0.8258946406639781\n",
            "Batch 1560 of 4869. Elapsed 0:10:15\n",
            "Sample: 0.7026066780090332 v/s 0.6776693471282045\n",
            "Batch 1570 of 4869. Elapsed 0:10:19\n",
            "Sample: 0.7602295279502869 v/s 0.7568710357184993\n",
            "Batch 1580 of 4869. Elapsed 0:10:23\n",
            "Sample: 0.8401039838790894 v/s 0.9104420483423459\n",
            "Batch 1590 of 4869. Elapsed 0:10:27\n",
            "Sample: 0.8304128646850586 v/s 0.8238594396250798\n",
            "Batch 1600 of 4869. Elapsed 0:10:32\n",
            "Sample: 0.8562991619110107 v/s 0.913373642511747\n",
            "Batch 1610 of 4869. Elapsed 0:10:36\n",
            "Sample: 0.7880294919013977 v/s 0.8259283024827261\n",
            "Batch 1620 of 4869. Elapsed 0:10:40\n",
            "Sample: 0.7613306045532227 v/s 0.796858204836643\n",
            "Batch 1630 of 4869. Elapsed 0:10:44\n",
            "Sample: 0.8632402420043945 v/s 0.9146087187769825\n",
            "Batch 1640 of 4869. Elapsed 0:10:48\n",
            "Sample: 0.8347193598747253 v/s 0.8425109364614045\n",
            "Batch 1650 of 4869. Elapsed 0:10:52\n",
            "Sample: 0.8270806670188904 v/s 0.8418230102479345\n",
            "Batch 1660 of 4869. Elapsed 0:10:55\n",
            "Sample: 0.8524662256240845 v/s 0.8120199550320839\n",
            "Batch 1670 of 4869. Elapsed 0:10:59\n",
            "Sample: 0.8916979432106018 v/s 0.9009274881077984\n",
            "Batch 1680 of 4869. Elapsed 0:11:03\n",
            "Sample: 0.8569390177726746 v/s 0.8563493346785943\n",
            "Batch 1690 of 4869. Elapsed 0:11:07\n",
            "Sample: 0.6916918754577637 v/s 0.6755509383047035\n",
            "Batch 1700 of 4869. Elapsed 0:11:11\n",
            "Sample: 0.8597735166549683 v/s 0.8613113491528377\n",
            "Batch 1710 of 4869. Elapsed 0:11:15\n",
            "Sample: 0.7880324125289917 v/s 0.8600122744486011\n",
            "Batch 1720 of 4869. Elapsed 0:11:19\n",
            "Sample: 0.8967850208282471 v/s 0.9057908648806462\n",
            "Batch 1730 of 4869. Elapsed 0:11:23\n",
            "Sample: 0.7884259819984436 v/s 0.8752328067759666\n",
            "Batch 1740 of 4869. Elapsed 0:11:27\n",
            "Sample: 0.8183549642562866 v/s 0.8753263717300983\n",
            "Batch 1750 of 4869. Elapsed 0:11:31\n",
            "Sample: 0.7944260239601135 v/s 0.8124880129921259\n",
            "Batch 1760 of 4869. Elapsed 0:11:35\n",
            "Sample: 0.8508941531181335 v/s 0.8259242275767585\n",
            "Batch 1770 of 4869. Elapsed 0:11:39\n",
            "Sample: 0.827508270740509 v/s 0.8271054759481458\n",
            "Batch 1780 of 4869. Elapsed 0:11:43\n",
            "Sample: 0.8672683238983154 v/s 0.8464002417607233\n",
            "Batch 1790 of 4869. Elapsed 0:11:46\n",
            "Sample: 0.8289685249328613 v/s 0.8453873072574974\n",
            "Batch 1800 of 4869. Elapsed 0:11:50\n",
            "Sample: 0.7816537618637085 v/s 0.7878194050379222\n",
            "Batch 1810 of 4869. Elapsed 0:11:54\n",
            "Sample: 0.7427288889884949 v/s 0.7397340518707233\n",
            "Batch 1820 of 4869. Elapsed 0:11:58\n",
            "Sample: 0.8428462743759155 v/s 0.8841965974125943\n",
            "Batch 1830 of 4869. Elapsed 0:12:02\n",
            "Sample: 0.8398537039756775 v/s 0.8165741989213653\n",
            "Batch 1840 of 4869. Elapsed 0:12:06\n",
            "Sample: 0.8594175577163696 v/s 0.873396695038839\n",
            "Batch 1850 of 4869. Elapsed 0:12:10\n",
            "Sample: 0.8135764002799988 v/s 0.8170761179816964\n",
            "Batch 1860 of 4869. Elapsed 0:12:14\n",
            "Sample: 0.8783654570579529 v/s 0.8924736881237647\n",
            "Batch 1870 of 4869. Elapsed 0:12:18\n",
            "Sample: 0.822332501411438 v/s 0.8447984576333152\n",
            "Batch 1880 of 4869. Elapsed 0:12:22\n",
            "Sample: 0.901532769203186 v/s 0.923943042592902\n",
            "Batch 1890 of 4869. Elapsed 0:12:26\n",
            "Sample: 0.8024501800537109 v/s 0.7661370508438273\n",
            "Batch 1900 of 4869. Elapsed 0:12:30\n",
            "Sample: 0.8499775528907776 v/s 0.8579891160504097\n",
            "Batch 1910 of 4869. Elapsed 0:12:33\n",
            "Sample: 0.7225217819213867 v/s 0.6786957544376448\n",
            "Batch 1920 of 4869. Elapsed 0:12:37\n",
            "Sample: 0.8847448229789734 v/s 0.9107182830814827\n",
            "Batch 1930 of 4869. Elapsed 0:12:41\n",
            "Sample: 0.8760029673576355 v/s 0.8956278433827013\n",
            "Batch 1940 of 4869. Elapsed 0:12:45\n",
            "Sample: 0.8010272979736328 v/s 0.7618601794475862\n",
            "Batch 1950 of 4869. Elapsed 0:12:49\n",
            "Sample: 0.8120686411857605 v/s 0.7930843855978692\n",
            "Batch 1960 of 4869. Elapsed 0:12:53\n",
            "Sample: 0.873538076877594 v/s 0.8799070763831629\n",
            "Batch 1970 of 4869. Elapsed 0:12:57\n",
            "Sample: 0.8926857113838196 v/s 0.8802923451513593\n",
            "Batch 1980 of 4869. Elapsed 0:13:01\n",
            "Sample: 0.8693538308143616 v/s 0.8789726458899466\n",
            "Batch 1990 of 4869. Elapsed 0:13:05\n",
            "Sample: 0.7669835686683655 v/s 0.704062003070214\n",
            "Batch 2000 of 4869. Elapsed 0:13:09\n",
            "Sample: 0.7094138264656067 v/s 0.6844762197684645\n",
            "Batch 2010 of 4869. Elapsed 0:13:13\n",
            "Sample: 0.8405115604400635 v/s 0.8764379681938129\n",
            "Batch 2020 of 4869. Elapsed 0:13:17\n",
            "Sample: 0.8613722324371338 v/s 0.852885195502195\n",
            "Batch 2030 of 4869. Elapsed 0:13:21\n",
            "Sample: 0.8364202976226807 v/s 0.8661201815294072\n",
            "Batch 2040 of 4869. Elapsed 0:13:25\n",
            "Sample: 0.8502163887023926 v/s 0.8780937945640408\n",
            "Batch 2050 of 4869. Elapsed 0:13:29\n",
            "Sample: 0.7897846698760986 v/s 0.8236525222916501\n",
            "Batch 2060 of 4869. Elapsed 0:13:33\n",
            "Sample: 0.828700602054596 v/s 0.8116438549273177\n",
            "Batch 2070 of 4869. Elapsed 0:13:37\n",
            "Sample: 0.8812751770019531 v/s 0.9069366916548389\n",
            "Batch 2080 of 4869. Elapsed 0:13:41\n",
            "Sample: 0.8864904046058655 v/s 0.9057173792047527\n",
            "Batch 2090 of 4869. Elapsed 0:13:45\n",
            "Sample: 0.8150184750556946 v/s 0.8111110408899526\n",
            "Batch 2100 of 4869. Elapsed 0:13:49\n",
            "Sample: 0.8840137720108032 v/s 0.9373859506762459\n",
            "Batch 2110 of 4869. Elapsed 0:13:53\n",
            "Sample: 0.7672891616821289 v/s 0.7288340233096416\n",
            "Batch 2120 of 4869. Elapsed 0:13:57\n",
            "Sample: 0.7315673232078552 v/s 0.6912897261601615\n",
            "Batch 2130 of 4869. Elapsed 0:14:01\n",
            "Sample: 0.804596483707428 v/s 0.7788295949557511\n",
            "Batch 2140 of 4869. Elapsed 0:14:05\n",
            "Sample: 0.8528915643692017 v/s 0.8244231372473597\n",
            "Batch 2150 of 4869. Elapsed 0:14:08\n",
            "Sample: 0.7433088421821594 v/s 0.7921822578287657\n",
            "Batch 2160 of 4869. Elapsed 0:14:12\n",
            "Sample: 0.842025101184845 v/s 0.8539384364806729\n",
            "Batch 2170 of 4869. Elapsed 0:14:17\n",
            "Sample: 0.8586775064468384 v/s 0.8218084109922575\n",
            "Batch 2180 of 4869. Elapsed 0:14:20\n",
            "Sample: 0.8161211609840393 v/s 0.7951961614926003\n",
            "Batch 2190 of 4869. Elapsed 0:14:24\n",
            "Sample: 0.8050904273986816 v/s 0.8060528704974221\n",
            "Batch 2200 of 4869. Elapsed 0:14:28\n",
            "Sample: 0.825157105922699 v/s 0.9036612244699599\n",
            "Batch 2210 of 4869. Elapsed 0:14:32\n",
            "Sample: 0.8382390737533569 v/s 0.7745865926127264\n",
            "Batch 2220 of 4869. Elapsed 0:14:36\n",
            "Sample: 0.8079236149787903 v/s 0.7680527594002203\n",
            "Batch 2230 of 4869. Elapsed 0:14:39\n",
            "Sample: 0.8630080223083496 v/s 0.8557022098430686\n",
            "Batch 2240 of 4869. Elapsed 0:14:43\n",
            "Sample: 0.8355457782745361 v/s 0.7919865819353472\n",
            "Batch 2250 of 4869. Elapsed 0:14:47\n",
            "Sample: 0.8205102682113647 v/s 0.7934754834307098\n",
            "Batch 2260 of 4869. Elapsed 0:14:51\n",
            "Sample: 0.8845697045326233 v/s 0.8669748463406669\n",
            "Batch 2270 of 4869. Elapsed 0:14:55\n",
            "Sample: 0.858153223991394 v/s 0.8596715325415324\n",
            "Batch 2280 of 4869. Elapsed 0:15:00\n",
            "Sample: 0.7333763241767883 v/s 0.7102495414051009\n",
            "Batch 2290 of 4869. Elapsed 0:15:03\n",
            "Sample: 0.79722660779953 v/s 0.8584843076499589\n",
            "Batch 2300 of 4869. Elapsed 0:15:08\n",
            "Sample: 0.8463133573532104 v/s 0.9062701509626243\n",
            "Batch 2310 of 4869. Elapsed 0:15:11\n",
            "Sample: 0.7503043413162231 v/s 0.8154654317585794\n",
            "Batch 2320 of 4869. Elapsed 0:15:15\n",
            "Sample: 0.8239790797233582 v/s 0.8414584445187161\n",
            "Batch 2330 of 4869. Elapsed 0:15:19\n",
            "Sample: 0.8548343181610107 v/s 0.849966409107377\n",
            "Batch 2340 of 4869. Elapsed 0:15:23\n",
            "Sample: 0.8239351511001587 v/s 0.8265804840681287\n",
            "Batch 2350 of 4869. Elapsed 0:15:27\n",
            "Sample: 0.826248049736023 v/s 0.8305118711123005\n",
            "Batch 2360 of 4869. Elapsed 0:15:31\n",
            "Sample: 0.874950110912323 v/s 0.8833356740737666\n",
            "Batch 2370 of 4869. Elapsed 0:15:35\n",
            "Sample: 0.8537168502807617 v/s 0.8730471703492514\n",
            "Batch 2380 of 4869. Elapsed 0:15:39\n",
            "Sample: 0.8378782272338867 v/s 0.8688084787793638\n",
            "Batch 2390 of 4869. Elapsed 0:15:43\n",
            "Sample: 0.8450378775596619 v/s 0.8452406409896428\n",
            "Batch 2400 of 4869. Elapsed 0:15:47\n",
            "Sample: 0.8227648138999939 v/s 0.7806569161667128\n",
            "Batch 2410 of 4869. Elapsed 0:15:51\n",
            "Sample: 0.8738797903060913 v/s 0.9223876703450516\n",
            "Batch 2420 of 4869. Elapsed 0:15:55\n",
            "Sample: 0.7570230960845947 v/s 0.7441634028315374\n",
            "Batch 2430 of 4869. Elapsed 0:15:59\n",
            "Sample: 0.9154036641120911 v/s 0.9508812287871875\n",
            "Batch 2440 of 4869. Elapsed 0:16:03\n",
            "Sample: 0.8956483006477356 v/s 0.9082363134698352\n",
            "Batch 2450 of 4869. Elapsed 0:16:07\n",
            "Sample: 0.833595335483551 v/s 0.7920946920042234\n",
            "Batch 2460 of 4869. Elapsed 0:16:10\n",
            "Sample: 0.8859307169914246 v/s 0.9218869330267417\n",
            "Batch 2470 of 4869. Elapsed 0:16:15\n",
            "Sample: 0.8024501800537109 v/s 0.769928833946114\n",
            "Batch 2480 of 4869. Elapsed 0:16:19\n",
            "Sample: 0.8461877107620239 v/s 0.8362497394873009\n",
            "Batch 2490 of 4869. Elapsed 0:16:22\n",
            "Sample: 0.8110197186470032 v/s 0.8241077581827917\n",
            "Batch 2500 of 4869. Elapsed 0:16:26\n",
            "Sample: 0.8275879621505737 v/s 0.8587616480650493\n",
            "Batch 2510 of 4869. Elapsed 0:16:30\n",
            "Sample: 0.7459064722061157 v/s 0.7466077595754231\n",
            "Batch 2520 of 4869. Elapsed 0:16:34\n",
            "Sample: 0.7812570929527283 v/s 0.7239205519697155\n",
            "Batch 2530 of 4869. Elapsed 0:16:38\n",
            "Sample: 0.831627368927002 v/s 0.7554578169571879\n",
            "Batch 2540 of 4869. Elapsed 0:16:42\n",
            "Sample: 0.8468324542045593 v/s 0.8945368701792651\n",
            "Batch 2550 of 4869. Elapsed 0:16:46\n",
            "Sample: 0.8071807026863098 v/s 0.7989669980261193\n",
            "Batch 2560 of 4869. Elapsed 0:16:50\n",
            "Sample: 0.8202134370803833 v/s 0.824765738699464\n",
            "Batch 2570 of 4869. Elapsed 0:16:54\n",
            "Sample: 0.8189893960952759 v/s 0.7618181246736216\n",
            "Batch 2580 of 4869. Elapsed 0:16:58\n",
            "Sample: 0.7941136956214905 v/s 0.7725639710339344\n",
            "Batch 2590 of 4869. Elapsed 0:17:03\n",
            "Sample: 0.8424590229988098 v/s 0.8492275025469291\n",
            "Batch 2600 of 4869. Elapsed 0:17:07\n",
            "Sample: 0.8156757950782776 v/s 0.8486948868300048\n",
            "Batch 2610 of 4869. Elapsed 0:17:11\n",
            "Sample: 0.7768651247024536 v/s 0.7395977223631247\n",
            "Batch 2620 of 4869. Elapsed 0:17:15\n",
            "Sample: 0.8592224717140198 v/s 0.8817669030469099\n",
            "Batch 2630 of 4869. Elapsed 0:17:19\n",
            "Sample: 0.8812681436538696 v/s 0.9194193841662458\n",
            "Batch 2640 of 4869. Elapsed 0:17:23\n",
            "Sample: 0.8311862349510193 v/s 0.8080593813797883\n",
            "Batch 2650 of 4869. Elapsed 0:17:27\n",
            "Sample: 0.8152768015861511 v/s 0.7890344444936725\n",
            "Batch 2660 of 4869. Elapsed 0:17:31\n",
            "Sample: 0.7449540495872498 v/s 0.6980139018191047\n",
            "Batch 2670 of 4869. Elapsed 0:17:35\n",
            "Sample: 0.8452792763710022 v/s 0.8758912776977468\n",
            "Batch 2680 of 4869. Elapsed 0:17:38\n",
            "Sample: 0.7503784894943237 v/s 0.7672083317479963\n",
            "Batch 2690 of 4869. Elapsed 0:17:42\n",
            "Sample: 0.8084811568260193 v/s 0.796428777283941\n",
            "Batch 2700 of 4869. Elapsed 0:17:46\n",
            "Sample: 0.7925751209259033 v/s 0.794759654250686\n",
            "Batch 2710 of 4869. Elapsed 0:17:50\n",
            "Sample: 0.8414861559867859 v/s 0.8291726800658035\n",
            "Batch 2720 of 4869. Elapsed 0:17:54\n",
            "Sample: 0.8072125911712646 v/s 0.8185901241242782\n",
            "Batch 2730 of 4869. Elapsed 0:17:58\n",
            "Sample: 0.7935928106307983 v/s 0.7333380869767426\n",
            "Batch 2740 of 4869. Elapsed 0:18:02\n",
            "Sample: 0.8250548839569092 v/s 0.7748682410122221\n",
            "Batch 2750 of 4869. Elapsed 0:18:06\n",
            "Sample: 0.8563819527626038 v/s 0.8512117203271894\n",
            "Batch 2760 of 4869. Elapsed 0:18:10\n",
            "Sample: 0.7898499965667725 v/s 0.752844749736517\n",
            "Batch 2770 of 4869. Elapsed 0:18:14\n",
            "Sample: 0.8776375651359558 v/s 0.929346268921238\n",
            "Batch 2780 of 4869. Elapsed 0:18:18\n",
            "Sample: 0.7617137432098389 v/s 0.8302378593836336\n",
            "Batch 2790 of 4869. Elapsed 0:18:22\n",
            "Sample: 0.8307445049285889 v/s 0.7998576301266167\n",
            "Batch 2800 of 4869. Elapsed 0:18:26\n",
            "Sample: 0.8282938599586487 v/s 0.7262984105758545\n",
            "Batch 2810 of 4869. Elapsed 0:18:30\n",
            "Sample: 0.7943785190582275 v/s 0.767816978023594\n",
            "Batch 2820 of 4869. Elapsed 0:18:34\n",
            "Sample: 0.8342837691307068 v/s 0.8310592923594873\n",
            "Batch 2830 of 4869. Elapsed 0:18:38\n",
            "Sample: 0.8164815306663513 v/s 0.7991599812471382\n",
            "Batch 2840 of 4869. Elapsed 0:18:42\n",
            "Sample: 0.8315645456314087 v/s 0.7799207194614594\n",
            "Batch 2850 of 4869. Elapsed 0:18:46\n",
            "Sample: 0.8507360816001892 v/s 0.9296724761056667\n",
            "Batch 2860 of 4869. Elapsed 0:18:50\n",
            "Sample: 0.8771212697029114 v/s 0.8820132516909951\n",
            "Batch 2870 of 4869. Elapsed 0:18:54\n",
            "Sample: 0.8564760088920593 v/s 0.8487023891393835\n",
            "Batch 2880 of 4869. Elapsed 0:18:57\n",
            "Sample: 0.8653326034545898 v/s 0.8738440024790085\n",
            "Batch 2890 of 4869. Elapsed 0:19:01\n",
            "Sample: 0.8585813641548157 v/s 0.845948374703462\n",
            "Batch 2900 of 4869. Elapsed 0:19:05\n",
            "Sample: 0.7823076248168945 v/s 0.7532095350957178\n",
            "Batch 2910 of 4869. Elapsed 0:19:09\n",
            "Sample: 0.8397354483604431 v/s 0.8635978732953489\n",
            "Batch 2920 of 4869. Elapsed 0:19:13\n",
            "Sample: 0.8055098056793213 v/s 0.741101140065569\n",
            "Batch 2930 of 4869. Elapsed 0:19:17\n",
            "Sample: 0.8738232254981995 v/s 0.860065040702555\n",
            "Batch 2940 of 4869. Elapsed 0:19:20\n",
            "Sample: 0.874372661113739 v/s 0.8599765001061629\n",
            "Batch 2950 of 4869. Elapsed 0:19:25\n",
            "Sample: 0.77088463306427 v/s 0.765723122323383\n",
            "Batch 2960 of 4869. Elapsed 0:19:28\n",
            "Sample: 0.8466665744781494 v/s 0.810904801793844\n",
            "Batch 2970 of 4869. Elapsed 0:19:32\n",
            "Sample: 0.7734421491622925 v/s 0.7603183669327337\n",
            "Batch 2980 of 4869. Elapsed 0:19:36\n",
            "Sample: 0.8229942321777344 v/s 0.7547300684571526\n",
            "Batch 2990 of 4869. Elapsed 0:19:40\n",
            "Sample: 0.8407265543937683 v/s 0.7942021045965664\n",
            "Batch 3000 of 4869. Elapsed 0:19:44\n",
            "Sample: 0.8265629410743713 v/s 0.7394851828493377\n",
            "Batch 3010 of 4869. Elapsed 0:19:48\n",
            "Sample: 0.8233873844146729 v/s 0.7573643095785879\n",
            "Batch 3020 of 4869. Elapsed 0:19:52\n",
            "Sample: 0.8208268284797668 v/s 0.8134555780174505\n",
            "Batch 3030 of 4869. Elapsed 0:19:56\n",
            "Sample: 0.8529283404350281 v/s 0.8235499025598646\n",
            "Batch 3040 of 4869. Elapsed 0:20:00\n",
            "Sample: 0.867047131061554 v/s 0.8523948354770865\n",
            "Batch 3050 of 4869. Elapsed 0:20:04\n",
            "Sample: 0.8572384715080261 v/s 0.8059383016313316\n",
            "Batch 3060 of 4869. Elapsed 0:20:08\n",
            "Sample: 0.8232764005661011 v/s 0.8037694249901832\n",
            "Batch 3070 of 4869. Elapsed 0:20:12\n",
            "Sample: 0.8031213879585266 v/s 0.7952111018734572\n",
            "Batch 3080 of 4869. Elapsed 0:20:16\n",
            "Sample: 0.808234691619873 v/s 0.7728927632608443\n",
            "Batch 3090 of 4869. Elapsed 0:20:19\n",
            "Sample: 0.8273610472679138 v/s 0.8373948560841096\n",
            "Batch 3100 of 4869. Elapsed 0:20:23\n",
            "Sample: 0.8284378051757812 v/s 0.8181081967012745\n",
            "Batch 3110 of 4869. Elapsed 0:20:27\n",
            "Sample: 0.86089026927948 v/s 0.8568520502262114\n",
            "Batch 3120 of 4869. Elapsed 0:20:31\n",
            "Sample: 0.8029783964157104 v/s 0.7542655880645809\n",
            "Batch 3130 of 4869. Elapsed 0:20:35\n",
            "Sample: 0.884641170501709 v/s 0.893997879081021\n",
            "Batch 3140 of 4869. Elapsed 0:20:39\n",
            "Sample: 0.776219367980957 v/s 0.7409491261504115\n",
            "Batch 3150 of 4869. Elapsed 0:20:43\n",
            "Sample: 0.8361924886703491 v/s 0.8073993453007715\n",
            "Batch 3160 of 4869. Elapsed 0:20:47\n",
            "Sample: 0.871522843837738 v/s 0.8898293044507377\n",
            "Batch 3170 of 4869. Elapsed 0:20:51\n",
            "Sample: 0.8914055824279785 v/s 0.9000657816525466\n",
            "Batch 3180 of 4869. Elapsed 0:20:55\n",
            "Sample: 0.8861801624298096 v/s 0.918087136953606\n",
            "Batch 3190 of 4869. Elapsed 0:20:59\n",
            "Sample: 0.8946157693862915 v/s 0.8748909882200392\n",
            "Batch 3200 of 4869. Elapsed 0:21:02\n",
            "Sample: 0.8121321797370911 v/s 0.7404806635560321\n",
            "Batch 3210 of 4869. Elapsed 0:21:06\n",
            "Sample: 0.7741177678108215 v/s 0.7788067492010307\n",
            "Batch 3220 of 4869. Elapsed 0:21:10\n",
            "Sample: 0.8418134450912476 v/s 0.8482459859150471\n",
            "Batch 3230 of 4869. Elapsed 0:21:14\n",
            "Sample: 0.7400187849998474 v/s 0.7324832532328358\n",
            "Batch 3240 of 4869. Elapsed 0:21:18\n",
            "Sample: 0.8601956963539124 v/s 0.8614516308435626\n",
            "Batch 3250 of 4869. Elapsed 0:21:22\n",
            "Sample: 0.8031014800071716 v/s 0.8121201145834464\n",
            "Batch 3260 of 4869. Elapsed 0:21:26\n",
            "Sample: 0.8207027316093445 v/s 0.760299332129606\n",
            "Batch 3270 of 4869. Elapsed 0:21:30\n",
            "Sample: 0.814946174621582 v/s 0.8491966955853665\n",
            "Batch 3280 of 4869. Elapsed 0:21:34\n",
            "Sample: 0.8308759331703186 v/s 0.8274519676104469\n",
            "Batch 3290 of 4869. Elapsed 0:21:38\n",
            "Sample: 0.8456121683120728 v/s 0.8654620401983173\n",
            "Batch 3300 of 4869. Elapsed 0:21:41\n",
            "Sample: 0.8895689249038696 v/s 0.8526093277594102\n",
            "Batch 3310 of 4869. Elapsed 0:21:45\n",
            "Sample: 0.8306255340576172 v/s 0.7660782488438428\n",
            "Batch 3320 of 4869. Elapsed 0:21:49\n",
            "Sample: 0.8526389598846436 v/s 0.8785131745646652\n",
            "Batch 3330 of 4869. Elapsed 0:21:53\n",
            "Sample: 0.8648992776870728 v/s 0.8184698882220993\n",
            "Batch 3340 of 4869. Elapsed 0:21:57\n",
            "Sample: 0.8623645305633545 v/s 0.9086284849406833\n",
            "Batch 3350 of 4869. Elapsed 0:22:01\n",
            "Sample: 0.8417456150054932 v/s 0.8840256690331042\n",
            "Batch 3360 of 4869. Elapsed 0:22:05\n",
            "Sample: 0.8483583331108093 v/s 0.8255708079157426\n",
            "Batch 3370 of 4869. Elapsed 0:22:09\n",
            "Sample: 0.8935394287109375 v/s 0.8640979698621516\n",
            "Batch 3380 of 4869. Elapsed 0:22:13\n",
            "Sample: 0.7609633207321167 v/s 0.7102486154446642\n",
            "Batch 3390 of 4869. Elapsed 0:22:17\n",
            "Sample: 0.8464444279670715 v/s 0.8855750743723041\n",
            "Batch 3400 of 4869. Elapsed 0:22:21\n",
            "Sample: 0.8283807635307312 v/s 0.824291010951339\n",
            "Batch 3410 of 4869. Elapsed 0:22:25\n",
            "Sample: 0.803126335144043 v/s 0.7193527549547208\n",
            "Batch 3420 of 4869. Elapsed 0:22:29\n",
            "Sample: 0.7856370210647583 v/s 0.7824032003568921\n",
            "Batch 3430 of 4869. Elapsed 0:22:33\n",
            "Sample: 0.8793513178825378 v/s 0.9020793761930401\n",
            "Batch 3440 of 4869. Elapsed 0:22:36\n",
            "Sample: 0.8207935690879822 v/s 0.8165292969346003\n",
            "Batch 3450 of 4869. Elapsed 0:22:40\n",
            "Sample: 0.8674407005310059 v/s 0.8550926628951352\n",
            "Batch 3460 of 4869. Elapsed 0:22:44\n",
            "Sample: 0.7883191108703613 v/s 0.8097835095797318\n",
            "Batch 3470 of 4869. Elapsed 0:22:48\n",
            "Sample: 0.7963118553161621 v/s 0.8145894863239077\n",
            "Batch 3480 of 4869. Elapsed 0:22:52\n",
            "Sample: 0.8551957011222839 v/s 0.8719621961108449\n",
            "Batch 3490 of 4869. Elapsed 0:22:56\n",
            "Sample: 0.8373275399208069 v/s 0.8366457547001264\n",
            "Batch 3500 of 4869. Elapsed 0:23:00\n",
            "Sample: 0.8875964283943176 v/s 0.8806604056468275\n",
            "Batch 3510 of 4869. Elapsed 0:23:03\n",
            "Sample: 0.7253884673118591 v/s 0.745026877758435\n",
            "Batch 3520 of 4869. Elapsed 0:23:08\n",
            "Sample: 0.8013492226600647 v/s 0.7747089368105251\n",
            "Batch 3530 of 4869. Elapsed 0:23:12\n",
            "Sample: 0.8529823422431946 v/s 0.8252971451848999\n",
            "Batch 3540 of 4869. Elapsed 0:23:16\n",
            "Sample: 0.8350270986557007 v/s 0.7257143119054709\n",
            "Batch 3550 of 4869. Elapsed 0:23:20\n",
            "Sample: 0.8404175043106079 v/s 0.8086041720266963\n",
            "Batch 3560 of 4869. Elapsed 0:23:23\n",
            "Sample: 0.8168445229530334 v/s 0.827124565130816\n",
            "Batch 3570 of 4869. Elapsed 0:23:27\n",
            "Sample: 0.8477250933647156 v/s 0.8538204748921212\n",
            "Batch 3580 of 4869. Elapsed 0:23:31\n",
            "Sample: 0.8517804145812988 v/s 0.8676815577902457\n",
            "Batch 3590 of 4869. Elapsed 0:23:35\n",
            "Sample: 0.8321805596351624 v/s 0.8253439297853065\n",
            "Batch 3600 of 4869. Elapsed 0:23:39\n",
            "Sample: 0.8743268847465515 v/s 0.8100737933972747\n",
            "Batch 3610 of 4869. Elapsed 0:23:43\n",
            "Sample: 0.8472336530685425 v/s 0.8988048173983223\n",
            "Batch 3620 of 4869. Elapsed 0:23:46\n",
            "Sample: 0.780943751335144 v/s 0.8008860325702546\n",
            "Batch 3630 of 4869. Elapsed 0:23:50\n",
            "Sample: 0.8812897205352783 v/s 0.8179266135863141\n",
            "Batch 3640 of 4869. Elapsed 0:23:54\n",
            "Sample: 0.8188375234603882 v/s 0.7896939885674586\n",
            "Batch 3650 of 4869. Elapsed 0:23:58\n",
            "Sample: 0.8648643493652344 v/s 0.9398547784599162\n",
            "Batch 3660 of 4869. Elapsed 0:24:02\n",
            "Sample: 0.8878855109214783 v/s 0.8879155181028461\n",
            "Batch 3670 of 4869. Elapsed 0:24:06\n",
            "Sample: 0.8883373737335205 v/s 0.8370026917631909\n",
            "Batch 3680 of 4869. Elapsed 0:24:10\n",
            "Sample: 0.856179416179657 v/s 0.8748178186304659\n",
            "Batch 3690 of 4869. Elapsed 0:24:14\n",
            "Sample: 0.7300136089324951 v/s 0.6169366012932191\n",
            "Batch 3700 of 4869. Elapsed 0:24:18\n",
            "Sample: 0.8453120589256287 v/s 0.8691254238037999\n",
            "Batch 3710 of 4869. Elapsed 0:24:21\n",
            "Sample: 0.8611737489700317 v/s 0.7919260449298168\n",
            "Batch 3720 of 4869. Elapsed 0:24:25\n",
            "Sample: 0.7542024850845337 v/s 0.6625730689055415\n",
            "Batch 3730 of 4869. Elapsed 0:24:30\n",
            "Sample: 0.8018226623535156 v/s 0.7642180879231304\n",
            "Batch 3740 of 4869. Elapsed 0:24:33\n",
            "Sample: 0.8113909363746643 v/s 0.8469257880108293\n",
            "Batch 3750 of 4869. Elapsed 0:24:37\n",
            "Sample: 0.8906545042991638 v/s 0.9334161354957791\n",
            "Batch 3760 of 4869. Elapsed 0:24:41\n",
            "Sample: 0.7761915326118469 v/s 0.7410559672473276\n",
            "Batch 3770 of 4869. Elapsed 0:24:45\n",
            "Sample: 0.888317883014679 v/s 0.8717083805578018\n",
            "Batch 3780 of 4869. Elapsed 0:24:49\n",
            "Sample: 0.8127434253692627 v/s 0.8051857810056605\n",
            "Batch 3790 of 4869. Elapsed 0:24:53\n",
            "Sample: 0.8589402437210083 v/s 0.8360564089442548\n",
            "Batch 3800 of 4869. Elapsed 0:24:58\n",
            "Sample: 0.8641364574432373 v/s 0.8946709963027649\n",
            "Batch 3810 of 4869. Elapsed 0:25:01\n",
            "Sample: 0.8386669754981995 v/s 0.7707031231218348\n",
            "Batch 3820 of 4869. Elapsed 0:25:05\n",
            "Sample: 0.8718622922897339 v/s 0.774351746265468\n",
            "Batch 3830 of 4869. Elapsed 0:25:09\n",
            "Sample: 0.8606464266777039 v/s 0.8327024412195818\n",
            "Batch 3840 of 4869. Elapsed 0:25:13\n",
            "Sample: 0.8638014197349548 v/s 0.9159541007553663\n",
            "Batch 3850 of 4869. Elapsed 0:25:17\n",
            "Sample: 0.8361323475837708 v/s 0.7268038668156727\n",
            "Batch 3860 of 4869. Elapsed 0:25:21\n",
            "Sample: 0.8735691905021667 v/s 0.9160385673525797\n",
            "Batch 3870 of 4869. Elapsed 0:25:25\n",
            "Sample: 0.8364731073379517 v/s 0.7511045250946319\n",
            "Batch 3880 of 4869. Elapsed 0:25:29\n",
            "Sample: 0.7885885238647461 v/s 0.7189630862107581\n",
            "Batch 3890 of 4869. Elapsed 0:25:33\n",
            "Sample: 0.8413652777671814 v/s 0.8741415930153511\n",
            "Batch 3900 of 4869. Elapsed 0:25:37\n",
            "Sample: 0.885744035243988 v/s 0.896064280707623\n",
            "Batch 3910 of 4869. Elapsed 0:25:41\n",
            "Sample: 0.8728036284446716 v/s 0.8256033070927177\n",
            "Batch 3920 of 4869. Elapsed 0:25:45\n",
            "Sample: 0.8551523089408875 v/s 0.8831054983034222\n",
            "Batch 3930 of 4869. Elapsed 0:25:49\n",
            "Sample: 0.875304102897644 v/s 0.8489777491909724\n",
            "Batch 3940 of 4869. Elapsed 0:25:53\n",
            "Sample: 0.8093048334121704 v/s 0.7845251369043614\n",
            "Batch 3950 of 4869. Elapsed 0:25:56\n",
            "Sample: 0.8180012702941895 v/s 0.7890962695033917\n",
            "Batch 3960 of 4869. Elapsed 0:26:00\n",
            "Sample: 0.8347327709197998 v/s 0.8265799899561047\n",
            "Batch 3970 of 4869. Elapsed 0:26:04\n",
            "Sample: 0.8511744141578674 v/s 0.8260178234588775\n",
            "Batch 3980 of 4869. Elapsed 0:26:08\n",
            "Sample: 0.8590018153190613 v/s 0.8677583304075615\n",
            "Batch 3990 of 4869. Elapsed 0:26:12\n",
            "Sample: 0.815976083278656 v/s 0.7712795132131921\n",
            "Batch 4000 of 4869. Elapsed 0:26:16\n",
            "Sample: 0.8527871370315552 v/s 0.8158497647155222\n",
            "Batch 4010 of 4869. Elapsed 0:26:20\n",
            "Sample: 0.822910726070404 v/s 0.7522382109063409\n",
            "Batch 4020 of 4869. Elapsed 0:26:24\n",
            "Sample: 0.8394037485122681 v/s 0.8673985280502686\n",
            "Batch 4030 of 4869. Elapsed 0:26:28\n",
            "Sample: 0.8598372936248779 v/s 0.8146533322428282\n",
            "Batch 4040 of 4869. Elapsed 0:26:32\n",
            "Sample: 0.7992514967918396 v/s 0.7456341214132345\n",
            "Batch 4050 of 4869. Elapsed 0:26:35\n",
            "Sample: 0.868285059928894 v/s 0.8551834456954491\n",
            "Batch 4060 of 4869. Elapsed 0:26:39\n",
            "Sample: 0.7823914885520935 v/s 0.7559241457728709\n",
            "Batch 4070 of 4869. Elapsed 0:26:43\n",
            "Sample: 0.8374217748641968 v/s 0.8682606086555662\n",
            "Batch 4080 of 4869. Elapsed 0:26:47\n",
            "Sample: 0.8807806968688965 v/s 0.8515705530134802\n",
            "Batch 4090 of 4869. Elapsed 0:26:51\n",
            "Sample: 0.8155182003974915 v/s 0.884557712311903\n",
            "Batch 4100 of 4869. Elapsed 0:26:55\n",
            "Sample: 0.8379271626472473 v/s 0.7903173652226029\n",
            "Batch 4110 of 4869. Elapsed 0:26:59\n",
            "Sample: 0.8587499856948853 v/s 0.8109658794405955\n",
            "Batch 4120 of 4869. Elapsed 0:27:03\n",
            "Sample: 0.8289362192153931 v/s 0.9246671249138722\n",
            "Batch 4130 of 4869. Elapsed 0:27:07\n",
            "Sample: 0.8154881596565247 v/s 0.790290789231529\n",
            "Batch 4140 of 4869. Elapsed 0:27:11\n",
            "Sample: 0.8219936490058899 v/s 0.8069994603264623\n",
            "Batch 4150 of 4869. Elapsed 0:27:14\n",
            "Sample: 0.8277907371520996 v/s 0.8109618960343824\n",
            "Batch 4160 of 4869. Elapsed 0:27:18\n",
            "Sample: 0.8681299686431885 v/s 0.8733071947220374\n",
            "Batch 4170 of 4869. Elapsed 0:27:22\n",
            "Sample: 0.7185527086257935 v/s 0.6478060217522665\n",
            "Batch 4180 of 4869. Elapsed 0:27:26\n",
            "Sample: 0.8485701680183411 v/s 0.8092587651324505\n",
            "Batch 4190 of 4869. Elapsed 0:27:31\n",
            "Sample: 0.7840742468833923 v/s 0.7699042127621533\n",
            "Batch 4200 of 4869. Elapsed 0:27:35\n",
            "Sample: 0.8456093668937683 v/s 0.7824634400427064\n",
            "Batch 4210 of 4869. Elapsed 0:27:38\n",
            "Sample: 0.8720045685768127 v/s 0.8436114496899033\n",
            "Batch 4220 of 4869. Elapsed 0:27:42\n",
            "Sample: 0.86134934425354 v/s 0.8476526049266746\n",
            "Batch 4230 of 4869. Elapsed 0:27:46\n",
            "Sample: 0.8680351376533508 v/s 0.8328204639095299\n",
            "Batch 4240 of 4869. Elapsed 0:27:50\n",
            "Sample: 0.8670551776885986 v/s 0.9095734332136212\n",
            "Batch 4250 of 4869. Elapsed 0:27:54\n",
            "Sample: 0.8048216700553894 v/s 0.7346319913803143\n",
            "Batch 4260 of 4869. Elapsed 0:27:58\n",
            "Sample: 0.8317499160766602 v/s 0.8208655373405559\n",
            "Batch 4270 of 4869. Elapsed 0:28:02\n",
            "Sample: 0.8533635139465332 v/s 0.8279392726841945\n",
            "Batch 4280 of 4869. Elapsed 0:28:06\n",
            "Sample: 0.7888892889022827 v/s 0.8290375366367121\n",
            "Batch 4290 of 4869. Elapsed 0:28:10\n",
            "Sample: 0.8916030526161194 v/s 0.8490530216449691\n",
            "Batch 4300 of 4869. Elapsed 0:28:14\n",
            "Sample: 0.8209177255630493 v/s 0.8129810989063229\n",
            "Batch 4310 of 4869. Elapsed 0:28:18\n",
            "Sample: 0.7290131449699402 v/s 0.6956580636476014\n",
            "Batch 4320 of 4869. Elapsed 0:28:22\n",
            "Sample: 0.7590581178665161 v/s 0.744656471925512\n",
            "Batch 4330 of 4869. Elapsed 0:28:26\n",
            "Sample: 0.8959353566169739 v/s 0.8929230609895678\n",
            "Batch 4340 of 4869. Elapsed 0:28:30\n",
            "Sample: 0.8466059565544128 v/s 0.7400277720308754\n",
            "Batch 4350 of 4869. Elapsed 0:28:34\n",
            "Sample: 0.8600875735282898 v/s 0.8297693699836146\n",
            "Batch 4360 of 4869. Elapsed 0:28:38\n",
            "Sample: 0.8875815868377686 v/s 0.924524303502555\n",
            "Batch 4370 of 4869. Elapsed 0:28:42\n",
            "Sample: 0.792777955532074 v/s 0.739535924595415\n",
            "Batch 4380 of 4869. Elapsed 0:28:46\n",
            "Sample: 0.8420268297195435 v/s 0.8014288627570575\n",
            "Batch 4390 of 4869. Elapsed 0:28:50\n",
            "Sample: 0.8849276304244995 v/s 0.8334418232963087\n",
            "Batch 4400 of 4869. Elapsed 0:28:54\n",
            "Sample: 0.761946976184845 v/s 0.7264131770963799\n",
            "Batch 4410 of 4869. Elapsed 0:28:58\n",
            "Sample: 0.8368034958839417 v/s 0.893876240550159\n",
            "Batch 4420 of 4869. Elapsed 0:29:02\n",
            "Sample: 0.8671871423721313 v/s 0.834313617494795\n",
            "Batch 4430 of 4869. Elapsed 0:29:06\n",
            "Sample: 0.8650830388069153 v/s 0.8597701203175951\n",
            "Batch 4440 of 4869. Elapsed 0:29:09\n",
            "Sample: 0.8578290343284607 v/s 0.8643370253961437\n",
            "Batch 4450 of 4869. Elapsed 0:29:13\n",
            "Sample: 0.8963675498962402 v/s 0.8917158085984644\n",
            "Batch 4460 of 4869. Elapsed 0:29:17\n",
            "Sample: 0.8391718864440918 v/s 0.8215392466818408\n",
            "Batch 4470 of 4869. Elapsed 0:29:21\n",
            "Sample: 0.8486016392707825 v/s 0.8167679334562706\n",
            "Batch 4480 of 4869. Elapsed 0:29:25\n",
            "Sample: 0.8276413083076477 v/s 0.7858551423267398\n",
            "Batch 4490 of 4869. Elapsed 0:29:29\n",
            "Sample: 0.8535627126693726 v/s 0.8027795260420186\n",
            "Batch 4500 of 4869. Elapsed 0:29:33\n",
            "Sample: 0.822505533695221 v/s 0.7562277469630343\n",
            "Batch 4510 of 4869. Elapsed 0:29:37\n",
            "Sample: 0.8619614243507385 v/s 0.8512489528419882\n",
            "Batch 4520 of 4869. Elapsed 0:29:41\n",
            "Sample: 0.7468575239181519 v/s 0.6926270363780234\n",
            "Batch 4530 of 4869. Elapsed 0:29:44\n",
            "Sample: 0.8342812657356262 v/s 0.7799850024064644\n",
            "Batch 4540 of 4869. Elapsed 0:29:48\n",
            "Sample: 0.814384400844574 v/s 0.7058647850621206\n",
            "Batch 4550 of 4869. Elapsed 0:29:52\n",
            "Sample: 0.845235288143158 v/s 0.8198006992401844\n",
            "Batch 4560 of 4869. Elapsed 0:29:56\n",
            "Sample: 0.8483378291130066 v/s 0.7937610477822654\n",
            "Batch 4570 of 4869. Elapsed 0:30:00\n",
            "Sample: 0.8036687970161438 v/s 0.7884895358925424\n",
            "Batch 4580 of 4869. Elapsed 0:30:04\n",
            "Sample: 0.7831763625144958 v/s 0.7156928583390627\n",
            "Batch 4590 of 4869. Elapsed 0:30:08\n",
            "Sample: 0.8076074123382568 v/s 0.853938954353368\n",
            "Batch 4600 of 4869. Elapsed 0:30:12\n",
            "Sample: 0.7697604894638062 v/s 0.769759707148749\n",
            "Batch 4610 of 4869. Elapsed 0:30:16\n",
            "Sample: 0.8495539426803589 v/s 0.8562953822907179\n",
            "Batch 4620 of 4869. Elapsed 0:30:19\n",
            "Sample: 0.7132254838943481 v/s 0.7048816598668224\n",
            "Batch 4630 of 4869. Elapsed 0:30:23\n",
            "Sample: 0.8353239297866821 v/s 0.7893028389398944\n",
            "Batch 4640 of 4869. Elapsed 0:30:27\n",
            "Sample: 0.8341396450996399 v/s 0.8796662671282511\n",
            "Batch 4650 of 4869. Elapsed 0:30:31\n",
            "Sample: 0.8431316614151001 v/s 0.8648486091526765\n",
            "Batch 4660 of 4869. Elapsed 0:30:36\n",
            "Sample: 0.8419160842895508 v/s 0.7738871137799704\n",
            "Batch 4670 of 4869. Elapsed 0:30:39\n",
            "Sample: 0.7809648513793945 v/s 0.727251020693823\n",
            "Batch 4680 of 4869. Elapsed 0:30:44\n",
            "Sample: 0.7719376683235168 v/s 0.7755110458232253\n",
            "Batch 4690 of 4869. Elapsed 0:30:47\n",
            "Sample: 0.7425256967544556 v/s 0.7121978310761218\n",
            "Batch 4700 of 4869. Elapsed 0:30:52\n",
            "Sample: 0.8557474613189697 v/s 0.8114795274984244\n",
            "Batch 4710 of 4869. Elapsed 0:30:56\n",
            "Sample: 0.8749219179153442 v/s 0.886908190543239\n",
            "Batch 4720 of 4869. Elapsed 0:30:59\n",
            "Sample: 0.8228247761726379 v/s 0.7484165558303503\n",
            "Batch 4730 of 4869. Elapsed 0:31:03\n",
            "Sample: 0.8510249853134155 v/s 0.9257289351709309\n",
            "Batch 4740 of 4869. Elapsed 0:31:07\n",
            "Sample: 0.8455696105957031 v/s 0.8168741009386171\n",
            "Batch 4750 of 4869. Elapsed 0:31:11\n",
            "Sample: 0.818743109703064 v/s 0.7892325966881008\n",
            "Batch 4760 of 4869. Elapsed 0:31:15\n",
            "Sample: 0.8319942951202393 v/s 0.8022437315200451\n",
            "Batch 4770 of 4869. Elapsed 0:31:19\n",
            "Sample: 0.8768196105957031 v/s 0.9077071648149055\n",
            "Batch 4780 of 4869. Elapsed 0:31:23\n",
            "Sample: 0.8320118188858032 v/s 0.8356634027505396\n",
            "Batch 4790 of 4869. Elapsed 0:31:27\n",
            "Sample: 0.8307535648345947 v/s 0.8007872814170892\n",
            "Batch 4800 of 4869. Elapsed 0:31:31\n",
            "Sample: 0.8074098229408264 v/s 0.7440224817674977\n",
            "Batch 4810 of 4869. Elapsed 0:31:35\n",
            "Sample: 0.8737905025482178 v/s 0.92412874818461\n",
            "Batch 4820 of 4869. Elapsed 0:31:39\n",
            "Sample: 0.8219856023788452 v/s 0.7116694714602446\n",
            "Batch 4830 of 4869. Elapsed 0:31:43\n",
            "Sample: 0.8839401602745056 v/s 0.8899557570867211\n",
            "Batch 4840 of 4869. Elapsed 0:31:46\n",
            "Sample: 0.7742626667022705 v/s 0.6343495019476381\n",
            "Batch 4850 of 4869. Elapsed 0:31:51\n",
            "Sample: 0.7955583930015564 v/s 0.7134610626848656\n",
            "Batch 4860 of 4869. Elapsed 0:31:54\n",
            "Average generator training loss for epoch 1 : 1.382571816444397\n",
            "Epoch took 0:31:57\n",
            "\n",
            "============= Generator Epoch 2 / 2 =================\n",
            "Sample: 0.7864506840705872 v/s 0.6475004419147583\n",
            "Batch 10 of 4869. Elapsed 0:00:04\n",
            "Sample: 0.8399743437767029 v/s 0.7884683759034172\n",
            "Batch 20 of 4869. Elapsed 0:00:08\n",
            "Sample: 0.8015198111534119 v/s 0.7591419910318111\n",
            "Batch 30 of 4869. Elapsed 0:00:12\n",
            "Sample: 0.8446701169013977 v/s 0.7920975527719593\n",
            "Batch 40 of 4869. Elapsed 0:00:16\n",
            "Sample: 0.863376796245575 v/s 0.7876729370986575\n",
            "Batch 50 of 4869. Elapsed 0:00:19\n",
            "Sample: 0.8185198307037354 v/s 0.7957741521773078\n",
            "Batch 60 of 4869. Elapsed 0:00:23\n",
            "Sample: 0.8603042364120483 v/s 0.90887615250168\n",
            "Batch 70 of 4869. Elapsed 0:00:27\n",
            "Sample: 0.7809564471244812 v/s 0.6881811398914924\n",
            "Batch 80 of 4869. Elapsed 0:00:31\n",
            "Sample: 0.8181819319725037 v/s 0.8270208624776797\n",
            "Batch 90 of 4869. Elapsed 0:00:35\n",
            "Sample: 0.8341394662857056 v/s 0.759957978433338\n",
            "Batch 100 of 4869. Elapsed 0:00:39\n",
            "Sample: 0.854189395904541 v/s 0.825174372147699\n",
            "Batch 110 of 4869. Elapsed 0:00:43\n",
            "Sample: 0.7312264442443848 v/s 0.6745155403545914\n",
            "Batch 120 of 4869. Elapsed 0:00:47\n",
            "Sample: 0.9058210849761963 v/s 0.9175620711123328\n",
            "Batch 130 of 4869. Elapsed 0:00:51\n",
            "Sample: 0.8725141882896423 v/s 0.8177254901253731\n",
            "Batch 140 of 4869. Elapsed 0:00:55\n",
            "Sample: 0.8092626929283142 v/s 0.824999346097975\n",
            "Batch 150 of 4869. Elapsed 0:00:59\n",
            "Sample: 0.8097009658813477 v/s 0.7979130918502506\n",
            "Batch 160 of 4869. Elapsed 0:01:03\n",
            "Sample: 0.8200955986976624 v/s 0.7244652157031837\n",
            "Batch 170 of 4869. Elapsed 0:01:07\n",
            "Sample: 0.815955638885498 v/s 0.7882252968924667\n",
            "Batch 180 of 4869. Elapsed 0:01:11\n",
            "Sample: 0.8496935367584229 v/s 0.830108808321891\n",
            "Batch 190 of 4869. Elapsed 0:01:15\n",
            "Sample: 0.8317253589630127 v/s 0.7908627413559367\n",
            "Batch 200 of 4869. Elapsed 0:01:19\n",
            "Sample: 0.7924057245254517 v/s 0.8071988806643894\n",
            "Batch 210 of 4869. Elapsed 0:01:22\n",
            "Sample: 0.8614562749862671 v/s 0.8625419725199631\n",
            "Batch 220 of 4869. Elapsed 0:01:26\n",
            "Sample: 0.8461893200874329 v/s 0.8537124508000075\n",
            "Batch 230 of 4869. Elapsed 0:01:30\n",
            "Sample: 0.8613654971122742 v/s 0.8392609681966873\n",
            "Batch 240 of 4869. Elapsed 0:01:34\n",
            "Sample: 0.8675137162208557 v/s 0.8312389954947044\n",
            "Batch 250 of 4869. Elapsed 0:01:38\n",
            "Sample: 0.8202759027481079 v/s 0.8132941219880607\n",
            "Batch 260 of 4869. Elapsed 0:01:42\n",
            "Sample: 0.7686490416526794 v/s 0.6467822517585422\n",
            "Batch 270 of 4869. Elapsed 0:01:46\n",
            "Sample: 0.8023556470870972 v/s 0.7407962826755096\n",
            "Batch 280 of 4869. Elapsed 0:01:50\n",
            "Sample: 0.8286444544792175 v/s 0.8703760371963924\n",
            "Batch 290 of 4869. Elapsed 0:01:54\n",
            "Sample: 0.8378592133522034 v/s 0.883227857903429\n",
            "Batch 300 of 4869. Elapsed 0:01:57\n",
            "Sample: 0.8323912024497986 v/s 0.8118160760148593\n",
            "Batch 310 of 4869. Elapsed 0:02:01\n",
            "Sample: 0.8545753359794617 v/s 0.8659404369466646\n",
            "Batch 320 of 4869. Elapsed 0:02:05\n",
            "Sample: 0.8102392554283142 v/s 0.7177647892429351\n",
            "Batch 330 of 4869. Elapsed 0:02:09\n",
            "Sample: 0.8525025248527527 v/s 0.7785654597178849\n",
            "Batch 340 of 4869. Elapsed 0:02:13\n",
            "Sample: 0.8104075789451599 v/s 0.7610029825070838\n",
            "Batch 350 of 4869. Elapsed 0:02:17\n",
            "Sample: 0.8495635986328125 v/s 0.8332567270120521\n",
            "Batch 360 of 4869. Elapsed 0:02:21\n",
            "Sample: 0.8415188193321228 v/s 0.8106099087384296\n",
            "Batch 370 of 4869. Elapsed 0:02:24\n",
            "Sample: 0.8286959528923035 v/s 0.8420254141816994\n",
            "Batch 380 of 4869. Elapsed 0:02:28\n",
            "Sample: 0.8713743686676025 v/s 0.8104832272089932\n",
            "Batch 390 of 4869. Elapsed 0:02:32\n",
            "Sample: 0.728442370891571 v/s 0.7470008387567302\n",
            "Batch 400 of 4869. Elapsed 0:02:36\n",
            "Sample: 0.796567440032959 v/s 0.8564659109846265\n",
            "Batch 410 of 4869. Elapsed 0:02:40\n",
            "Sample: 0.8719809055328369 v/s 0.9160542801597018\n",
            "Batch 420 of 4869. Elapsed 0:02:44\n",
            "Sample: 0.8502107858657837 v/s 0.8704680770654001\n",
            "Batch 430 of 4869. Elapsed 0:02:48\n",
            "Sample: 0.8368803262710571 v/s 0.8344669023068464\n",
            "Batch 440 of 4869. Elapsed 0:02:52\n",
            "Sample: 0.8647032380104065 v/s 0.8218758288278428\n",
            "Batch 450 of 4869. Elapsed 0:02:56\n",
            "Sample: 0.7826135158538818 v/s 0.7713753835157228\n",
            "Batch 460 of 4869. Elapsed 0:03:00\n",
            "Sample: 0.8615744709968567 v/s 0.8810304699059309\n",
            "Batch 470 of 4869. Elapsed 0:03:04\n",
            "Sample: 0.847416341304779 v/s 0.8547918694927171\n",
            "Batch 480 of 4869. Elapsed 0:03:08\n",
            "Sample: 0.8734177350997925 v/s 0.8211370913437579\n",
            "Batch 490 of 4869. Elapsed 0:03:12\n",
            "Sample: 0.8659651875495911 v/s 0.8423792827830043\n",
            "Batch 500 of 4869. Elapsed 0:03:16\n",
            "Sample: 0.8690040111541748 v/s 0.778328307689538\n",
            "Batch 510 of 4869. Elapsed 0:03:20\n",
            "Sample: 0.8647772073745728 v/s 0.8996825109263864\n",
            "Batch 520 of 4869. Elapsed 0:03:24\n",
            "Sample: 0.8478417992591858 v/s 0.8002781392442478\n",
            "Batch 530 of 4869. Elapsed 0:03:28\n",
            "Sample: 0.774590015411377 v/s 0.6918036986035321\n",
            "Batch 540 of 4869. Elapsed 0:03:31\n",
            "Sample: 0.8839346766471863 v/s 0.8816878666022376\n",
            "Batch 550 of 4869. Elapsed 0:03:35\n",
            "Sample: 0.8240060210227966 v/s 0.7878401596745148\n",
            "Batch 560 of 4869. Elapsed 0:03:39\n",
            "Sample: 0.8271260261535645 v/s 0.8769760596371201\n",
            "Batch 570 of 4869. Elapsed 0:03:43\n",
            "Sample: 0.8552042841911316 v/s 0.7601965486850252\n",
            "Batch 580 of 4869. Elapsed 0:03:47\n",
            "Sample: 0.8247516751289368 v/s 0.7552609824750021\n",
            "Batch 590 of 4869. Elapsed 0:03:50\n",
            "Sample: 0.8007287383079529 v/s 0.7793840730712703\n",
            "Batch 600 of 4869. Elapsed 0:03:54\n",
            "Sample: 0.8799367547035217 v/s 0.8754058997954198\n",
            "Batch 610 of 4869. Elapsed 0:03:58\n",
            "Sample: 0.8564023971557617 v/s 0.8713353724093772\n",
            "Batch 620 of 4869. Elapsed 0:04:02\n",
            "Sample: 0.8425487875938416 v/s 0.791439239721498\n",
            "Batch 630 of 4869. Elapsed 0:04:06\n",
            "Sample: 0.8712407946586609 v/s 0.7692762278998503\n",
            "Batch 640 of 4869. Elapsed 0:04:10\n",
            "Sample: 0.7574780583381653 v/s 0.7123611835820602\n",
            "Batch 650 of 4869. Elapsed 0:04:14\n",
            "Sample: 0.8204429149627686 v/s 0.8589134993969498\n",
            "Batch 660 of 4869. Elapsed 0:04:18\n",
            "Sample: 0.8022470474243164 v/s 0.7645739449523786\n",
            "Batch 670 of 4869. Elapsed 0:04:21\n",
            "Sample: 0.852545440196991 v/s 0.7650084530743784\n",
            "Batch 680 of 4869. Elapsed 0:04:26\n",
            "Sample: 0.8240541815757751 v/s 0.7653814155632089\n",
            "Batch 690 of 4869. Elapsed 0:04:30\n",
            "Sample: 0.8319286704063416 v/s 0.7495580780377513\n",
            "Batch 700 of 4869. Elapsed 0:04:33\n",
            "Sample: 0.8561339974403381 v/s 0.8345432791587926\n",
            "Batch 710 of 4869. Elapsed 0:04:37\n",
            "Sample: 0.8649587631225586 v/s 0.8552185995046028\n",
            "Batch 720 of 4869. Elapsed 0:04:42\n",
            "Sample: 0.8349149227142334 v/s 0.7954315622367126\n",
            "Batch 730 of 4869. Elapsed 0:04:46\n",
            "Sample: 0.9209529757499695 v/s 0.9353589323785941\n",
            "Batch 740 of 4869. Elapsed 0:04:50\n",
            "Sample: 0.8288248181343079 v/s 0.7421125958726443\n",
            "Batch 750 of 4869. Elapsed 0:04:53\n",
            "Sample: 0.8065232634544373 v/s 0.7918576374040686\n",
            "Batch 760 of 4869. Elapsed 0:04:57\n",
            "Sample: 0.8601576089859009 v/s 0.878010316907639\n",
            "Batch 770 of 4869. Elapsed 0:05:01\n",
            "Sample: 0.8095195889472961 v/s 0.8282226624318357\n",
            "Batch 780 of 4869. Elapsed 0:05:05\n",
            "Sample: 0.788989245891571 v/s 0.779435947411709\n",
            "Batch 790 of 4869. Elapsed 0:05:09\n",
            "Sample: 0.8189522624015808 v/s 0.7889962647047597\n",
            "Batch 800 of 4869. Elapsed 0:05:13\n",
            "Sample: 0.8210316896438599 v/s 0.8427208211722226\n",
            "Batch 810 of 4869. Elapsed 0:05:17\n",
            "Sample: 0.8325707316398621 v/s 0.8436371190308775\n",
            "Batch 820 of 4869. Elapsed 0:05:20\n",
            "Sample: 0.8513751029968262 v/s 0.8039518410262035\n",
            "Batch 830 of 4869. Elapsed 0:05:24\n",
            "Sample: 0.8262150287628174 v/s 0.7462783325539354\n",
            "Batch 840 of 4869. Elapsed 0:05:28\n",
            "Sample: 0.7991721630096436 v/s 0.7436644542008362\n",
            "Batch 850 of 4869. Elapsed 0:05:32\n",
            "Sample: 0.7609115839004517 v/s 0.7714062758387311\n",
            "Batch 860 of 4869. Elapsed 0:05:36\n",
            "Sample: 0.8425251245498657 v/s 0.8008116920348561\n",
            "Batch 870 of 4869. Elapsed 0:05:40\n",
            "Sample: 0.8217718005180359 v/s 0.8458136287313722\n",
            "Batch 880 of 4869. Elapsed 0:05:44\n",
            "Sample: 0.7516607642173767 v/s 0.7073960235013345\n",
            "Batch 890 of 4869. Elapsed 0:05:48\n",
            "Sample: 0.8357709646224976 v/s 0.8335058777036466\n",
            "Batch 900 of 4869. Elapsed 0:05:51\n",
            "Sample: 0.8059948086738586 v/s 0.8073510900907501\n",
            "Batch 910 of 4869. Elapsed 0:05:55\n",
            "Sample: 0.8904994130134583 v/s 0.93278338624149\n",
            "Batch 920 of 4869. Elapsed 0:05:59\n",
            "Sample: 0.8828638195991516 v/s 0.8629228626166688\n",
            "Batch 930 of 4869. Elapsed 0:06:03\n",
            "Sample: 0.8641018867492676 v/s 0.8764554213140779\n",
            "Batch 940 of 4869. Elapsed 0:06:07\n",
            "Sample: 0.8283311128616333 v/s 0.800353853315863\n",
            "Batch 950 of 4869. Elapsed 0:06:11\n",
            "Sample: 0.8322427868843079 v/s 0.8075813210718533\n",
            "Batch 960 of 4869. Elapsed 0:06:15\n",
            "Sample: 0.8132404685020447 v/s 0.7568033528481192\n",
            "Batch 970 of 4869. Elapsed 0:06:19\n",
            "Sample: 0.8492149114608765 v/s 0.8009089732980409\n",
            "Batch 980 of 4869. Elapsed 0:06:23\n",
            "Sample: 0.8528366684913635 v/s 0.808654561039797\n",
            "Batch 990 of 4869. Elapsed 0:06:27\n",
            "Sample: 0.8356732726097107 v/s 0.8388008905110279\n",
            "Batch 1000 of 4869. Elapsed 0:06:31\n",
            "Sample: 0.8508939743041992 v/s 0.8354790934273282\n",
            "Batch 1010 of 4869. Elapsed 0:06:34\n",
            "Sample: 0.8318511247634888 v/s 0.8201148044090651\n",
            "Batch 1020 of 4869. Elapsed 0:06:38\n",
            "Sample: 0.8789809346199036 v/s 0.862183372511315\n",
            "Batch 1030 of 4869. Elapsed 0:06:42\n",
            "Sample: 0.8783005475997925 v/s 0.9095716635079869\n",
            "Batch 1040 of 4869. Elapsed 0:06:46\n",
            "Sample: 0.7930823564529419 v/s 0.7340641736314238\n",
            "Batch 1050 of 4869. Elapsed 0:06:50\n",
            "Sample: 0.7703250050544739 v/s 0.7340143713522693\n",
            "Batch 1060 of 4869. Elapsed 0:06:54\n",
            "Sample: 0.82138991355896 v/s 0.7700952419880728\n",
            "Batch 1070 of 4869. Elapsed 0:06:58\n",
            "Sample: 0.8362256288528442 v/s 0.900047266832065\n",
            "Batch 1080 of 4869. Elapsed 0:07:02\n",
            "Sample: 0.8396616578102112 v/s 0.8846451766490564\n",
            "Batch 1090 of 4869. Elapsed 0:07:06\n",
            "Sample: 0.8816302418708801 v/s 0.8710425964930071\n",
            "Batch 1100 of 4869. Elapsed 0:07:10\n",
            "Sample: 0.8475868701934814 v/s 0.774456358214996\n",
            "Batch 1110 of 4869. Elapsed 0:07:14\n",
            "Sample: 0.7738275527954102 v/s 0.7751767196607224\n",
            "Batch 1120 of 4869. Elapsed 0:07:18\n",
            "Sample: 0.9116420149803162 v/s 0.9286131493696829\n",
            "Batch 1130 of 4869. Elapsed 0:07:22\n",
            "Sample: 0.8168582320213318 v/s 0.7910886635129211\n",
            "Batch 1140 of 4869. Elapsed 0:07:26\n",
            "Sample: 0.8347604274749756 v/s 0.8033940091332417\n",
            "Batch 1150 of 4869. Elapsed 0:07:29\n",
            "Sample: 0.8356452584266663 v/s 0.7585010166717452\n",
            "Batch 1160 of 4869. Elapsed 0:07:33\n",
            "Sample: 0.8254842162132263 v/s 0.7215842142080008\n",
            "Batch 1170 of 4869. Elapsed 0:07:37\n",
            "Sample: 0.8482027649879456 v/s 0.7891516340128273\n",
            "Batch 1180 of 4869. Elapsed 0:07:41\n",
            "Sample: 0.8423377871513367 v/s 0.7894689687119744\n",
            "Batch 1190 of 4869. Elapsed 0:07:45\n",
            "Sample: 0.8747029900550842 v/s 0.8606824209426492\n",
            "Batch 1200 of 4869. Elapsed 0:07:49\n",
            "Sample: 0.8716006278991699 v/s 0.9593079992128999\n",
            "Batch 1210 of 4869. Elapsed 0:07:53\n",
            "Sample: 0.8188804984092712 v/s 0.7487578123996341\n",
            "Batch 1220 of 4869. Elapsed 0:07:57\n",
            "Sample: 0.8869014978408813 v/s 0.880159322168849\n",
            "Batch 1230 of 4869. Elapsed 0:08:01\n",
            "Sample: 0.7902349829673767 v/s 0.7174737007319456\n",
            "Batch 1240 of 4869. Elapsed 0:08:05\n",
            "Sample: 0.8425003290176392 v/s 0.7726823015121213\n",
            "Batch 1250 of 4869. Elapsed 0:08:09\n",
            "Sample: 0.777127206325531 v/s 0.8603566771529289\n",
            "Batch 1260 of 4869. Elapsed 0:08:13\n",
            "Sample: 0.859798014163971 v/s 0.8325622340826012\n",
            "Batch 1270 of 4869. Elapsed 0:08:17\n",
            "Sample: 0.8692786693572998 v/s 0.8146982557960352\n",
            "Batch 1280 of 4869. Elapsed 0:08:20\n",
            "Sample: 0.7752593159675598 v/s 0.7231943946631758\n",
            "Batch 1290 of 4869. Elapsed 0:08:24\n",
            "Sample: 0.7702799439430237 v/s 0.6849520278452805\n",
            "Batch 1300 of 4869. Elapsed 0:08:28\n",
            "Sample: 0.7504397034645081 v/s 0.6772682940842717\n",
            "Batch 1310 of 4869. Elapsed 0:08:32\n",
            "Sample: 0.7277738451957703 v/s 0.7770577489165595\n",
            "Batch 1320 of 4869. Elapsed 0:08:36\n",
            "Sample: 0.8850553631782532 v/s 0.8835954757457495\n",
            "Batch 1330 of 4869. Elapsed 0:08:40\n",
            "Sample: 0.8250794410705566 v/s 0.7976050537517098\n",
            "Batch 1340 of 4869. Elapsed 0:08:43\n",
            "Sample: 0.8115863800048828 v/s 0.7993269831294323\n",
            "Batch 1350 of 4869. Elapsed 0:08:47\n",
            "Sample: 0.8615485429763794 v/s 0.8545581853403229\n",
            "Batch 1360 of 4869. Elapsed 0:08:51\n",
            "Sample: 0.8378854393959045 v/s 0.7985311529790523\n",
            "Batch 1370 of 4869. Elapsed 0:08:55\n",
            "Sample: 0.7718894481658936 v/s 0.7617559852504121\n",
            "Batch 1380 of 4869. Elapsed 0:08:59\n",
            "Sample: 0.8316746950149536 v/s 0.81124570589432\n",
            "Batch 1390 of 4869. Elapsed 0:09:03\n",
            "Sample: 0.7868260145187378 v/s 0.7861577127604278\n",
            "Batch 1400 of 4869. Elapsed 0:09:07\n",
            "Sample: 0.846393346786499 v/s 0.7606590359331461\n",
            "Batch 1410 of 4869. Elapsed 0:09:10\n",
            "Sample: 0.8082091212272644 v/s 0.7817049545088868\n",
            "Batch 1420 of 4869. Elapsed 0:09:14\n",
            "Sample: 0.876392662525177 v/s 0.8381309621736749\n",
            "Batch 1430 of 4869. Elapsed 0:09:18\n",
            "Sample: 0.8618579506874084 v/s 0.7741772631703928\n",
            "Batch 1440 of 4869. Elapsed 0:09:22\n",
            "Sample: 0.8768969178199768 v/s 0.8365021983511941\n",
            "Batch 1450 of 4869. Elapsed 0:09:26\n",
            "Sample: 0.8785452246665955 v/s 0.8601807270655694\n",
            "Batch 1460 of 4869. Elapsed 0:09:30\n",
            "Sample: 0.8126798272132874 v/s 0.8175126813039356\n",
            "Batch 1470 of 4869. Elapsed 0:09:34\n",
            "Sample: 0.7367871999740601 v/s 0.7204648479389301\n",
            "Batch 1480 of 4869. Elapsed 0:09:38\n",
            "Sample: 0.7256213426589966 v/s 0.6927293216830132\n",
            "Batch 1490 of 4869. Elapsed 0:09:41\n",
            "Sample: 0.8397990465164185 v/s 0.856418574410986\n",
            "Batch 1500 of 4869. Elapsed 0:09:45\n",
            "Sample: 0.8449814915657043 v/s 0.7930105026239075\n",
            "Batch 1510 of 4869. Elapsed 0:09:49\n",
            "Sample: 0.8677075505256653 v/s 0.9294033660555711\n",
            "Batch 1520 of 4869. Elapsed 0:09:53\n",
            "Sample: 0.8411215543746948 v/s 0.8981747262309087\n",
            "Batch 1530 of 4869. Elapsed 0:09:57\n",
            "Sample: 0.8075956106185913 v/s 0.7770394616974371\n",
            "Batch 1540 of 4869. Elapsed 0:10:01\n",
            "Sample: 0.8381845355033875 v/s 0.7721196580713061\n",
            "Batch 1550 of 4869. Elapsed 0:10:05\n",
            "Sample: 0.8665989637374878 v/s 0.9150695489071609\n",
            "Batch 1560 of 4869. Elapsed 0:10:09\n",
            "Sample: 0.7665349841117859 v/s 0.6873181013555886\n",
            "Batch 1570 of 4869. Elapsed 0:10:13\n",
            "Sample: 0.8671013116836548 v/s 0.8147649004221191\n",
            "Batch 1580 of 4869. Elapsed 0:10:17\n",
            "Sample: 0.7866857051849365 v/s 0.7533454238485593\n",
            "Batch 1590 of 4869. Elapsed 0:10:20\n",
            "Sample: 0.8000301122665405 v/s 0.7373462144810542\n",
            "Batch 1600 of 4869. Elapsed 0:10:24\n",
            "Sample: 0.849113941192627 v/s 0.8052961215769454\n",
            "Batch 1610 of 4869. Elapsed 0:10:28\n",
            "Sample: 0.8210519552230835 v/s 0.7890548810853665\n",
            "Batch 1620 of 4869. Elapsed 0:10:32\n",
            "Sample: 0.8391310572624207 v/s 0.7109646493845732\n",
            "Batch 1630 of 4869. Elapsed 0:10:36\n",
            "Sample: 0.842485785484314 v/s 0.7633760208882653\n",
            "Batch 1640 of 4869. Elapsed 0:10:39\n",
            "Sample: 0.8618156909942627 v/s 0.8720833294696425\n",
            "Batch 1650 of 4869. Elapsed 0:10:43\n",
            "Sample: 0.8380823135375977 v/s 0.9142798622800258\n",
            "Batch 1660 of 4869. Elapsed 0:10:47\n",
            "Sample: 0.821665346622467 v/s 0.8038809688530455\n",
            "Batch 1670 of 4869. Elapsed 0:10:51\n",
            "Sample: 0.7453567385673523 v/s 0.727874475813997\n",
            "Batch 1680 of 4869. Elapsed 0:10:55\n",
            "Sample: 0.8907897472381592 v/s 0.9117930528218798\n",
            "Batch 1690 of 4869. Elapsed 0:10:59\n",
            "Sample: 0.8447544574737549 v/s 0.823090988909568\n",
            "Batch 1700 of 4869. Elapsed 0:11:03\n",
            "Sample: 0.8317660093307495 v/s 0.8377212026777722\n",
            "Batch 1710 of 4869. Elapsed 0:11:07\n",
            "Sample: 0.8305389881134033 v/s 0.7260813557261918\n",
            "Batch 1720 of 4869. Elapsed 0:11:11\n",
            "Sample: 0.862614095211029 v/s 0.8460294292119275\n",
            "Batch 1730 of 4869. Elapsed 0:11:15\n",
            "Sample: 0.8553832769393921 v/s 0.7576458354955439\n",
            "Batch 1740 of 4869. Elapsed 0:11:19\n",
            "Sample: 0.8217235207557678 v/s 0.8339252668397531\n",
            "Batch 1750 of 4869. Elapsed 0:11:23\n",
            "Sample: 0.8575824499130249 v/s 0.8712545793539594\n",
            "Batch 1760 of 4869. Elapsed 0:11:27\n",
            "Sample: 0.8434290885925293 v/s 0.7934296752535871\n",
            "Batch 1770 of 4869. Elapsed 0:11:31\n",
            "Sample: 0.8787800669670105 v/s 0.8964064604193779\n",
            "Batch 1780 of 4869. Elapsed 0:11:35\n",
            "Sample: 0.8134096264839172 v/s 0.855687878367329\n",
            "Batch 1790 of 4869. Elapsed 0:11:38\n",
            "Sample: 0.815801203250885 v/s 0.7977855330193482\n",
            "Batch 1800 of 4869. Elapsed 0:11:42\n",
            "Sample: 0.8128801584243774 v/s 0.7956711615941665\n",
            "Batch 1810 of 4869. Elapsed 0:11:47\n",
            "Sample: 0.8864582180976868 v/s 0.9207896587663136\n",
            "Batch 1820 of 4869. Elapsed 0:11:50\n",
            "Sample: 0.7681553363800049 v/s 0.699642130171076\n",
            "Batch 1830 of 4869. Elapsed 0:11:54\n",
            "Sample: 0.8250445127487183 v/s 0.8382372579277835\n",
            "Batch 1840 of 4869. Elapsed 0:11:58\n",
            "Sample: 0.8484255075454712 v/s 0.8083659164631527\n",
            "Batch 1850 of 4869. Elapsed 0:12:02\n",
            "Sample: 0.8491647243499756 v/s 0.8574689594787589\n",
            "Batch 1860 of 4869. Elapsed 0:12:06\n",
            "Sample: 0.8896063566207886 v/s 0.8946902115821282\n",
            "Batch 1870 of 4869. Elapsed 0:12:10\n",
            "Sample: 0.8504266738891602 v/s 0.8172478358674449\n",
            "Batch 1880 of 4869. Elapsed 0:12:14\n",
            "Sample: 0.7872427105903625 v/s 0.7048024660245749\n",
            "Batch 1890 of 4869. Elapsed 0:12:18\n",
            "Sample: 0.8236117362976074 v/s 0.7851114993717325\n",
            "Batch 1900 of 4869. Elapsed 0:12:22\n",
            "Sample: 0.7944743633270264 v/s 0.7151022468690481\n",
            "Batch 1910 of 4869. Elapsed 0:12:26\n",
            "Sample: 0.867062509059906 v/s 0.8557430667521078\n",
            "Batch 1920 of 4869. Elapsed 0:12:30\n",
            "Sample: 0.8515570759773254 v/s 0.7968409347722989\n",
            "Batch 1930 of 4869. Elapsed 0:12:34\n",
            "Sample: 0.8667276501655579 v/s 0.9028663256892062\n",
            "Batch 1940 of 4869. Elapsed 0:12:38\n",
            "Sample: 0.7856756448745728 v/s 0.6774280561035686\n",
            "Batch 1950 of 4869. Elapsed 0:12:42\n",
            "Sample: 0.8719715476036072 v/s 0.9178660574645007\n",
            "Batch 1960 of 4869. Elapsed 0:12:46\n",
            "Sample: 0.8569981455802917 v/s 0.8349272140097548\n",
            "Batch 1970 of 4869. Elapsed 0:12:50\n",
            "Sample: 0.8139680027961731 v/s 0.8221803621905783\n",
            "Batch 1980 of 4869. Elapsed 0:12:54\n",
            "Sample: 0.8220890164375305 v/s 0.7986222141596343\n",
            "Batch 1990 of 4869. Elapsed 0:12:57\n",
            "Sample: 0.8462264537811279 v/s 0.8700557178802192\n",
            "Batch 2000 of 4869. Elapsed 0:13:01\n",
            "Sample: 0.8124449849128723 v/s 0.7671300782519749\n",
            "Batch 2010 of 4869. Elapsed 0:13:05\n",
            "Sample: 0.8737617135047913 v/s 0.8922161784827778\n",
            "Batch 2020 of 4869. Elapsed 0:13:10\n",
            "Sample: 0.8847920298576355 v/s 0.807128955238331\n",
            "Batch 2030 of 4869. Elapsed 0:13:13\n",
            "Sample: 0.8372461795806885 v/s 0.7653703202102566\n",
            "Batch 2040 of 4869. Elapsed 0:13:17\n",
            "Sample: 0.8400277495384216 v/s 0.8144669246514898\n",
            "Batch 2050 of 4869. Elapsed 0:13:21\n",
            "Sample: 0.8152854442596436 v/s 0.7464498492674696\n",
            "Batch 2060 of 4869. Elapsed 0:13:25\n",
            "Sample: 0.7777647376060486 v/s 0.7404202339635643\n",
            "Batch 2070 of 4869. Elapsed 0:13:29\n",
            "Sample: 0.8995639085769653 v/s 0.8446484278328549\n",
            "Batch 2080 of 4869. Elapsed 0:13:33\n",
            "Sample: 0.8613919615745544 v/s 0.8346827552449656\n",
            "Batch 2090 of 4869. Elapsed 0:13:37\n",
            "Sample: 0.8239899277687073 v/s 0.828986528435587\n",
            "Batch 2100 of 4869. Elapsed 0:13:41\n",
            "Sample: 0.8800275921821594 v/s 0.8602145753109943\n",
            "Batch 2110 of 4869. Elapsed 0:13:45\n",
            "Sample: 0.904618501663208 v/s 0.8995856188423837\n",
            "Batch 2120 of 4869. Elapsed 0:13:49\n",
            "Sample: 0.8854844570159912 v/s 0.9415935377996102\n",
            "Batch 2130 of 4869. Elapsed 0:13:53\n",
            "Sample: 0.7526139616966248 v/s 0.7327272284211127\n",
            "Batch 2140 of 4869. Elapsed 0:13:57\n",
            "Sample: 0.7734266519546509 v/s 0.7640118482206144\n",
            "Batch 2150 of 4869. Elapsed 0:14:01\n",
            "Sample: 0.9080002307891846 v/s 0.8889027424597639\n",
            "Batch 2160 of 4869. Elapsed 0:14:05\n",
            "Sample: 0.8288741111755371 v/s 0.7780762594960807\n",
            "Batch 2170 of 4869. Elapsed 0:14:09\n",
            "Sample: 0.8236823678016663 v/s 0.7603310670699264\n",
            "Batch 2180 of 4869. Elapsed 0:14:12\n",
            "Sample: 0.8599669933319092 v/s 0.8582698292221973\n",
            "Batch 2190 of 4869. Elapsed 0:14:16\n",
            "Sample: 0.8420494794845581 v/s 0.8643395437577931\n",
            "Batch 2200 of 4869. Elapsed 0:14:20\n",
            "Sample: 0.8031525015830994 v/s 0.7614189336948143\n",
            "Batch 2210 of 4869. Elapsed 0:14:24\n",
            "Sample: 0.8623946905136108 v/s 0.8876895108826408\n",
            "Batch 2220 of 4869. Elapsed 0:14:28\n",
            "Sample: 0.844079852104187 v/s 0.8795209903306994\n",
            "Batch 2230 of 4869. Elapsed 0:14:32\n",
            "Sample: 0.8237910866737366 v/s 0.8429414693663907\n",
            "Batch 2240 of 4869. Elapsed 0:14:36\n",
            "Sample: 0.8378167152404785 v/s 0.8152338013949668\n",
            "Batch 2250 of 4869. Elapsed 0:14:40\n",
            "Sample: 0.8141430616378784 v/s 0.7168378873948359\n",
            "Batch 2260 of 4869. Elapsed 0:14:44\n",
            "Sample: 0.8428830504417419 v/s 0.7739439866549257\n",
            "Batch 2270 of 4869. Elapsed 0:14:48\n",
            "Sample: 0.857994794845581 v/s 0.7967610313379683\n",
            "Batch 2280 of 4869. Elapsed 0:14:51\n",
            "Sample: 0.8772688508033752 v/s 0.8616283584135607\n",
            "Batch 2290 of 4869. Elapsed 0:14:55\n",
            "Sample: 0.8256261944770813 v/s 0.8109611290810592\n",
            "Batch 2300 of 4869. Elapsed 0:14:59\n",
            "Sample: 0.8764967918395996 v/s 0.8516382804157645\n",
            "Batch 2310 of 4869. Elapsed 0:15:03\n",
            "Sample: 0.8840144872665405 v/s 0.8991951360140964\n",
            "Batch 2320 of 4869. Elapsed 0:15:07\n",
            "Sample: 0.82193523645401 v/s 0.7969846675406526\n",
            "Batch 2330 of 4869. Elapsed 0:15:11\n",
            "Sample: 0.8154881596565247 v/s 0.7507569089377146\n",
            "Batch 2340 of 4869. Elapsed 0:15:15\n",
            "Sample: 0.758490800857544 v/s 0.7015827000632271\n",
            "Batch 2350 of 4869. Elapsed 0:15:19\n",
            "Sample: 0.8729847073554993 v/s 0.8206934772004361\n",
            "Batch 2360 of 4869. Elapsed 0:15:23\n",
            "Sample: 0.8233022689819336 v/s 0.8232653325062939\n",
            "Batch 2370 of 4869. Elapsed 0:15:27\n",
            "Sample: 0.9088020920753479 v/s 0.9632800215885978\n",
            "Batch 2380 of 4869. Elapsed 0:15:31\n",
            "Sample: 0.8917536735534668 v/s 0.9213041936002967\n",
            "Batch 2390 of 4869. Elapsed 0:15:34\n",
            "Sample: 0.7857259511947632 v/s 0.7006751447962299\n",
            "Batch 2400 of 4869. Elapsed 0:15:38\n",
            "Sample: 0.8530040979385376 v/s 0.8535050737920109\n",
            "Batch 2410 of 4869. Elapsed 0:15:42\n",
            "Sample: 0.8736813068389893 v/s 0.8463572590655872\n",
            "Batch 2420 of 4869. Elapsed 0:15:46\n",
            "Sample: 0.9153926372528076 v/s 0.9222390166758133\n",
            "Batch 2430 of 4869. Elapsed 0:15:50\n",
            "Sample: 0.7915652990341187 v/s 0.8202738934297856\n",
            "Batch 2440 of 4869. Elapsed 0:15:54\n",
            "Sample: 0.8130720853805542 v/s 0.8453345800585629\n",
            "Batch 2450 of 4869. Elapsed 0:15:58\n",
            "Sample: 0.7738879323005676 v/s 0.8103809740244623\n",
            "Batch 2460 of 4869. Elapsed 0:16:02\n",
            "Sample: 0.830953061580658 v/s 0.8717916961343116\n",
            "Batch 2470 of 4869. Elapsed 0:16:06\n",
            "Sample: 0.8151521682739258 v/s 0.7703512561659726\n",
            "Batch 2480 of 4869. Elapsed 0:16:10\n",
            "Sample: 0.7246681451797485 v/s 0.717305924602565\n",
            "Batch 2490 of 4869. Elapsed 0:16:13\n",
            "Sample: 0.7945387959480286 v/s 0.7842929824050073\n",
            "Batch 2500 of 4869. Elapsed 0:16:17\n",
            "Sample: 0.8287721276283264 v/s 0.7936593277231899\n",
            "Batch 2510 of 4869. Elapsed 0:16:21\n",
            "Sample: 0.8395745158195496 v/s 0.8634071514294958\n",
            "Batch 2520 of 4869. Elapsed 0:16:25\n",
            "Sample: 0.7971289753913879 v/s 0.7073304080071222\n",
            "Batch 2530 of 4869. Elapsed 0:16:29\n",
            "Sample: 0.8177027702331543 v/s 0.8153133246216214\n",
            "Batch 2540 of 4869. Elapsed 0:16:33\n",
            "Sample: 0.8744751811027527 v/s 0.858236429748824\n",
            "Batch 2550 of 4869. Elapsed 0:16:37\n",
            "Sample: 0.7711308598518372 v/s 0.8817444931922305\n",
            "Batch 2560 of 4869. Elapsed 0:16:41\n",
            "Sample: 0.8121164441108704 v/s 0.8376246253088606\n",
            "Batch 2570 of 4869. Elapsed 0:16:45\n",
            "Sample: 0.8520056009292603 v/s 0.8190079377241419\n",
            "Batch 2580 of 4869. Elapsed 0:16:49\n",
            "Sample: 0.8610658049583435 v/s 0.9244013497212996\n",
            "Batch 2590 of 4869. Elapsed 0:16:53\n",
            "Sample: 0.847907543182373 v/s 0.8103408881997154\n",
            "Batch 2600 of 4869. Elapsed 0:16:56\n",
            "Sample: 0.824640154838562 v/s 0.7930693244135555\n",
            "Batch 2610 of 4869. Elapsed 0:17:00\n",
            "Sample: 0.8901813626289368 v/s 0.8794591356965383\n",
            "Batch 2620 of 4869. Elapsed 0:17:04\n",
            "Sample: 0.8573161363601685 v/s 0.8183370299994596\n",
            "Batch 2630 of 4869. Elapsed 0:17:08\n",
            "Sample: 0.8423740267753601 v/s 0.794966961750774\n",
            "Batch 2640 of 4869. Elapsed 0:17:12\n",
            "Sample: 0.8963326811790466 v/s 0.9614402523044252\n",
            "Batch 2650 of 4869. Elapsed 0:17:16\n",
            "Sample: 0.8256295919418335 v/s 0.8231605510550699\n",
            "Batch 2660 of 4869. Elapsed 0:17:20\n",
            "Sample: 0.8362468481063843 v/s 0.8450270529739258\n",
            "Batch 2670 of 4869. Elapsed 0:17:24\n",
            "Sample: 0.8220419883728027 v/s 0.747598180954393\n",
            "Batch 2680 of 4869. Elapsed 0:17:28\n",
            "Sample: 0.8531139492988586 v/s 0.8721172904812935\n",
            "Batch 2690 of 4869. Elapsed 0:17:32\n",
            "Sample: 0.8509075045585632 v/s 0.8488264131795561\n",
            "Batch 2700 of 4869. Elapsed 0:17:36\n",
            "Sample: 0.8003232479095459 v/s 0.7339076420371011\n",
            "Batch 2710 of 4869. Elapsed 0:17:39\n",
            "Sample: 0.8802618980407715 v/s 0.8645343204875324\n",
            "Batch 2720 of 4869. Elapsed 0:17:43\n",
            "Sample: 0.8440147638320923 v/s 0.8131139366826323\n",
            "Batch 2730 of 4869. Elapsed 0:17:47\n",
            "Sample: 0.8353426456451416 v/s 0.8857528217314085\n",
            "Batch 2740 of 4869. Elapsed 0:17:51\n",
            "Sample: 0.8495481014251709 v/s 0.7956197047928254\n",
            "Batch 2750 of 4869. Elapsed 0:17:55\n",
            "Sample: 0.8334051370620728 v/s 0.8193529032597883\n",
            "Batch 2760 of 4869. Elapsed 0:17:59\n",
            "Sample: 0.782589852809906 v/s 0.7797662213119578\n",
            "Batch 2770 of 4869. Elapsed 0:18:03\n",
            "Sample: 0.8497055172920227 v/s 0.8237204016615732\n",
            "Batch 2780 of 4869. Elapsed 0:18:07\n",
            "Sample: 0.7903227806091309 v/s 0.711095279601183\n",
            "Batch 2790 of 4869. Elapsed 0:18:11\n",
            "Sample: 0.8546929359436035 v/s 0.853944954853692\n",
            "Batch 2800 of 4869. Elapsed 0:18:15\n",
            "Sample: 0.8362599611282349 v/s 0.7585258152171549\n",
            "Batch 2810 of 4869. Elapsed 0:18:19\n",
            "Sample: 0.7023480534553528 v/s 0.6670127071828206\n",
            "Batch 2820 of 4869. Elapsed 0:18:23\n",
            "Sample: 0.7824058532714844 v/s 0.7284667637473349\n",
            "Batch 2830 of 4869. Elapsed 0:18:26\n",
            "Sample: 0.8514412045478821 v/s 0.7973863290469179\n",
            "Batch 2840 of 4869. Elapsed 0:18:30\n",
            "Sample: 0.8480608463287354 v/s 0.9109097113310802\n",
            "Batch 2850 of 4869. Elapsed 0:18:34\n",
            "Sample: 0.7987558841705322 v/s 0.7371219916615048\n",
            "Batch 2860 of 4869. Elapsed 0:18:38\n",
            "Sample: 0.8763219118118286 v/s 0.8829956999287348\n",
            "Batch 2870 of 4869. Elapsed 0:18:41\n",
            "Sample: 0.8568528294563293 v/s 0.8608513811467896\n",
            "Batch 2880 of 4869. Elapsed 0:18:45\n",
            "Sample: 0.8643910884857178 v/s 0.8198553379272328\n",
            "Batch 2890 of 4869. Elapsed 0:18:49\n",
            "Sample: 0.8528109788894653 v/s 0.8676384515927092\n",
            "Batch 2900 of 4869. Elapsed 0:18:53\n",
            "Sample: 0.8473749756813049 v/s 0.8298782157785556\n",
            "Batch 2910 of 4869. Elapsed 0:18:57\n",
            "Sample: 0.832252025604248 v/s 0.7639590858618599\n",
            "Batch 2920 of 4869. Elapsed 0:19:01\n",
            "Sample: 0.8484256267547607 v/s 0.8523971668544496\n",
            "Batch 2930 of 4869. Elapsed 0:19:05\n",
            "Sample: 0.8576809167861938 v/s 0.847674054756843\n",
            "Batch 2940 of 4869. Elapsed 0:19:09\n",
            "Sample: 0.8152693510055542 v/s 0.8049759567034707\n",
            "Batch 2950 of 4869. Elapsed 0:19:12\n",
            "Sample: 0.7716856002807617 v/s 0.789323623808844\n",
            "Batch 2960 of 4869. Elapsed 0:19:17\n",
            "Sample: 0.8636344075202942 v/s 0.8367418833893309\n",
            "Batch 2970 of 4869. Elapsed 0:19:21\n",
            "Sample: 0.7791332006454468 v/s 0.763797854817005\n",
            "Batch 2980 of 4869. Elapsed 0:19:24\n",
            "Sample: 0.8227789402008057 v/s 0.84751923810574\n",
            "Batch 2990 of 4869. Elapsed 0:19:28\n",
            "Sample: 0.8594978451728821 v/s 0.8372342202331002\n",
            "Batch 3000 of 4869. Elapsed 0:19:32\n",
            "Sample: 0.7808424234390259 v/s 0.7483464266524456\n",
            "Batch 3010 of 4869. Elapsed 0:19:36\n",
            "Sample: 0.8175156116485596 v/s 0.8198286718313199\n",
            "Batch 3020 of 4869. Elapsed 0:19:40\n",
            "Sample: 0.8013187646865845 v/s 0.7629815692066404\n",
            "Batch 3030 of 4869. Elapsed 0:19:44\n",
            "Sample: 0.8350327610969543 v/s 0.8270003717474388\n",
            "Batch 3040 of 4869. Elapsed 0:19:48\n",
            "Sample: 0.824431836605072 v/s 0.7826989164011271\n",
            "Batch 3050 of 4869. Elapsed 0:19:52\n",
            "Sample: 0.8244741559028625 v/s 0.7842397539651685\n",
            "Batch 3060 of 4869. Elapsed 0:19:56\n",
            "Sample: 0.8102222084999084 v/s 0.7634356328628826\n",
            "Batch 3070 of 4869. Elapsed 0:20:00\n",
            "Sample: 0.8621546030044556 v/s 0.8248908612769619\n",
            "Batch 3080 of 4869. Elapsed 0:20:04\n",
            "Sample: 0.8059090375900269 v/s 0.8126064666977372\n",
            "Batch 3090 of 4869. Elapsed 0:20:07\n",
            "Sample: 0.7592394948005676 v/s 0.7282911537354957\n",
            "Batch 3100 of 4869. Elapsed 0:20:11\n",
            "Sample: 0.8557311296463013 v/s 0.9090271816502027\n",
            "Batch 3110 of 4869. Elapsed 0:20:15\n",
            "Sample: 0.7805072665214539 v/s 0.7765393892862794\n",
            "Batch 3120 of 4869. Elapsed 0:20:19\n",
            "Sample: 0.8486829400062561 v/s 0.8497067263680883\n",
            "Batch 3130 of 4869. Elapsed 0:20:23\n",
            "Sample: 0.807356059551239 v/s 0.7521783690777679\n",
            "Batch 3140 of 4869. Elapsed 0:20:27\n",
            "Sample: 0.8734691143035889 v/s 0.8620498471167998\n",
            "Batch 3150 of 4869. Elapsed 0:20:31\n",
            "Sample: 0.8766325116157532 v/s 0.9376283712801072\n",
            "Batch 3160 of 4869. Elapsed 0:20:35\n",
            "Sample: 0.8625373840332031 v/s 0.875005544127858\n",
            "Batch 3170 of 4869. Elapsed 0:20:39\n",
            "Sample: 0.8529312014579773 v/s 0.8039431863087757\n",
            "Batch 3180 of 4869. Elapsed 0:20:43\n",
            "Sample: 0.8490476608276367 v/s 0.7909620964270638\n",
            "Batch 3190 of 4869. Elapsed 0:20:47\n",
            "Sample: 0.7934520244598389 v/s 0.7180741456184127\n",
            "Batch 3200 of 4869. Elapsed 0:20:51\n",
            "Sample: 0.8499990105628967 v/s 0.8593758679472834\n",
            "Batch 3210 of 4869. Elapsed 0:20:55\n",
            "Sample: 0.8437793850898743 v/s 0.8711904474168314\n",
            "Batch 3220 of 4869. Elapsed 0:20:59\n",
            "Sample: 0.7998315691947937 v/s 0.8937538507245575\n",
            "Batch 3230 of 4869. Elapsed 0:21:03\n",
            "Sample: 0.8606170415878296 v/s 0.8309999293437914\n",
            "Batch 3240 of 4869. Elapsed 0:21:06\n",
            "Sample: 0.8141884207725525 v/s 0.7478139655041895\n",
            "Batch 3250 of 4869. Elapsed 0:21:10\n",
            "Sample: 0.7609256505966187 v/s 0.679277478083364\n",
            "Batch 3260 of 4869. Elapsed 0:21:14\n",
            "Sample: 0.8396027684211731 v/s 0.8873094885780402\n",
            "Batch 3270 of 4869. Elapsed 0:21:18\n",
            "Sample: 0.8480785489082336 v/s 0.8453316886673876\n",
            "Batch 3280 of 4869. Elapsed 0:21:22\n",
            "Sample: 0.8053866624832153 v/s 0.8175658286141099\n",
            "Batch 3290 of 4869. Elapsed 0:21:26\n",
            "Sample: 0.8578228950500488 v/s 0.8070085940831374\n",
            "Batch 3300 of 4869. Elapsed 0:21:30\n",
            "Sample: 0.8725021481513977 v/s 0.8046283983999896\n",
            "Batch 3310 of 4869. Elapsed 0:21:34\n",
            "Sample: 0.8536638617515564 v/s 0.781199012624137\n",
            "Batch 3320 of 4869. Elapsed 0:21:38\n",
            "Sample: 0.8656131625175476 v/s 0.8523017142438877\n",
            "Batch 3330 of 4869. Elapsed 0:21:42\n",
            "Sample: 0.8616572618484497 v/s 0.814664783815933\n",
            "Batch 3340 of 4869. Elapsed 0:21:46\n",
            "Sample: 0.8636284470558167 v/s 0.8406925288883483\n",
            "Batch 3350 of 4869. Elapsed 0:21:50\n",
            "Sample: 0.8514118790626526 v/s 0.7695697160735889\n",
            "Batch 3360 of 4869. Elapsed 0:21:54\n",
            "Sample: 0.8596700429916382 v/s 0.9353427655038453\n",
            "Batch 3370 of 4869. Elapsed 0:21:57\n",
            "Sample: 0.8398157358169556 v/s 0.8401599712881104\n",
            "Batch 3380 of 4869. Elapsed 0:22:01\n",
            "Sample: 0.917783260345459 v/s 0.937682754700062\n",
            "Batch 3390 of 4869. Elapsed 0:22:05\n",
            "Sample: 0.807060956954956 v/s 0.7902739980952941\n",
            "Batch 3400 of 4869. Elapsed 0:22:09\n",
            "Sample: 0.8704962134361267 v/s 0.9476995633024303\n",
            "Batch 3410 of 4869. Elapsed 0:22:13\n",
            "Sample: 0.8198927640914917 v/s 0.842097576984026\n",
            "Batch 3420 of 4869. Elapsed 0:22:17\n",
            "Sample: 0.853325605392456 v/s 0.8595877282126101\n",
            "Batch 3430 of 4869. Elapsed 0:22:21\n",
            "Sample: 0.8798038959503174 v/s 0.9469395716295795\n",
            "Batch 3440 of 4869. Elapsed 0:22:25\n",
            "Sample: 0.8506021499633789 v/s 0.7940451242594949\n",
            "Batch 3450 of 4869. Elapsed 0:22:29\n",
            "Sample: 0.8164460062980652 v/s 0.8011166859178284\n",
            "Batch 3460 of 4869. Elapsed 0:22:33\n",
            "Sample: 0.871086835861206 v/s 0.8947147277503967\n",
            "Batch 3470 of 4869. Elapsed 0:22:37\n",
            "Sample: 0.853390634059906 v/s 0.8657936561071462\n",
            "Batch 3480 of 4869. Elapsed 0:22:41\n",
            "Sample: 0.8281213641166687 v/s 0.799793994185604\n",
            "Batch 3490 of 4869. Elapsed 0:22:45\n",
            "Sample: 0.7522250413894653 v/s 0.7705668293543202\n",
            "Batch 3500 of 4869. Elapsed 0:22:49\n",
            "Sample: 0.8663744926452637 v/s 0.9445799492836038\n",
            "Batch 3510 of 4869. Elapsed 0:22:53\n",
            "Sample: 0.8391803503036499 v/s 0.8171844660309324\n",
            "Batch 3520 of 4869. Elapsed 0:22:57\n",
            "Sample: 0.8054037094116211 v/s 0.773495770646048\n",
            "Batch 3530 of 4869. Elapsed 0:23:01\n",
            "Sample: 0.8472112417221069 v/s 0.7564368103604984\n",
            "Batch 3540 of 4869. Elapsed 0:23:05\n",
            "Sample: 0.8584555387496948 v/s 0.8473523045636229\n",
            "Batch 3550 of 4869. Elapsed 0:23:09\n",
            "Sample: 0.90412837266922 v/s 0.9242205494158275\n",
            "Batch 3560 of 4869. Elapsed 0:23:13\n",
            "Sample: 0.8694503903388977 v/s 0.8822020855042795\n",
            "Batch 3570 of 4869. Elapsed 0:23:17\n",
            "Sample: 0.8524140119552612 v/s 0.8066997478807381\n",
            "Batch 3580 of 4869. Elapsed 0:23:20\n",
            "Sample: 0.8675301671028137 v/s 0.9378404861979884\n",
            "Batch 3590 of 4869. Elapsed 0:23:24\n",
            "Sample: 0.8789120316505432 v/s 0.9448238710596093\n",
            "Batch 3600 of 4869. Elapsed 0:23:28\n",
            "Sample: 0.8352094292640686 v/s 0.7585614765958895\n",
            "Batch 3610 of 4869. Elapsed 0:23:32\n",
            "Sample: 0.8504268527030945 v/s 0.8828276516737523\n",
            "Batch 3620 of 4869. Elapsed 0:23:36\n",
            "Sample: 0.8563107848167419 v/s 0.7658882903613031\n",
            "Batch 3630 of 4869. Elapsed 0:23:40\n",
            "Sample: 0.8551063537597656 v/s 0.8495160252945665\n",
            "Batch 3640 of 4869. Elapsed 0:23:44\n",
            "Sample: 0.7786548137664795 v/s 0.7028155090711894\n",
            "Batch 3650 of 4869. Elapsed 0:23:48\n",
            "Sample: 0.8748452663421631 v/s 0.8556440279998297\n",
            "Batch 3660 of 4869. Elapsed 0:23:52\n",
            "Sample: 0.8401244282722473 v/s 0.7707282163754182\n",
            "Batch 3670 of 4869. Elapsed 0:23:55\n",
            "Sample: 0.8487269282341003 v/s 0.8581091930295425\n",
            "Batch 3680 of 4869. Elapsed 0:23:59\n",
            "Sample: 0.7310903072357178 v/s 0.6512117903793057\n",
            "Batch 3690 of 4869. Elapsed 0:24:03\n",
            "Sample: 0.8451622724533081 v/s 0.9565086827021378\n",
            "Batch 3700 of 4869. Elapsed 0:24:07\n",
            "Sample: 0.799498438835144 v/s 0.7456057236987972\n",
            "Batch 3710 of 4869. Elapsed 0:24:11\n",
            "Sample: 0.8294200897216797 v/s 0.9244694287935653\n",
            "Batch 3720 of 4869. Elapsed 0:24:15\n",
            "Sample: 0.864419162273407 v/s 0.8916901739149009\n",
            "Batch 3730 of 4869. Elapsed 0:24:19\n",
            "Sample: 0.8230810761451721 v/s 0.7613861548120654\n",
            "Batch 3740 of 4869. Elapsed 0:24:23\n",
            "Sample: 0.856356143951416 v/s 0.9192160542810917\n",
            "Batch 3750 of 4869. Elapsed 0:24:26\n",
            "Sample: 0.8495102524757385 v/s 0.8890729942178843\n",
            "Batch 3760 of 4869. Elapsed 0:24:30\n",
            "Sample: 0.7565062046051025 v/s 0.6840016356723283\n",
            "Batch 3770 of 4869. Elapsed 0:24:34\n",
            "Sample: 0.8248031735420227 v/s 0.8393464059380744\n",
            "Batch 3780 of 4869. Elapsed 0:24:38\n",
            "Sample: 0.7971475720405579 v/s 0.7946121603405943\n",
            "Batch 3790 of 4869. Elapsed 0:24:41\n",
            "Sample: 0.8486330509185791 v/s 0.8335446961350566\n",
            "Batch 3800 of 4869. Elapsed 0:24:45\n",
            "Sample: 0.8577316403388977 v/s 0.8345960265121299\n",
            "Batch 3810 of 4869. Elapsed 0:24:49\n",
            "Sample: 0.848741352558136 v/s 0.8657362218846543\n",
            "Batch 3820 of 4869. Elapsed 0:24:53\n",
            "Sample: 0.8234133124351501 v/s 0.711505863691337\n",
            "Batch 3830 of 4869. Elapsed 0:24:57\n",
            "Sample: 0.8518794775009155 v/s 0.8185927818520207\n",
            "Batch 3840 of 4869. Elapsed 0:25:00\n",
            "Sample: 0.7526435852050781 v/s 0.7098043596420808\n",
            "Batch 3850 of 4869. Elapsed 0:25:04\n",
            "Sample: 0.8169012665748596 v/s 0.8082351809425735\n",
            "Batch 3860 of 4869. Elapsed 0:25:08\n",
            "Sample: 0.8969694375991821 v/s 0.9615962617498116\n",
            "Batch 3870 of 4869. Elapsed 0:25:12\n",
            "Sample: 0.829835832118988 v/s 0.7662233184787616\n",
            "Batch 3880 of 4869. Elapsed 0:25:16\n",
            "Sample: 0.7771385312080383 v/s 0.6453427727517971\n",
            "Batch 3890 of 4869. Elapsed 0:25:20\n",
            "Sample: 0.7958288192749023 v/s 0.7777238337529621\n",
            "Batch 3900 of 4869. Elapsed 0:25:23\n",
            "Sample: 0.8712075352668762 v/s 0.8464684217413306\n",
            "Batch 3910 of 4869. Elapsed 0:25:27\n",
            "Sample: 0.766828179359436 v/s 0.7474541734067569\n",
            "Batch 3920 of 4869. Elapsed 0:25:31\n",
            "Sample: 0.8681414127349854 v/s 0.926436465655158\n",
            "Batch 3930 of 4869. Elapsed 0:25:35\n",
            "Sample: 0.8429721593856812 v/s 0.8479668074201155\n",
            "Batch 3940 of 4869. Elapsed 0:25:39\n",
            "Sample: 0.8683926463127136 v/s 0.8392045126681468\n",
            "Batch 3950 of 4869. Elapsed 0:25:43\n",
            "Sample: 0.8236532211303711 v/s 0.7708877461886058\n",
            "Batch 3960 of 4869. Elapsed 0:25:47\n",
            "Sample: 0.8627727031707764 v/s 0.8214172962959473\n",
            "Batch 3970 of 4869. Elapsed 0:25:51\n",
            "Sample: 0.7479678392410278 v/s 0.6950409727914892\n",
            "Batch 3980 of 4869. Elapsed 0:25:54\n",
            "Sample: 0.8375451564788818 v/s 0.7561435547803965\n",
            "Batch 3990 of 4869. Elapsed 0:25:58\n",
            "Sample: 0.8512255549430847 v/s 0.8399323096982257\n",
            "Batch 4000 of 4869. Elapsed 0:26:03\n",
            "Sample: 0.8768002986907959 v/s 0.8618145401620068\n",
            "Batch 4010 of 4869. Elapsed 0:26:06\n",
            "Sample: 0.7487066388130188 v/s 0.747743485874672\n",
            "Batch 4020 of 4869. Elapsed 0:26:10\n",
            "Sample: 0.9005984663963318 v/s 0.9449217578331027\n",
            "Batch 4030 of 4869. Elapsed 0:26:14\n",
            "Sample: 0.8685102462768555 v/s 0.8847412192069071\n",
            "Batch 4040 of 4869. Elapsed 0:26:18\n",
            "Sample: 0.8827695846557617 v/s 0.8528807665198225\n",
            "Batch 4050 of 4869. Elapsed 0:26:22\n",
            "Sample: 0.7443023324012756 v/s 0.7273752454322379\n",
            "Batch 4060 of 4869. Elapsed 0:26:26\n",
            "Sample: 0.8414620161056519 v/s 0.7704735767093408\n",
            "Batch 4070 of 4869. Elapsed 0:26:30\n",
            "Sample: 0.8701149821281433 v/s 0.8513648167138131\n",
            "Batch 4080 of 4869. Elapsed 0:26:33\n",
            "Sample: 0.8157333135604858 v/s 0.7696227089346529\n",
            "Batch 4090 of 4869. Elapsed 0:26:37\n",
            "Sample: 0.7787733674049377 v/s 0.7361372418720721\n",
            "Batch 4100 of 4869. Elapsed 0:26:41\n",
            "Sample: 0.7293399572372437 v/s 0.7058170199090124\n",
            "Batch 4110 of 4869. Elapsed 0:26:45\n",
            "Sample: 0.8412839770317078 v/s 0.8144322810710598\n",
            "Batch 4120 of 4869. Elapsed 0:26:49\n",
            "Sample: 0.8300508260726929 v/s 0.717435260455311\n",
            "Batch 4130 of 4869. Elapsed 0:26:53\n",
            "Sample: 0.8902262449264526 v/s 0.9411279191451648\n",
            "Batch 4140 of 4869. Elapsed 0:26:57\n",
            "Sample: 0.839229166507721 v/s 0.8237333275046098\n",
            "Batch 4150 of 4869. Elapsed 0:27:01\n",
            "Sample: 0.7964239716529846 v/s 0.7419920814125636\n",
            "Batch 4160 of 4869. Elapsed 0:27:05\n",
            "Sample: 0.8599036931991577 v/s 0.9069116050603471\n",
            "Batch 4170 of 4869. Elapsed 0:27:09\n",
            "Sample: 0.8970779180526733 v/s 0.8482623275585859\n",
            "Batch 4180 of 4869. Elapsed 0:27:12\n",
            "Sample: 0.8666088581085205 v/s 0.8503525968807126\n",
            "Batch 4190 of 4869. Elapsed 0:27:16\n",
            "Sample: 0.8137375712394714 v/s 0.7660703705283787\n",
            "Batch 4200 of 4869. Elapsed 0:27:20\n",
            "Sample: 0.878737211227417 v/s 0.9194210909908936\n",
            "Batch 4210 of 4869. Elapsed 0:27:24\n",
            "Sample: 0.8393369317054749 v/s 0.8211687000462105\n",
            "Batch 4220 of 4869. Elapsed 0:27:28\n",
            "Sample: 0.8571181297302246 v/s 0.861689907287769\n",
            "Batch 4230 of 4869. Elapsed 0:27:32\n",
            "Sample: 0.8855854272842407 v/s 0.8966809516898824\n",
            "Batch 4240 of 4869. Elapsed 0:27:36\n",
            "Sample: 0.8053701519966125 v/s 0.812170650183313\n",
            "Batch 4250 of 4869. Elapsed 0:27:40\n",
            "Sample: 0.77482670545578 v/s 0.7289855916811842\n",
            "Batch 4260 of 4869. Elapsed 0:27:44\n",
            "Sample: 0.8589245080947876 v/s 0.7957838689720872\n",
            "Batch 4270 of 4869. Elapsed 0:27:48\n",
            "Sample: 0.8576148748397827 v/s 0.8619926826868539\n",
            "Batch 4280 of 4869. Elapsed 0:27:52\n",
            "Sample: 0.8665242195129395 v/s 0.8813252227076348\n",
            "Batch 4290 of 4869. Elapsed 0:27:56\n",
            "Sample: 0.8279557228088379 v/s 0.7542751699589565\n",
            "Batch 4300 of 4869. Elapsed 0:28:00\n",
            "Sample: 0.8825209736824036 v/s 0.9100002439992152\n",
            "Batch 4310 of 4869. Elapsed 0:28:04\n",
            "Sample: 0.8877238035202026 v/s 0.8629737622510143\n",
            "Batch 4320 of 4869. Elapsed 0:28:08\n",
            "Sample: 0.8932452201843262 v/s 0.868553147756215\n",
            "Batch 4330 of 4869. Elapsed 0:28:12\n",
            "Sample: 0.8064302206039429 v/s 0.7521817018016286\n",
            "Batch 4340 of 4869. Elapsed 0:28:16\n",
            "Sample: 0.8162090182304382 v/s 0.7858778434779757\n",
            "Batch 4350 of 4869. Elapsed 0:28:20\n",
            "Sample: 0.8419251441955566 v/s 0.8595507665564899\n",
            "Batch 4360 of 4869. Elapsed 0:28:24\n",
            "Sample: 0.8613235950469971 v/s 0.8710092040216167\n",
            "Batch 4370 of 4869. Elapsed 0:28:28\n",
            "Sample: 0.8313260078430176 v/s 0.7585735862130485\n",
            "Batch 4380 of 4869. Elapsed 0:28:32\n",
            "Sample: 0.792069137096405 v/s 0.7164268367391589\n",
            "Batch 4390 of 4869. Elapsed 0:28:35\n",
            "Sample: 0.8477239012718201 v/s 0.8420576700984488\n",
            "Batch 4400 of 4869. Elapsed 0:28:39\n",
            "Sample: 0.8380662202835083 v/s 0.8020569901926562\n",
            "Batch 4410 of 4869. Elapsed 0:28:43\n",
            "Sample: 0.8221986293792725 v/s 0.7729094222705984\n",
            "Batch 4420 of 4869. Elapsed 0:28:46\n",
            "Sample: 0.8423642516136169 v/s 0.7077618049330082\n",
            "Batch 4430 of 4869. Elapsed 0:28:50\n",
            "Sample: 0.7825325131416321 v/s 0.8022136111882195\n",
            "Batch 4440 of 4869. Elapsed 0:28:54\n",
            "Sample: 0.7890964150428772 v/s 0.7014585607538687\n",
            "Batch 4450 of 4869. Elapsed 0:28:58\n",
            "Sample: 0.8817907571792603 v/s 0.807293225002344\n",
            "Batch 4460 of 4869. Elapsed 0:29:02\n",
            "Sample: 0.8083712458610535 v/s 0.8164076378400533\n",
            "Batch 4470 of 4869. Elapsed 0:29:06\n",
            "Sample: 0.8275154232978821 v/s 0.7923337717308505\n",
            "Batch 4480 of 4869. Elapsed 0:29:10\n",
            "Sample: 0.8254193663597107 v/s 0.836809069409344\n",
            "Batch 4490 of 4869. Elapsed 0:29:14\n",
            "Sample: 0.8025380373001099 v/s 0.7824235954249019\n",
            "Batch 4500 of 4869. Elapsed 0:29:18\n",
            "Sample: 0.8524464964866638 v/s 0.8019279263479117\n",
            "Batch 4510 of 4869. Elapsed 0:29:21\n",
            "Sample: 0.8817593455314636 v/s 0.9018058070660938\n",
            "Batch 4520 of 4869. Elapsed 0:29:25\n",
            "Sample: 0.8187087178230286 v/s 0.9223453088339664\n",
            "Batch 4530 of 4869. Elapsed 0:29:29\n",
            "Sample: 0.8232600092887878 v/s 0.7666965443659972\n",
            "Batch 4540 of 4869. Elapsed 0:29:33\n",
            "Sample: 0.8049921989440918 v/s 0.8452324239888768\n",
            "Batch 4550 of 4869. Elapsed 0:29:37\n",
            "Sample: 0.8685968518257141 v/s 0.8295941624653657\n",
            "Batch 4560 of 4869. Elapsed 0:29:41\n",
            "Sample: 0.8731394410133362 v/s 0.9190729381051134\n",
            "Batch 4570 of 4869. Elapsed 0:29:45\n",
            "Sample: 0.8963134288787842 v/s 0.8648158565847004\n",
            "Batch 4580 of 4869. Elapsed 0:29:49\n",
            "Sample: 0.8733348250389099 v/s 0.8479150672840043\n",
            "Batch 4590 of 4869. Elapsed 0:29:53\n",
            "Sample: 0.8400484323501587 v/s 0.8379083699702062\n",
            "Batch 4600 of 4869. Elapsed 0:29:57\n",
            "Sample: 0.7691607475280762 v/s 0.776037296611121\n",
            "Batch 4610 of 4869. Elapsed 0:30:00\n",
            "Sample: 0.809927761554718 v/s 0.7326835527113544\n",
            "Batch 4620 of 4869. Elapsed 0:30:04\n",
            "Sample: 0.7940875291824341 v/s 0.720839744976888\n",
            "Batch 4630 of 4869. Elapsed 0:30:09\n",
            "Sample: 0.8534119129180908 v/s 0.8544486040277093\n",
            "Batch 4640 of 4869. Elapsed 0:30:12\n",
            "Sample: 0.858958899974823 v/s 0.8654402126627325\n",
            "Batch 4650 of 4869. Elapsed 0:30:16\n",
            "Sample: 0.8607364892959595 v/s 0.9245110623300881\n",
            "Batch 4660 of 4869. Elapsed 0:30:20\n",
            "Sample: 0.9100476503372192 v/s 0.8898983018150338\n",
            "Batch 4670 of 4869. Elapsed 0:30:24\n",
            "Sample: 0.8154743313789368 v/s 0.8617527260041337\n",
            "Batch 4680 of 4869. Elapsed 0:30:28\n",
            "Sample: 0.8744691610336304 v/s 0.8702227605953876\n",
            "Batch 4690 of 4869. Elapsed 0:30:32\n",
            "Sample: 0.7856874465942383 v/s 0.7472805386018485\n",
            "Batch 4700 of 4869. Elapsed 0:30:36\n",
            "Sample: 0.8229844570159912 v/s 0.767432196706901\n",
            "Batch 4710 of 4869. Elapsed 0:30:40\n",
            "Sample: 0.8585706353187561 v/s 0.7802839771118338\n",
            "Batch 4720 of 4869. Elapsed 0:30:44\n",
            "Sample: 0.7988642454147339 v/s 0.7906049271132383\n",
            "Batch 4730 of 4869. Elapsed 0:30:48\n",
            "Sample: 0.8670516014099121 v/s 0.7934735742638345\n",
            "Batch 4740 of 4869. Elapsed 0:30:52\n",
            "Sample: 0.8560951352119446 v/s 0.7981679860485534\n",
            "Batch 4750 of 4869. Elapsed 0:30:56\n",
            "Sample: 0.8009769916534424 v/s 0.7922037970878186\n",
            "Batch 4760 of 4869. Elapsed 0:31:00\n",
            "Sample: 0.8322984576225281 v/s 0.7546580193373712\n",
            "Batch 4770 of 4869. Elapsed 0:31:04\n",
            "Sample: 0.840328574180603 v/s 0.8347454112717133\n",
            "Batch 4780 of 4869. Elapsed 0:31:08\n",
            "Sample: 0.8097198009490967 v/s 0.7938151269350714\n",
            "Batch 4790 of 4869. Elapsed 0:31:11\n",
            "Sample: 0.8819592595100403 v/s 0.8344213054623435\n",
            "Batch 4800 of 4869. Elapsed 0:31:15\n",
            "Sample: 0.8295062184333801 v/s 0.8655629748989836\n",
            "Batch 4810 of 4869. Elapsed 0:31:19\n",
            "Sample: 0.8601080775260925 v/s 0.877803550238906\n",
            "Batch 4820 of 4869. Elapsed 0:31:23\n",
            "Sample: 0.857151448726654 v/s 0.7956482926166684\n",
            "Batch 4830 of 4869. Elapsed 0:31:27\n",
            "Sample: 0.8630189299583435 v/s 0.903759927477556\n",
            "Batch 4840 of 4869. Elapsed 0:31:31\n",
            "Sample: 0.8610714673995972 v/s 0.8293231848133289\n",
            "Batch 4850 of 4869. Elapsed 0:31:35\n",
            "Sample: 0.8752164244651794 v/s 0.8525109753928067\n",
            "Batch 4860 of 4869. Elapsed 0:31:39\n",
            "Average generator training loss for epoch 2 : 1.3636194467544556\n",
            "Epoch took 0:31:42\n",
            "\n",
            "Saving new files for next epoch\n",
            "Average STOI: 0.7866384977793036\n",
            "<<<<<<<<<<<<<<< GAN epoch 10 >>>>>>>>>>>>>>>>>\n",
            "=============== Discriminator Epoch 1 / 2 =================\n",
            "Sample: 0.81279057264328 v/s 0.7450673580169678 v/s 0.79437554457438\n",
            "Batch 10 of 6492. Elapsed 0:00:03\n",
            "Sample: 0.8446649312973022 v/s 0.7499018907546997 v/s 0.8151413941034156\n",
            "Batch 20 of 6492. Elapsed 0:00:06\n",
            "Sample: 0.8004264235496521 v/s 0.7505754828453064 v/s 0.8092026168569264\n",
            "Batch 30 of 6492. Elapsed 0:00:09\n",
            "Sample: 0.7511005997657776 v/s 0.6527575850486755 v/s 0.7193998491761905\n",
            "Batch 40 of 6492. Elapsed 0:00:12\n",
            "Sample: 0.7395203709602356 v/s 0.7508059740066528 v/s 0.7993715402749402\n",
            "Batch 50 of 6492. Elapsed 0:00:15\n",
            "Sample: 0.8062853217124939 v/s 0.8654094934463501 v/s 0.8872308326088091\n",
            "Batch 60 of 6492. Elapsed 0:00:18\n",
            "Sample: 0.7297293543815613 v/s 0.820709228515625 v/s 0.8809684691610136\n",
            "Batch 70 of 6492. Elapsed 0:00:21\n",
            "Sample: 0.8626217246055603 v/s 0.8199177980422974 v/s 0.8619905271587727\n",
            "Batch 80 of 6492. Elapsed 0:00:24\n",
            "Sample: 0.7606691122055054 v/s 0.7000235915184021 v/s 0.7589147560844491\n",
            "Batch 90 of 6492. Elapsed 0:00:26\n",
            "Sample: 0.8215017914772034 v/s 0.8203389048576355 v/s 0.8588001714218148\n",
            "Batch 100 of 6492. Elapsed 0:00:29\n",
            "Sample: 0.7896275520324707 v/s 0.7662315964698792 v/s 0.8196138322581635\n",
            "Batch 110 of 6492. Elapsed 0:00:32\n",
            "Sample: 0.7960978746414185 v/s 0.9046593308448792 v/s 0.91692078023671\n",
            "Batch 120 of 6492. Elapsed 0:00:35\n",
            "Sample: 0.8191227912902832 v/s 0.7595786452293396 v/s 0.8275217891466705\n",
            "Batch 130 of 6492. Elapsed 0:00:38\n",
            "Sample: 0.7929255366325378 v/s 0.8100168704986572 v/s 0.8507922045881887\n",
            "Batch 140 of 6492. Elapsed 0:00:41\n",
            "Sample: 0.8288025259971619 v/s 0.91737300157547 v/s 0.9367576550734966\n",
            "Batch 150 of 6492. Elapsed 0:00:45\n",
            "Sample: 0.786651074886322 v/s 0.7975494265556335 v/s 0.8267157729465122\n",
            "Batch 160 of 6492. Elapsed 0:00:48\n",
            "Sample: 0.8089891076087952 v/s 0.7896202206611633 v/s 0.8211630836226509\n",
            "Batch 170 of 6492. Elapsed 0:00:51\n",
            "Sample: 0.8206732273101807 v/s 0.8328703045845032 v/s 0.8822672652347434\n",
            "Batch 180 of 6492. Elapsed 0:00:53\n",
            "Sample: 0.8141226172447205 v/s 0.8114461898803711 v/s 0.8503120544280474\n",
            "Batch 190 of 6492. Elapsed 0:00:57\n",
            "Sample: 0.835191547870636 v/s 0.8042399883270264 v/s 0.8506790853976466\n",
            "Batch 200 of 6492. Elapsed 0:00:59\n",
            "Sample: 0.8338109254837036 v/s 0.8644611239433289 v/s 0.8916041478284609\n",
            "Batch 210 of 6492. Elapsed 0:01:02\n",
            "Sample: 0.8556860089302063 v/s 0.8912194967269897 v/s 0.9196699932211053\n",
            "Batch 220 of 6492. Elapsed 0:01:05\n",
            "Sample: 0.7509562373161316 v/s 0.6935189366340637 v/s 0.7691860142424853\n",
            "Batch 230 of 6492. Elapsed 0:01:09\n",
            "Sample: 0.8164295554161072 v/s 0.7744297981262207 v/s 0.8176035943080262\n",
            "Batch 240 of 6492. Elapsed 0:01:11\n",
            "Sample: 0.7961618304252625 v/s 0.7875357866287231 v/s 0.8251917727601398\n",
            "Batch 250 of 6492. Elapsed 0:01:14\n",
            "Sample: 0.8358649611473083 v/s 0.9193785786628723 v/s 0.9346646456910509\n",
            "Batch 260 of 6492. Elapsed 0:01:17\n",
            "Sample: 0.8119744658470154 v/s 0.7302488088607788 v/s 0.8134952314419909\n",
            "Batch 270 of 6492. Elapsed 0:01:20\n",
            "Sample: 0.7540578246116638 v/s 0.8167183995246887 v/s 0.8512541955718365\n",
            "Batch 280 of 6492. Elapsed 0:01:23\n",
            "Sample: 0.7776210308074951 v/s 0.8181344866752625 v/s 0.8521589183725611\n",
            "Batch 290 of 6492. Elapsed 0:01:26\n",
            "Sample: 0.6950439810752869 v/s 0.6515297293663025 v/s 0.7165151464779188\n",
            "Batch 300 of 6492. Elapsed 0:01:29\n",
            "Sample: 0.7727248072624207 v/s 0.7579619288444519 v/s 0.8126752398960605\n",
            "Batch 310 of 6492. Elapsed 0:01:32\n",
            "Sample: 0.7501993775367737 v/s 0.7849953174591064 v/s 0.8521068234077441\n",
            "Batch 320 of 6492. Elapsed 0:01:35\n",
            "Sample: 0.6967228055000305 v/s 0.701479434967041 v/s 0.7511532217679161\n",
            "Batch 330 of 6492. Elapsed 0:01:38\n",
            "Sample: 0.7669975757598877 v/s 0.7491706013679504 v/s 0.8094481261333757\n",
            "Batch 340 of 6492. Elapsed 0:01:41\n",
            "Sample: 0.7658201456069946 v/s 0.8336473703384399 v/s 0.8722778887929149\n",
            "Batch 350 of 6492. Elapsed 0:01:44\n",
            "Sample: 0.8206363320350647 v/s 0.7848491072654724 v/s 0.8427229761870464\n",
            "Batch 360 of 6492. Elapsed 0:01:47\n",
            "Sample: 0.8376796841621399 v/s 0.8057332634925842 v/s 0.8303327406556058\n",
            "Batch 370 of 6492. Elapsed 0:01:50\n",
            "Sample: 0.8406237363815308 v/s 0.8312316536903381 v/s 0.8808211230406586\n",
            "Batch 380 of 6492. Elapsed 0:01:53\n",
            "Sample: 0.7740169763565063 v/s 0.8018033504486084 v/s 0.8272434889959789\n",
            "Batch 390 of 6492. Elapsed 0:01:56\n",
            "Sample: 0.8243978023529053 v/s 0.8201345205307007 v/s 0.8632778929233621\n",
            "Batch 400 of 6492. Elapsed 0:01:59\n",
            "Sample: 0.8418698906898499 v/s 0.8090865612030029 v/s 0.8758717998630674\n",
            "Batch 410 of 6492. Elapsed 0:02:02\n",
            "Sample: 0.7829994559288025 v/s 0.8251784443855286 v/s 0.8718395256559931\n",
            "Batch 420 of 6492. Elapsed 0:02:05\n",
            "Sample: 0.8373856544494629 v/s 0.7671574354171753 v/s 0.8350514696249611\n",
            "Batch 430 of 6492. Elapsed 0:02:08\n",
            "Sample: 0.7323653697967529 v/s 0.7481175661087036 v/s 0.7946602370828427\n",
            "Batch 440 of 6492. Elapsed 0:02:11\n",
            "Sample: 0.8344386219978333 v/s 0.8035303354263306 v/s 0.8456511442217202\n",
            "Batch 450 of 6492. Elapsed 0:02:14\n",
            "Sample: 0.7734087705612183 v/s 0.701965868473053 v/s 0.7695739004282901\n",
            "Batch 460 of 6492. Elapsed 0:02:17\n",
            "Sample: 0.8769707083702087 v/s 0.9401764869689941 v/s 0.9589361164104765\n",
            "Batch 470 of 6492. Elapsed 0:02:20\n",
            "Sample: 0.7956147789955139 v/s 0.7698474526405334 v/s 0.8226140371696067\n",
            "Batch 480 of 6492. Elapsed 0:02:23\n",
            "Sample: 0.8418493866920471 v/s 0.8339898586273193 v/s 0.87878690862551\n",
            "Batch 490 of 6492. Elapsed 0:02:26\n",
            "Sample: 0.7927274703979492 v/s 0.7337733507156372 v/s 0.784352017681824\n",
            "Batch 500 of 6492. Elapsed 0:02:29\n",
            "Sample: 0.7743843793869019 v/s 0.7465986013412476 v/s 0.8056650886103236\n",
            "Batch 510 of 6492. Elapsed 0:02:32\n",
            "Sample: 0.8390861749649048 v/s 0.9265907406806946 v/s 0.9331599111395504\n",
            "Batch 520 of 6492. Elapsed 0:02:34\n",
            "Sample: 0.7105361223220825 v/s 0.6845265030860901 v/s 0.7668494357370699\n",
            "Batch 530 of 6492. Elapsed 0:02:37\n",
            "Sample: 0.7697293162345886 v/s 0.8901587128639221 v/s 0.9124943536906297\n",
            "Batch 540 of 6492. Elapsed 0:02:40\n",
            "Sample: 0.8391836881637573 v/s 0.6862461566925049 v/s 0.7858242555725228\n",
            "Batch 550 of 6492. Elapsed 0:02:43\n",
            "Sample: 0.8458560109138489 v/s 0.893232524394989 v/s 0.914671438549956\n",
            "Batch 560 of 6492. Elapsed 0:02:46\n",
            "Sample: 0.7334306836128235 v/s 0.7558562159538269 v/s 0.7931064192343391\n",
            "Batch 570 of 6492. Elapsed 0:02:49\n",
            "Sample: 0.7687816023826599 v/s 0.7496922612190247 v/s 0.7852411595342691\n",
            "Batch 580 of 6492. Elapsed 0:02:52\n",
            "Sample: 0.7785264849662781 v/s 0.7428311705589294 v/s 0.7826022747619403\n",
            "Batch 590 of 6492. Elapsed 0:02:55\n",
            "Sample: 0.8480316400527954 v/s 0.9423783421516418 v/s 0.9532752910852371\n",
            "Batch 600 of 6492. Elapsed 0:02:58\n",
            "Sample: 0.864001452922821 v/s 0.9336974620819092 v/s 0.9502831498342419\n",
            "Batch 610 of 6492. Elapsed 0:03:01\n",
            "Sample: 0.8578639626502991 v/s 0.8743147253990173 v/s 0.9087570854419723\n",
            "Batch 620 of 6492. Elapsed 0:03:04\n",
            "Sample: 0.7737914323806763 v/s 0.7801766395568848 v/s 0.8298111282501784\n",
            "Batch 630 of 6492. Elapsed 0:03:07\n",
            "Sample: 0.8590996265411377 v/s 0.886640727519989 v/s 0.9216674060842319\n",
            "Batch 640 of 6492. Elapsed 0:03:10\n",
            "Sample: 0.7969401478767395 v/s 0.7479724884033203 v/s 0.8076411349799266\n",
            "Batch 650 of 6492. Elapsed 0:03:13\n",
            "Sample: 0.7615923881530762 v/s 0.7578495740890503 v/s 0.802211893824646\n",
            "Batch 660 of 6492. Elapsed 0:03:15\n",
            "Sample: 0.832137942314148 v/s 0.8034212589263916 v/s 0.8270806855582046\n",
            "Batch 670 of 6492. Elapsed 0:03:18\n",
            "Sample: 0.7809579372406006 v/s 0.8230739235877991 v/s 0.8604153633107414\n",
            "Batch 680 of 6492. Elapsed 0:03:21\n",
            "Sample: 0.8386601805686951 v/s 0.7913313508033752 v/s 0.8389770567019512\n",
            "Batch 690 of 6492. Elapsed 0:03:25\n",
            "Sample: 0.8379423022270203 v/s 0.8574690818786621 v/s 0.8864465111965086\n",
            "Batch 700 of 6492. Elapsed 0:03:28\n",
            "Sample: 0.8004082441329956 v/s 0.7760741114616394 v/s 0.8368946117760003\n",
            "Batch 710 of 6492. Elapsed 0:03:31\n",
            "Sample: 0.7332906723022461 v/s 0.7872053384780884 v/s 0.8320317402140015\n",
            "Batch 720 of 6492. Elapsed 0:03:34\n",
            "Sample: 0.8528650403022766 v/s 0.8394792079925537 v/s 0.8949353690748086\n",
            "Batch 730 of 6492. Elapsed 0:03:37\n",
            "Sample: 0.81471848487854 v/s 0.8773400783538818 v/s 0.8982581134138752\n",
            "Batch 740 of 6492. Elapsed 0:03:40\n",
            "Sample: 0.8576229214668274 v/s 0.8169229030609131 v/s 0.8507854391705565\n",
            "Batch 750 of 6492. Elapsed 0:03:43\n",
            "Sample: 0.8245970606803894 v/s 0.8039525747299194 v/s 0.8599569537968554\n",
            "Batch 760 of 6492. Elapsed 0:03:46\n",
            "Sample: 0.8406640291213989 v/s 0.7964350581169128 v/s 0.8628245191699836\n",
            "Batch 770 of 6492. Elapsed 0:03:49\n",
            "Sample: 0.8153042793273926 v/s 0.7136741280555725 v/s 0.7750133597022945\n",
            "Batch 780 of 6492. Elapsed 0:03:52\n",
            "Sample: 0.784919798374176 v/s 0.7738920450210571 v/s 0.819992653874847\n",
            "Batch 790 of 6492. Elapsed 0:03:55\n",
            "Sample: 0.7976044416427612 v/s 0.7873093485832214 v/s 0.8242593432793452\n",
            "Batch 800 of 6492. Elapsed 0:03:58\n",
            "Sample: 0.7993301153182983 v/s 0.7758883833885193 v/s 0.8294525440637931\n",
            "Batch 810 of 6492. Elapsed 0:04:01\n",
            "Sample: 0.8732178211212158 v/s 0.8513157367706299 v/s 0.8822977765269927\n",
            "Batch 820 of 6492. Elapsed 0:04:04\n",
            "Sample: 0.8962973356246948 v/s 0.9155958294868469 v/s 0.9439913541233397\n",
            "Batch 830 of 6492. Elapsed 0:04:07\n",
            "Sample: 0.7814239263534546 v/s 0.7364174723625183 v/s 0.804097168910223\n",
            "Batch 840 of 6492. Elapsed 0:04:10\n",
            "Sample: 0.8300825357437134 v/s 0.8244205713272095 v/s 0.8605093446313193\n",
            "Batch 850 of 6492. Elapsed 0:04:13\n",
            "Sample: 0.8144568800926208 v/s 0.7118456959724426 v/s 0.7914113329853284\n",
            "Batch 860 of 6492. Elapsed 0:04:16\n",
            "Sample: 0.8281516432762146 v/s 0.8756802678108215 v/s 0.9159374568760056\n",
            "Batch 870 of 6492. Elapsed 0:04:19\n",
            "Sample: 0.7407211065292358 v/s 0.7069567441940308 v/s 0.7601260481105631\n",
            "Batch 880 of 6492. Elapsed 0:04:22\n",
            "Sample: 0.8185878992080688 v/s 0.8182101845741272 v/s 0.8546871136899497\n",
            "Batch 890 of 6492. Elapsed 0:04:25\n",
            "Sample: 0.7707489728927612 v/s 0.7411180138587952 v/s 0.7937987003339214\n",
            "Batch 900 of 6492. Elapsed 0:04:27\n",
            "Sample: 0.7659412026405334 v/s 0.7721851468086243 v/s 0.8165440695170074\n",
            "Batch 910 of 6492. Elapsed 0:04:31\n",
            "Sample: 0.8135330080986023 v/s 0.8201631307601929 v/s 0.8427005791827522\n",
            "Batch 920 of 6492. Elapsed 0:04:33\n",
            "Sample: 0.802982747554779 v/s 0.8201163411140442 v/s 0.8690785009994465\n",
            "Batch 930 of 6492. Elapsed 0:04:36\n",
            "Sample: 0.7775712609291077 v/s 0.8087502717971802 v/s 0.850333879663405\n",
            "Batch 940 of 6492. Elapsed 0:04:39\n",
            "Sample: 0.8139989972114563 v/s 0.7550492286682129 v/s 0.7917636370610419\n",
            "Batch 950 of 6492. Elapsed 0:04:42\n",
            "Sample: 0.747683048248291 v/s 0.7449212670326233 v/s 0.8017766128362208\n",
            "Batch 960 of 6492. Elapsed 0:04:45\n",
            "Sample: 0.7261385917663574 v/s 0.7019827365875244 v/s 0.7676223118197288\n",
            "Batch 970 of 6492. Elapsed 0:04:48\n",
            "Sample: 0.8364399671554565 v/s 0.8700334429740906 v/s 0.8957455901483294\n",
            "Batch 980 of 6492. Elapsed 0:04:51\n",
            "Sample: 0.8367491960525513 v/s 0.8090370893478394 v/s 0.8452218060658209\n",
            "Batch 990 of 6492. Elapsed 0:04:54\n",
            "Sample: 0.8087473511695862 v/s 0.8288756012916565 v/s 0.8608340728177006\n",
            "Batch 1000 of 6492. Elapsed 0:04:57\n",
            "Sample: 0.8883858919143677 v/s 0.9182312488555908 v/s 0.9371412313198575\n",
            "Batch 1010 of 6492. Elapsed 0:05:00\n",
            "Sample: 0.8896216154098511 v/s 0.9040433168411255 v/s 0.9399544687340403\n",
            "Batch 1020 of 6492. Elapsed 0:05:03\n",
            "Sample: 0.8397300839424133 v/s 0.8866124749183655 v/s 0.909011314394123\n",
            "Batch 1030 of 6492. Elapsed 0:05:06\n",
            "Sample: 0.7935593724250793 v/s 0.7944773435592651 v/s 0.8234722853945208\n",
            "Batch 1040 of 6492. Elapsed 0:05:09\n",
            "Sample: 0.7181374430656433 v/s 0.7106085419654846 v/s 0.7894659832820425\n",
            "Batch 1050 of 6492. Elapsed 0:05:12\n",
            "Sample: 0.8158098459243774 v/s 0.9431998133659363 v/s 0.9544383601308383\n",
            "Batch 1060 of 6492. Elapsed 0:05:15\n",
            "Sample: 0.836542010307312 v/s 0.8430674076080322 v/s 0.8677973654132592\n",
            "Batch 1070 of 6492. Elapsed 0:05:18\n",
            "Sample: 0.8856384754180908 v/s 0.8612155914306641 v/s 0.8909103015143452\n",
            "Batch 1080 of 6492. Elapsed 0:05:21\n",
            "Sample: 0.7731432914733887 v/s 0.840036928653717 v/s 0.8678149385002446\n",
            "Batch 1090 of 6492. Elapsed 0:05:24\n",
            "Sample: 0.7851353287696838 v/s 0.8875328302383423 v/s 0.9015286189046697\n",
            "Batch 1100 of 6492. Elapsed 0:05:26\n",
            "Sample: 0.8038239479064941 v/s 0.8265727758407593 v/s 0.8641482687404249\n",
            "Batch 1110 of 6492. Elapsed 0:05:29\n",
            "Sample: 0.8308964371681213 v/s 0.8327401876449585 v/s 0.8861674786509538\n",
            "Batch 1120 of 6492. Elapsed 0:05:32\n",
            "Sample: 0.7262712717056274 v/s 0.6593473553657532 v/s 0.7470602044541342\n",
            "Batch 1130 of 6492. Elapsed 0:05:35\n",
            "Sample: 0.7816804051399231 v/s 0.8201732039451599 v/s 0.869127598259927\n",
            "Batch 1140 of 6492. Elapsed 0:05:38\n",
            "Sample: 0.7837310433387756 v/s 0.7955743074417114 v/s 0.8421410227312438\n",
            "Batch 1150 of 6492. Elapsed 0:05:41\n",
            "Sample: 0.7992587089538574 v/s 0.8381717801094055 v/s 0.8667924953680891\n",
            "Batch 1160 of 6492. Elapsed 0:05:44\n",
            "Sample: 0.8105121850967407 v/s 0.8074488639831543 v/s 0.8644382542692439\n",
            "Batch 1170 of 6492. Elapsed 0:05:47\n",
            "Sample: 0.7886541485786438 v/s 0.8032822012901306 v/s 0.8342829722117822\n",
            "Batch 1180 of 6492. Elapsed 0:05:50\n",
            "Sample: 0.8381315469741821 v/s 0.902388334274292 v/s 0.9262028589124081\n",
            "Batch 1190 of 6492. Elapsed 0:05:53\n",
            "Sample: 0.8556219935417175 v/s 0.8870915770530701 v/s 0.9217643351270413\n",
            "Batch 1200 of 6492. Elapsed 0:05:57\n",
            "Sample: 0.7786371111869812 v/s 0.7188996076583862 v/s 0.7715439973080657\n",
            "Batch 1210 of 6492. Elapsed 0:06:00\n",
            "Sample: 0.7419986128807068 v/s 0.7407411336898804 v/s 0.7840705967861868\n",
            "Batch 1220 of 6492. Elapsed 0:06:02\n",
            "Sample: 0.8224365711212158 v/s 0.7944809198379517 v/s 0.8312830413702669\n",
            "Batch 1230 of 6492. Elapsed 0:06:06\n",
            "Sample: 0.8083367347717285 v/s 0.8563892841339111 v/s 0.8887339300780517\n",
            "Batch 1240 of 6492. Elapsed 0:06:08\n",
            "Sample: 0.8140535950660706 v/s 0.817390501499176 v/s 0.8614185324290011\n",
            "Batch 1250 of 6492. Elapsed 0:06:12\n",
            "Sample: 0.8742060661315918 v/s 0.8450070023536682 v/s 0.8833645604897666\n",
            "Batch 1260 of 6492. Elapsed 0:06:14\n",
            "Sample: 0.8422166705131531 v/s 0.799774706363678 v/s 0.8554568200585042\n",
            "Batch 1270 of 6492. Elapsed 0:06:17\n",
            "Sample: 0.9050388932228088 v/s 0.94849693775177 v/s 0.9629421890393352\n",
            "Batch 1280 of 6492. Elapsed 0:06:20\n",
            "Sample: 0.7322297096252441 v/s 0.6943501830101013 v/s 0.7604358307251572\n",
            "Batch 1290 of 6492. Elapsed 0:06:23\n",
            "Sample: 0.6637582778930664 v/s 0.6618323922157288 v/s 0.7514332847942691\n",
            "Batch 1300 of 6492. Elapsed 0:06:26\n",
            "Sample: 0.6846118569374084 v/s 0.6931020021438599 v/s 0.7882607062388853\n",
            "Batch 1310 of 6492. Elapsed 0:06:29\n",
            "Sample: 0.6864806413650513 v/s 0.706291913986206 v/s 0.755263706045805\n",
            "Batch 1320 of 6492. Elapsed 0:06:32\n",
            "Sample: 0.7940393686294556 v/s 0.7524966597557068 v/s 0.8212240624756694\n",
            "Batch 1330 of 6492. Elapsed 0:06:35\n",
            "Sample: 0.7876016497612 v/s 0.7292957901954651 v/s 0.8161917751456216\n",
            "Batch 1340 of 6492. Elapsed 0:06:38\n",
            "Sample: 0.8224054574966431 v/s 0.7931957244873047 v/s 0.8478518575565944\n",
            "Batch 1350 of 6492. Elapsed 0:06:41\n",
            "Sample: 0.8199021816253662 v/s 0.8703699111938477 v/s 0.9005049989901563\n",
            "Batch 1360 of 6492. Elapsed 0:06:44\n",
            "Sample: 0.839458167552948 v/s 0.7532410621643066 v/s 0.7996722344657466\n",
            "Batch 1370 of 6492. Elapsed 0:06:47\n",
            "Sample: 0.8085242509841919 v/s 0.8086307644844055 v/s 0.8762869234903832\n",
            "Batch 1380 of 6492. Elapsed 0:06:51\n",
            "Sample: 0.8814922571182251 v/s 0.890227735042572 v/s 0.9244264841710452\n",
            "Batch 1390 of 6492. Elapsed 0:06:54\n",
            "Sample: 0.8570448756217957 v/s 0.7951126098632812 v/s 0.8512497149408261\n",
            "Batch 1400 of 6492. Elapsed 0:06:56\n",
            "Sample: 0.8041633367538452 v/s 0.7952596545219421 v/s 0.8517877450162583\n",
            "Batch 1410 of 6492. Elapsed 0:06:59\n",
            "Sample: 0.8656749725341797 v/s 0.9043277502059937 v/s 0.9240588328222963\n",
            "Batch 1420 of 6492. Elapsed 0:07:02\n",
            "Sample: 0.8478630781173706 v/s 0.7857232689857483 v/s 0.8246168303291523\n",
            "Batch 1430 of 6492. Elapsed 0:07:05\n",
            "Sample: 0.8000670075416565 v/s 0.8793174624443054 v/s 0.8919203626927424\n",
            "Batch 1440 of 6492. Elapsed 0:07:08\n",
            "Sample: 0.6751276254653931 v/s 0.6689661741256714 v/s 0.7278603291273862\n",
            "Batch 1450 of 6492. Elapsed 0:07:11\n",
            "Sample: 0.8164489269256592 v/s 0.7541201114654541 v/s 0.8018645622870131\n",
            "Batch 1460 of 6492. Elapsed 0:07:14\n",
            "Sample: 0.8476986289024353 v/s 0.7607384324073792 v/s 0.8297366580385566\n",
            "Batch 1470 of 6492. Elapsed 0:07:17\n",
            "Sample: 0.8076705932617188 v/s 0.7329418659210205 v/s 0.8094654127536264\n",
            "Batch 1480 of 6492. Elapsed 0:07:20\n",
            "Sample: 0.8262478709220886 v/s 0.7989175915718079 v/s 0.8417758032572089\n",
            "Batch 1490 of 6492. Elapsed 0:07:23\n",
            "Sample: 0.7506384253501892 v/s 0.867792010307312 v/s 0.8915175964742007\n",
            "Batch 1500 of 6492. Elapsed 0:07:26\n",
            "Sample: 0.7873225808143616 v/s 0.7763535380363464 v/s 0.824473682391636\n",
            "Batch 1510 of 6492. Elapsed 0:07:29\n",
            "Sample: 0.8593911528587341 v/s 0.8447535037994385 v/s 0.8975709288424335\n",
            "Batch 1520 of 6492. Elapsed 0:07:32\n",
            "Sample: 0.8321291208267212 v/s 0.7655733823776245 v/s 0.8182073604285899\n",
            "Batch 1530 of 6492. Elapsed 0:07:35\n",
            "Sample: 0.8011160492897034 v/s 0.8716221451759338 v/s 0.8925537710814565\n",
            "Batch 1540 of 6492. Elapsed 0:07:38\n",
            "Sample: 0.7695086002349854 v/s 0.8332726359367371 v/s 0.8697115182005719\n",
            "Batch 1550 of 6492. Elapsed 0:07:41\n",
            "Sample: 0.8921219706535339 v/s 0.8514799475669861 v/s 0.8948622389051212\n",
            "Batch 1560 of 6492. Elapsed 0:07:44\n",
            "Sample: 0.8803551197052002 v/s 0.8846471309661865 v/s 0.912541311199766\n",
            "Batch 1570 of 6492. Elapsed 0:07:47\n",
            "Sample: 0.8634476661682129 v/s 0.8054648637771606 v/s 0.8564931018198545\n",
            "Batch 1580 of 6492. Elapsed 0:07:50\n",
            "Sample: 0.7864922285079956 v/s 0.7448854446411133 v/s 0.7950871063607645\n",
            "Batch 1590 of 6492. Elapsed 0:07:53\n",
            "Sample: 0.7557647228240967 v/s 0.7082093954086304 v/s 0.7640622952257569\n",
            "Batch 1600 of 6492. Elapsed 0:07:56\n",
            "Sample: 0.7402771711349487 v/s 0.749205470085144 v/s 0.7870515736120591\n",
            "Batch 1610 of 6492. Elapsed 0:07:59\n",
            "Sample: 0.8150718808174133 v/s 0.7657126784324646 v/s 0.8118456888920149\n",
            "Batch 1620 of 6492. Elapsed 0:08:02\n",
            "Sample: 0.8098073601722717 v/s 0.7734401226043701 v/s 0.8218046235959614\n",
            "Batch 1630 of 6492. Elapsed 0:08:05\n",
            "Sample: 0.8424047827720642 v/s 0.7959039211273193 v/s 0.839611675115042\n",
            "Batch 1640 of 6492. Elapsed 0:08:08\n",
            "Sample: 0.7020829916000366 v/s 0.6639679074287415 v/s 0.7333811580001713\n",
            "Batch 1650 of 6492. Elapsed 0:08:11\n",
            "Sample: 0.8294098973274231 v/s 0.8716005086898804 v/s 0.8885243462693172\n",
            "Batch 1660 of 6492. Elapsed 0:08:14\n",
            "Sample: 0.75016850233078 v/s 0.7229581475257874 v/s 0.7968733911412683\n",
            "Batch 1670 of 6492. Elapsed 0:08:17\n",
            "Sample: 0.8614323735237122 v/s 0.8892136812210083 v/s 0.9099031332186918\n",
            "Batch 1680 of 6492. Elapsed 0:08:20\n",
            "Sample: 0.7642098665237427 v/s 0.7392179369926453 v/s 0.7861768614599586\n",
            "Batch 1690 of 6492. Elapsed 0:08:23\n",
            "Sample: 0.7635513544082642 v/s 0.7473779916763306 v/s 0.7978912559521822\n",
            "Batch 1700 of 6492. Elapsed 0:08:26\n",
            "Sample: 0.6444449424743652 v/s 0.6946249604225159 v/s 0.7829000049361319\n",
            "Batch 1710 of 6492. Elapsed 0:08:29\n",
            "Sample: 0.7449179887771606 v/s 0.700063169002533 v/s 0.7597732159482974\n",
            "Batch 1720 of 6492. Elapsed 0:08:32\n",
            "Sample: 0.795832097530365 v/s 0.7976594567298889 v/s 0.845371377015933\n",
            "Batch 1730 of 6492. Elapsed 0:08:35\n",
            "Sample: 0.8259643316268921 v/s 0.8592235445976257 v/s 0.884416391662279\n",
            "Batch 1740 of 6492. Elapsed 0:08:38\n",
            "Sample: 0.803149402141571 v/s 0.8109824657440186 v/s 0.8486560230066137\n",
            "Batch 1750 of 6492. Elapsed 0:08:41\n",
            "Sample: 0.8030698895454407 v/s 0.7890295386314392 v/s 0.84535885659006\n",
            "Batch 1760 of 6492. Elapsed 0:08:44\n",
            "Sample: 0.8405420780181885 v/s 0.8233035206794739 v/s 0.8709663592201735\n",
            "Batch 1770 of 6492. Elapsed 0:08:47\n",
            "Sample: 0.6578566431999207 v/s 0.5810255408287048 v/s 0.7156849902436332\n",
            "Batch 1780 of 6492. Elapsed 0:08:50\n",
            "Sample: 0.8389880657196045 v/s 0.8732512593269348 v/s 0.9047455687272185\n",
            "Batch 1790 of 6492. Elapsed 0:08:53\n",
            "Sample: 0.7457737922668457 v/s 0.7696869969367981 v/s 0.8012265712650587\n",
            "Batch 1800 of 6492. Elapsed 0:08:55\n",
            "Sample: 0.7986374497413635 v/s 0.8051812648773193 v/s 0.8449035545898484\n",
            "Batch 1810 of 6492. Elapsed 0:08:59\n",
            "Sample: 0.8683791160583496 v/s 0.8593346476554871 v/s 0.8865469843567976\n",
            "Batch 1820 of 6492. Elapsed 0:09:02\n",
            "Sample: 0.8732183575630188 v/s 0.8464414477348328 v/s 0.8797195919878054\n",
            "Batch 1830 of 6492. Elapsed 0:09:05\n",
            "Sample: 0.7679567337036133 v/s 0.7798476219177246 v/s 0.8120853291840352\n",
            "Batch 1840 of 6492. Elapsed 0:09:07\n",
            "Sample: 0.8821573257446289 v/s 0.957392156124115 v/s 0.9660636369828179\n",
            "Batch 1850 of 6492. Elapsed 0:09:11\n",
            "Sample: 0.7766680121421814 v/s 0.7870863080024719 v/s 0.8208799670244191\n",
            "Batch 1860 of 6492. Elapsed 0:09:14\n",
            "Sample: 0.7263736724853516 v/s 0.7293950319290161 v/s 0.7875979396080058\n",
            "Batch 1870 of 6492. Elapsed 0:09:17\n",
            "Sample: 0.6710066199302673 v/s 0.7252815961837769 v/s 0.7961827952378666\n",
            "Batch 1880 of 6492. Elapsed 0:09:20\n",
            "Sample: 0.7968869805335999 v/s 0.8024741411209106 v/s 0.8500038116196775\n",
            "Batch 1890 of 6492. Elapsed 0:09:23\n",
            "Sample: 0.8728631734848022 v/s 0.8698075413703918 v/s 0.8936162722663364\n",
            "Batch 1900 of 6492. Elapsed 0:09:26\n",
            "Sample: 0.770035445690155 v/s 0.772811770439148 v/s 0.8090218782630556\n",
            "Batch 1910 of 6492. Elapsed 0:09:29\n",
            "Sample: 0.8008764982223511 v/s 0.829720675945282 v/s 0.8638580785663891\n",
            "Batch 1920 of 6492. Elapsed 0:09:32\n",
            "Sample: 0.8005881905555725 v/s 0.7794262766838074 v/s 0.8401438073154971\n",
            "Batch 1930 of 6492. Elapsed 0:09:34\n",
            "Sample: 0.7879617214202881 v/s 0.8500730395317078 v/s 0.877474361501603\n",
            "Batch 1940 of 6492. Elapsed 0:09:37\n",
            "Sample: 0.7520458102226257 v/s 0.7720706462860107 v/s 0.8204931569561548\n",
            "Batch 1950 of 6492. Elapsed 0:09:40\n",
            "Sample: 0.7877424359321594 v/s 0.8132619857788086 v/s 0.8476047726233917\n",
            "Batch 1960 of 6492. Elapsed 0:09:43\n",
            "Sample: 0.817808985710144 v/s 0.8453987836837769 v/s 0.8772729695915482\n",
            "Batch 1970 of 6492. Elapsed 0:09:46\n",
            "Sample: 0.8328270316123962 v/s 0.8493024110794067 v/s 0.8775648206770634\n",
            "Batch 1980 of 6492. Elapsed 0:09:49\n",
            "Sample: 0.7912500500679016 v/s 0.7546682357788086 v/s 0.8160240972287199\n",
            "Batch 1990 of 6492. Elapsed 0:09:52\n",
            "Sample: 0.8467776775360107 v/s 0.8816571831703186 v/s 0.9135650073473968\n",
            "Batch 2000 of 6492. Elapsed 0:09:55\n",
            "Sample: 0.8959230184555054 v/s 0.8447416424751282 v/s 0.8854590639617289\n",
            "Batch 2010 of 6492. Elapsed 0:09:58\n",
            "Sample: 0.7623753547668457 v/s 0.7176722884178162 v/s 0.7688136239214999\n",
            "Batch 2020 of 6492. Elapsed 0:10:01\n",
            "Sample: 0.7766900062561035 v/s 0.6946540474891663 v/s 0.7504959484250237\n",
            "Batch 2030 of 6492. Elapsed 0:10:04\n",
            "Sample: 0.8689593076705933 v/s 0.8676502108573914 v/s 0.888768166890323\n",
            "Batch 2040 of 6492. Elapsed 0:10:07\n",
            "Sample: 0.7972138524055481 v/s 0.8418440222740173 v/s 0.8776799913956499\n",
            "Batch 2050 of 6492. Elapsed 0:10:10\n",
            "Sample: 0.7677748203277588 v/s 0.8006457686424255 v/s 0.8426645550645931\n",
            "Batch 2060 of 6492. Elapsed 0:10:13\n",
            "Sample: 0.8721937537193298 v/s 0.8719005584716797 v/s 0.8997960924908508\n",
            "Batch 2070 of 6492. Elapsed 0:10:16\n",
            "Sample: 0.8099888563156128 v/s 0.770348846912384 v/s 0.8273499894235462\n",
            "Batch 2080 of 6492. Elapsed 0:10:19\n",
            "Sample: 0.85340416431427 v/s 0.8646601438522339 v/s 0.8938631244977157\n",
            "Batch 2090 of 6492. Elapsed 0:10:22\n",
            "Sample: 0.8296451568603516 v/s 0.8843730092048645 v/s 0.9016729653983856\n",
            "Batch 2100 of 6492. Elapsed 0:10:25\n",
            "Sample: 0.7455330491065979 v/s 0.7200376987457275 v/s 0.7744124119550717\n",
            "Batch 2110 of 6492. Elapsed 0:10:28\n",
            "Sample: 0.7054886221885681 v/s 0.7423754930496216 v/s 0.7977798804071836\n",
            "Batch 2120 of 6492. Elapsed 0:10:31\n",
            "Sample: 0.8365292549133301 v/s 0.8783788084983826 v/s 0.8943251345053997\n",
            "Batch 2130 of 6492. Elapsed 0:10:34\n",
            "Sample: 0.8413674831390381 v/s 0.8408271074295044 v/s 0.8745530290570404\n",
            "Batch 2140 of 6492. Elapsed 0:10:36\n",
            "Sample: 0.7617080807685852 v/s 0.7735552191734314 v/s 0.8133864220231398\n",
            "Batch 2150 of 6492. Elapsed 0:10:40\n",
            "Sample: 0.8647809028625488 v/s 0.8508576154708862 v/s 0.8808431884314185\n",
            "Batch 2160 of 6492. Elapsed 0:10:43\n",
            "Sample: 0.8349273800849915 v/s 0.8730393052101135 v/s 0.9135517763391108\n",
            "Batch 2170 of 6492. Elapsed 0:10:46\n",
            "Sample: 0.8010938167572021 v/s 0.7914317846298218 v/s 0.83163041538433\n",
            "Batch 2180 of 6492. Elapsed 0:10:49\n",
            "Sample: 0.7917105555534363 v/s 0.7426552176475525 v/s 0.7999561482424191\n",
            "Batch 2190 of 6492. Elapsed 0:10:52\n",
            "Sample: 0.7767378687858582 v/s 0.9140640497207642 v/s 0.9367053801365043\n",
            "Batch 2200 of 6492. Elapsed 0:10:54\n",
            "Sample: 0.8403626680374146 v/s 0.8798460364341736 v/s 0.9048320735724202\n",
            "Batch 2210 of 6492. Elapsed 0:10:57\n",
            "Sample: 0.7682808637619019 v/s 0.7646603584289551 v/s 0.8093545386796189\n",
            "Batch 2220 of 6492. Elapsed 0:11:00\n",
            "Sample: 0.7537060379981995 v/s 0.8057904839515686 v/s 0.8394173167276887\n",
            "Batch 2230 of 6492. Elapsed 0:11:03\n",
            "Sample: 0.8446180820465088 v/s 0.8389237523078918 v/s 0.8567845880400935\n",
            "Batch 2240 of 6492. Elapsed 0:11:06\n",
            "Sample: 0.787002682685852 v/s 0.806265115737915 v/s 0.8475884090151841\n",
            "Batch 2250 of 6492. Elapsed 0:11:09\n",
            "Sample: 0.7194682955741882 v/s 0.7228125929832458 v/s 0.7766404073464562\n",
            "Batch 2260 of 6492. Elapsed 0:11:12\n",
            "Sample: 0.8923215866088867 v/s 0.9011562466621399 v/s 0.9299890851196524\n",
            "Batch 2270 of 6492. Elapsed 0:11:14\n",
            "Sample: 0.8762068152427673 v/s 0.9512925744056702 v/s 0.95928157364915\n",
            "Batch 2280 of 6492. Elapsed 0:11:17\n",
            "Sample: 0.7697353959083557 v/s 0.7297330498695374 v/s 0.789650501557401\n",
            "Batch 2290 of 6492. Elapsed 0:11:20\n",
            "Sample: 0.8228737711906433 v/s 0.7469516396522522 v/s 0.8097325261719017\n",
            "Batch 2300 of 6492. Elapsed 0:11:23\n",
            "Sample: 0.8447691798210144 v/s 0.8393088579177856 v/s 0.8743702845495194\n",
            "Batch 2310 of 6492. Elapsed 0:11:26\n",
            "Sample: 0.8473606705665588 v/s 0.8717937469482422 v/s 0.8888632430375452\n",
            "Batch 2320 of 6492. Elapsed 0:11:29\n",
            "Sample: 0.7770414352416992 v/s 0.8052796721458435 v/s 0.8448937758754621\n",
            "Batch 2330 of 6492. Elapsed 0:11:32\n",
            "Sample: 0.8122962117195129 v/s 0.7906458973884583 v/s 0.8491827497163477\n",
            "Batch 2340 of 6492. Elapsed 0:11:35\n",
            "Sample: 0.8837162852287292 v/s 0.9701520800590515 v/s 0.9811061961072466\n",
            "Batch 2350 of 6492. Elapsed 0:11:38\n",
            "Sample: 0.6686406135559082 v/s 0.6748393774032593 v/s 0.7315964857784546\n",
            "Batch 2360 of 6492. Elapsed 0:11:41\n",
            "Sample: 0.7814984917640686 v/s 0.7570702433586121 v/s 0.8037056229122251\n",
            "Batch 2370 of 6492. Elapsed 0:11:44\n",
            "Sample: 0.8000213503837585 v/s 0.8042073845863342 v/s 0.834661806850539\n",
            "Batch 2380 of 6492. Elapsed 0:11:47\n",
            "Sample: 0.8147612810134888 v/s 0.7617696523666382 v/s 0.8103023246733742\n",
            "Batch 2390 of 6492. Elapsed 0:11:50\n",
            "Sample: 0.7816582918167114 v/s 0.8568036556243896 v/s 0.880359508292361\n",
            "Batch 2400 of 6492. Elapsed 0:11:53\n",
            "Sample: 0.7006496787071228 v/s 0.6862053871154785 v/s 0.7638459717125534\n",
            "Batch 2410 of 6492. Elapsed 0:11:56\n",
            "Sample: 0.8273893594741821 v/s 0.8526092767715454 v/s 0.8768062463669357\n",
            "Batch 2420 of 6492. Elapsed 0:11:59\n",
            "Sample: 0.8835251331329346 v/s 0.8352659940719604 v/s 0.8984895973530227\n",
            "Batch 2430 of 6492. Elapsed 0:12:02\n",
            "Sample: 0.8348236680030823 v/s 0.8270260691642761 v/s 0.865963074157141\n",
            "Batch 2440 of 6492. Elapsed 0:12:05\n",
            "Sample: 0.8747007250785828 v/s 0.8180612921714783 v/s 0.834106654353752\n",
            "Batch 2450 of 6492. Elapsed 0:12:08\n",
            "Sample: 0.6349424123764038 v/s 0.6378509402275085 v/s 0.7293876242373928\n",
            "Batch 2460 of 6492. Elapsed 0:12:11\n",
            "Sample: 0.8945105075836182 v/s 0.928741991519928 v/s 0.9483394530163674\n",
            "Batch 2470 of 6492. Elapsed 0:12:14\n",
            "Sample: 0.8911553025245667 v/s 0.893978476524353 v/s 0.9245821459781275\n",
            "Batch 2480 of 6492. Elapsed 0:12:17\n",
            "Sample: 0.824024498462677 v/s 0.8241025805473328 v/s 0.8523857661442343\n",
            "Batch 2490 of 6492. Elapsed 0:12:20\n",
            "Sample: 0.7481285333633423 v/s 0.7474161982536316 v/s 0.8069158631190075\n",
            "Batch 2500 of 6492. Elapsed 0:12:23\n",
            "Sample: 0.7592646479606628 v/s 0.7527931928634644 v/s 0.8211859148470022\n",
            "Batch 2510 of 6492. Elapsed 0:12:26\n",
            "Sample: 0.7059897780418396 v/s 0.7602618336677551 v/s 0.8301919729556368\n",
            "Batch 2520 of 6492. Elapsed 0:12:29\n",
            "Sample: 0.8069212436676025 v/s 0.7938272953033447 v/s 0.8197853852545268\n",
            "Batch 2530 of 6492. Elapsed 0:12:32\n",
            "Sample: 0.6567607522010803 v/s 0.6318773627281189 v/s 0.7059567488558666\n",
            "Batch 2540 of 6492. Elapsed 0:12:34\n",
            "Sample: 0.8059068918228149 v/s 0.9131796360015869 v/s 0.9299805469442948\n",
            "Batch 2550 of 6492. Elapsed 0:12:38\n",
            "Sample: 0.9056332111358643 v/s 0.93351811170578 v/s 0.9425725226787698\n",
            "Batch 2560 of 6492. Elapsed 0:12:41\n",
            "Sample: 0.6727050542831421 v/s 0.6989167928695679 v/s 0.76476349724496\n",
            "Batch 2570 of 6492. Elapsed 0:12:44\n",
            "Sample: 0.8291643857955933 v/s 0.8498602509498596 v/s 0.8757452207798276\n",
            "Batch 2580 of 6492. Elapsed 0:12:46\n",
            "Sample: 0.8559975028038025 v/s 0.8080148100852966 v/s 0.8628261488054743\n",
            "Batch 2590 of 6492. Elapsed 0:12:49\n",
            "Sample: 0.8356940746307373 v/s 0.900995135307312 v/s 0.9156050660566991\n",
            "Batch 2600 of 6492. Elapsed 0:12:52\n",
            "Sample: 0.8379913568496704 v/s 0.8958299160003662 v/s 0.9147386189271487\n",
            "Batch 2610 of 6492. Elapsed 0:12:55\n",
            "Sample: 0.7821753621101379 v/s 0.7361710071563721 v/s 0.7947364232731745\n",
            "Batch 2620 of 6492. Elapsed 0:12:58\n",
            "Sample: 0.8210331201553345 v/s 0.7720115780830383 v/s 0.8349282018883424\n",
            "Batch 2630 of 6492. Elapsed 0:13:01\n",
            "Sample: 0.7309942841529846 v/s 0.6292656660079956 v/s 0.7200110736976697\n",
            "Batch 2640 of 6492. Elapsed 0:13:04\n",
            "Sample: 0.756655752658844 v/s 0.7720460295677185 v/s 0.8215182789218309\n",
            "Batch 2650 of 6492. Elapsed 0:13:07\n",
            "Sample: 0.8203976154327393 v/s 0.8000695109367371 v/s 0.82906251549389\n",
            "Batch 2660 of 6492. Elapsed 0:13:10\n",
            "Sample: 0.8003886938095093 v/s 0.7844401001930237 v/s 0.813787052418143\n",
            "Batch 2670 of 6492. Elapsed 0:13:13\n",
            "Sample: 0.7354437708854675 v/s 0.7132306694984436 v/s 0.7922306461341981\n",
            "Batch 2680 of 6492. Elapsed 0:13:16\n",
            "Sample: 0.8117012977600098 v/s 0.8313905596733093 v/s 0.8692641019776383\n",
            "Batch 2690 of 6492. Elapsed 0:13:19\n",
            "Sample: 0.8775451183319092 v/s 0.8547056317329407 v/s 0.900383322271282\n",
            "Batch 2700 of 6492. Elapsed 0:13:21\n",
            "Sample: 0.8162826895713806 v/s 0.8153294324874878 v/s 0.851500518470516\n",
            "Batch 2710 of 6492. Elapsed 0:13:24\n",
            "Sample: 0.8811765909194946 v/s 0.9405476450920105 v/s 0.9550351116635901\n",
            "Batch 2720 of 6492. Elapsed 0:13:27\n",
            "Sample: 0.8141961693763733 v/s 0.7596916556358337 v/s 0.8174319483919253\n",
            "Batch 2730 of 6492. Elapsed 0:13:30\n",
            "Sample: 0.799999475479126 v/s 0.7823418378829956 v/s 0.817804373240673\n",
            "Batch 2740 of 6492. Elapsed 0:13:33\n",
            "Sample: 0.7650545835494995 v/s 0.852834939956665 v/s 0.8830423947561545\n",
            "Batch 2750 of 6492. Elapsed 0:13:36\n",
            "Sample: 0.8422747850418091 v/s 0.7849023342132568 v/s 0.837102911714882\n",
            "Batch 2760 of 6492. Elapsed 0:13:39\n",
            "Sample: 0.6871604323387146 v/s 0.6552088856697083 v/s 0.7414264528253703\n",
            "Batch 2770 of 6492. Elapsed 0:13:42\n",
            "Sample: 0.8568049669265747 v/s 0.8857927918434143 v/s 0.9129391610294618\n",
            "Batch 2780 of 6492. Elapsed 0:13:45\n",
            "Sample: 0.7533616423606873 v/s 0.7088579535484314 v/s 0.7670415861533559\n",
            "Batch 2790 of 6492. Elapsed 0:13:48\n",
            "Sample: 0.8349094390869141 v/s 0.8402687907218933 v/s 0.8832895338329191\n",
            "Batch 2800 of 6492. Elapsed 0:13:51\n",
            "Sample: 0.80819171667099 v/s 0.7968120574951172 v/s 0.8442721308956125\n",
            "Batch 2810 of 6492. Elapsed 0:13:54\n",
            "Sample: 0.6861619353294373 v/s 0.748554527759552 v/s 0.8027803285071208\n",
            "Batch 2820 of 6492. Elapsed 0:13:57\n",
            "Sample: 0.8194407820701599 v/s 0.8208855986595154 v/s 0.8542536945635334\n",
            "Batch 2830 of 6492. Elapsed 0:14:00\n",
            "Sample: 0.7290723919868469 v/s 0.7494701743125916 v/s 0.7934519287245619\n",
            "Batch 2840 of 6492. Elapsed 0:14:03\n",
            "Sample: 0.6816762685775757 v/s 0.7443011403083801 v/s 0.7923878180596455\n",
            "Batch 2850 of 6492. Elapsed 0:14:06\n",
            "Sample: 0.730877697467804 v/s 0.7960426211357117 v/s 0.8313231463617569\n",
            "Batch 2860 of 6492. Elapsed 0:14:09\n",
            "Sample: 0.8290309906005859 v/s 0.7783477306365967 v/s 0.8161764024309104\n",
            "Batch 2870 of 6492. Elapsed 0:14:12\n",
            "Sample: 0.8211160898208618 v/s 0.7664337158203125 v/s 0.7912812464263248\n",
            "Batch 2880 of 6492. Elapsed 0:14:15\n",
            "Sample: 0.7388423681259155 v/s 0.7048556208610535 v/s 0.7652258624251238\n",
            "Batch 2890 of 6492. Elapsed 0:14:18\n",
            "Sample: 0.7923840880393982 v/s 0.7631811499595642 v/s 0.8382697433355266\n",
            "Batch 2900 of 6492. Elapsed 0:14:21\n",
            "Sample: 0.7244816422462463 v/s 0.7048501372337341 v/s 0.7765505431506518\n",
            "Batch 2910 of 6492. Elapsed 0:14:24\n",
            "Sample: 0.8337893486022949 v/s 0.8161548972129822 v/s 0.882945055320625\n",
            "Batch 2920 of 6492. Elapsed 0:14:27\n",
            "Sample: 0.6583340167999268 v/s 0.7822380661964417 v/s 0.8224402323319159\n",
            "Batch 2930 of 6492. Elapsed 0:14:30\n",
            "Sample: 0.8381092548370361 v/s 0.8599815964698792 v/s 0.8872813791922004\n",
            "Batch 2940 of 6492. Elapsed 0:14:33\n",
            "Sample: 0.7394891381263733 v/s 0.7252956032752991 v/s 0.7756036177167124\n",
            "Batch 2950 of 6492. Elapsed 0:14:36\n",
            "Sample: 0.742177426815033 v/s 0.6180796027183533 v/s 0.6895538180071539\n",
            "Batch 2960 of 6492. Elapsed 0:14:39\n",
            "Sample: 0.7586467266082764 v/s 0.74068284034729 v/s 0.8054717583217721\n",
            "Batch 2970 of 6492. Elapsed 0:14:42\n",
            "Sample: 0.8312430381774902 v/s 0.8382086753845215 v/s 0.8749633652326827\n",
            "Batch 2980 of 6492. Elapsed 0:14:45\n",
            "Sample: 0.7927787899971008 v/s 0.8206745386123657 v/s 0.8553745460788198\n",
            "Batch 2990 of 6492. Elapsed 0:14:48\n",
            "Sample: 0.8305465579032898 v/s 0.8740740418434143 v/s 0.9115587588427825\n",
            "Batch 3000 of 6492. Elapsed 0:14:51\n",
            "Sample: 0.8391324877738953 v/s 0.8218213319778442 v/s 0.887249391487135\n",
            "Batch 3010 of 6492. Elapsed 0:14:54\n",
            "Sample: 0.8022189736366272 v/s 0.7991814017295837 v/s 0.8306030706410362\n",
            "Batch 3020 of 6492. Elapsed 0:14:57\n",
            "Sample: 0.8501631021499634 v/s 0.8514266610145569 v/s 0.8656120518381029\n",
            "Batch 3030 of 6492. Elapsed 0:15:00\n",
            "Sample: 0.8309099674224854 v/s 0.8585533499717712 v/s 0.8846698547080311\n",
            "Batch 3040 of 6492. Elapsed 0:15:03\n",
            "Sample: 0.8748199939727783 v/s 0.8504717350006104 v/s 0.8809292879244403\n",
            "Batch 3050 of 6492. Elapsed 0:15:06\n",
            "Sample: 0.8187869787216187 v/s 0.8355500102043152 v/s 0.8791648271425224\n",
            "Batch 3060 of 6492. Elapsed 0:15:09\n",
            "Sample: 0.875251293182373 v/s 0.9066740870475769 v/s 0.9219691441241272\n",
            "Batch 3070 of 6492. Elapsed 0:15:12\n",
            "Sample: 0.8283666372299194 v/s 0.8975663185119629 v/s 0.9144635209332267\n",
            "Batch 3080 of 6492. Elapsed 0:15:15\n",
            "Sample: 0.7664405703544617 v/s 0.7797034382820129 v/s 0.8223318280596377\n",
            "Batch 3090 of 6492. Elapsed 0:15:18\n",
            "Sample: 0.7769259810447693 v/s 0.7708104252815247 v/s 0.8424142391333024\n",
            "Batch 3100 of 6492. Elapsed 0:15:21\n",
            "Sample: 0.7469323873519897 v/s 0.7233922481536865 v/s 0.7716212633640268\n",
            "Batch 3110 of 6492. Elapsed 0:15:24\n",
            "Sample: 0.7780628204345703 v/s 0.8721147179603577 v/s 0.8932836016701321\n",
            "Batch 3120 of 6492. Elapsed 0:15:27\n",
            "Sample: 0.8284465074539185 v/s 0.8077656030654907 v/s 0.8589696623498816\n",
            "Batch 3130 of 6492. Elapsed 0:15:29\n",
            "Sample: 0.8318538665771484 v/s 0.869773805141449 v/s 0.898570831091465\n",
            "Batch 3140 of 6492. Elapsed 0:15:32\n",
            "Sample: 0.8201876878738403 v/s 0.805536150932312 v/s 0.8268516228275662\n",
            "Batch 3150 of 6492. Elapsed 0:15:35\n",
            "Sample: 0.7996490001678467 v/s 0.7375981211662292 v/s 0.8011567116417181\n",
            "Batch 3160 of 6492. Elapsed 0:15:38\n",
            "Sample: 0.7951922416687012 v/s 0.7816088199615479 v/s 0.8253972687973818\n",
            "Batch 3170 of 6492. Elapsed 0:15:41\n",
            "Sample: 0.8748032450675964 v/s 0.8465419411659241 v/s 0.8871842172164703\n",
            "Batch 3180 of 6492. Elapsed 0:15:44\n",
            "Sample: 0.7208276391029358 v/s 0.6866622567176819 v/s 0.7767416967797542\n",
            "Batch 3190 of 6492. Elapsed 0:15:47\n",
            "Sample: 0.7901901602745056 v/s 0.8943688869476318 v/s 0.9112423061117377\n",
            "Batch 3200 of 6492. Elapsed 0:15:50\n",
            "Sample: 0.8325457572937012 v/s 0.852904200553894 v/s 0.8816444363747523\n",
            "Batch 3210 of 6492. Elapsed 0:15:53\n",
            "Sample: 0.7144580483436584 v/s 0.6661495566368103 v/s 0.7328514274722592\n",
            "Batch 3220 of 6492. Elapsed 0:15:56\n",
            "Sample: 0.845075249671936 v/s 0.9237435460090637 v/s 0.9388743141220771\n",
            "Batch 3230 of 6492. Elapsed 0:15:59\n",
            "Sample: 0.7398372888565063 v/s 0.6889594197273254 v/s 0.7649175417924123\n",
            "Batch 3240 of 6492. Elapsed 0:16:02\n",
            "Sample: 0.8251461386680603 v/s 0.8140423893928528 v/s 0.8693513584371573\n",
            "Batch 3250 of 6492. Elapsed 0:16:05\n",
            "Sample: 0.8415234684944153 v/s 0.8450260758399963 v/s 0.8879054793416196\n",
            "Batch 3260 of 6492. Elapsed 0:16:08\n",
            "Sample: 0.8073055148124695 v/s 0.8270923495292664 v/s 0.8590284292740358\n",
            "Batch 3270 of 6492. Elapsed 0:16:11\n",
            "Sample: 0.825694739818573 v/s 0.8346228003501892 v/s 0.8680488846192796\n",
            "Batch 3280 of 6492. Elapsed 0:16:14\n",
            "Sample: 0.836249589920044 v/s 0.7989757657051086 v/s 0.8547499243514378\n",
            "Batch 3290 of 6492. Elapsed 0:16:17\n",
            "Sample: 0.8144388794898987 v/s 0.8327652812004089 v/s 0.8593597173242241\n",
            "Batch 3300 of 6492. Elapsed 0:16:20\n",
            "Sample: 0.8497388958930969 v/s 0.9014798402786255 v/s 0.937740917051931\n",
            "Batch 3310 of 6492. Elapsed 0:16:23\n",
            "Sample: 0.6833390593528748 v/s 0.7261731028556824 v/s 0.7769139849433253\n",
            "Batch 3320 of 6492. Elapsed 0:16:26\n",
            "Sample: 0.762688159942627 v/s 0.7727197408676147 v/s 0.829023558436973\n",
            "Batch 3330 of 6492. Elapsed 0:16:29\n",
            "Sample: 0.9040017127990723 v/s 0.9744693040847778 v/s 0.9820029206122934\n",
            "Batch 3340 of 6492. Elapsed 0:16:32\n",
            "Sample: 0.8645183444023132 v/s 0.8555240631103516 v/s 0.8819516658034334\n",
            "Batch 3350 of 6492. Elapsed 0:16:35\n",
            "Sample: 0.8122349977493286 v/s 0.7746942043304443 v/s 0.8245485062646469\n",
            "Batch 3360 of 6492. Elapsed 0:16:37\n",
            "Sample: 0.8176417946815491 v/s 0.7978330850601196 v/s 0.8574703879012086\n",
            "Batch 3370 of 6492. Elapsed 0:16:41\n",
            "Sample: 0.7529045343399048 v/s 0.67685866355896 v/s 0.7654045850264377\n",
            "Batch 3380 of 6492. Elapsed 0:16:43\n",
            "Sample: 0.828226625919342 v/s 0.8482286930084229 v/s 0.8868531510746916\n",
            "Batch 3390 of 6492. Elapsed 0:16:46\n",
            "Sample: 0.7911508679389954 v/s 0.7973255515098572 v/s 0.8329901066968525\n",
            "Batch 3400 of 6492. Elapsed 0:16:49\n",
            "Sample: 0.7831647992134094 v/s 0.8556819558143616 v/s 0.8790768143799905\n",
            "Batch 3410 of 6492. Elapsed 0:16:52\n",
            "Sample: 0.8578090071678162 v/s 0.8588244318962097 v/s 0.8960126584573254\n",
            "Batch 3420 of 6492. Elapsed 0:16:55\n",
            "Sample: 0.8587393164634705 v/s 0.876715362071991 v/s 0.9084286703033413\n",
            "Batch 3430 of 6492. Elapsed 0:16:58\n",
            "Sample: 0.8505319952964783 v/s 0.881437361240387 v/s 0.9014883305689287\n",
            "Batch 3440 of 6492. Elapsed 0:17:01\n",
            "Sample: 0.8444380760192871 v/s 0.8345767259597778 v/s 0.8574130962692532\n",
            "Batch 3450 of 6492. Elapsed 0:17:04\n",
            "Sample: 0.8565983176231384 v/s 0.8594115376472473 v/s 0.8948553132434514\n",
            "Batch 3460 of 6492. Elapsed 0:17:07\n",
            "Sample: 0.7680647373199463 v/s 0.7741078734397888 v/s 0.8057497240352544\n",
            "Batch 3470 of 6492. Elapsed 0:17:10\n",
            "Sample: 0.754050076007843 v/s 0.6904587149620056 v/s 0.7439781351194099\n",
            "Batch 3480 of 6492. Elapsed 0:17:13\n",
            "Sample: 0.8123115301132202 v/s 0.8741416335105896 v/s 0.8946056612281195\n",
            "Batch 3490 of 6492. Elapsed 0:17:16\n",
            "Sample: 0.8480783700942993 v/s 0.8644513487815857 v/s 0.8886233764019158\n",
            "Batch 3500 of 6492. Elapsed 0:17:19\n",
            "Sample: 0.813961386680603 v/s 0.7210690975189209 v/s 0.7774762081426727\n",
            "Batch 3510 of 6492. Elapsed 0:17:22\n",
            "Sample: 0.8002106547355652 v/s 0.8426107168197632 v/s 0.8748076937116502\n",
            "Batch 3520 of 6492. Elapsed 0:17:25\n",
            "Sample: 0.8180936574935913 v/s 0.8689435124397278 v/s 0.8964041760698243\n",
            "Batch 3530 of 6492. Elapsed 0:17:28\n",
            "Sample: 0.8232800364494324 v/s 0.8298270106315613 v/s 0.8615871059212217\n",
            "Batch 3540 of 6492. Elapsed 0:17:31\n",
            "Sample: 0.7833619713783264 v/s 0.722847580909729 v/s 0.7925364917978868\n",
            "Batch 3550 of 6492. Elapsed 0:17:34\n",
            "Sample: 0.8157113194465637 v/s 0.7791597843170166 v/s 0.8239378031351662\n",
            "Batch 3560 of 6492. Elapsed 0:17:37\n",
            "Sample: 0.7921499609947205 v/s 0.7740774154663086 v/s 0.8255078940033301\n",
            "Batch 3570 of 6492. Elapsed 0:17:40\n",
            "Sample: 0.7676317691802979 v/s 0.8514293432235718 v/s 0.8782489789682445\n",
            "Batch 3580 of 6492. Elapsed 0:17:43\n",
            "Sample: 0.8477588891983032 v/s 0.8203110694885254 v/s 0.8470844049477944\n",
            "Batch 3590 of 6492. Elapsed 0:17:46\n",
            "Sample: 0.7497912645339966 v/s 0.7337765693664551 v/s 0.7831221817222477\n",
            "Batch 3600 of 6492. Elapsed 0:17:49\n",
            "Sample: 0.8029459714889526 v/s 0.7600883841514587 v/s 0.8085225606639083\n",
            "Batch 3610 of 6492. Elapsed 0:17:52\n",
            "Sample: 0.7149497270584106 v/s 0.6749320030212402 v/s 0.7526988581041955\n",
            "Batch 3620 of 6492. Elapsed 0:17:55\n",
            "Sample: 0.7940231561660767 v/s 0.7301687598228455 v/s 0.7991822493092428\n",
            "Batch 3630 of 6492. Elapsed 0:17:58\n",
            "Sample: 0.754199743270874 v/s 0.7099093198776245 v/s 0.7773302989027268\n",
            "Batch 3640 of 6492. Elapsed 0:18:01\n",
            "Sample: 0.8592438697814941 v/s 0.8572356104850769 v/s 0.8823612977304696\n",
            "Batch 3650 of 6492. Elapsed 0:18:04\n",
            "Sample: 0.898048460483551 v/s 0.9601553082466125 v/s 0.9694476617809061\n",
            "Batch 3660 of 6492. Elapsed 0:18:07\n",
            "Sample: 0.8287038207054138 v/s 0.7655203342437744 v/s 0.8581045749395186\n",
            "Batch 3670 of 6492. Elapsed 0:18:10\n",
            "Sample: 0.8322172164916992 v/s 0.8398572206497192 v/s 0.859129775632102\n",
            "Batch 3680 of 6492. Elapsed 0:18:13\n",
            "Sample: 0.8551927804946899 v/s 0.8870090842247009 v/s 0.9083862617979228\n",
            "Batch 3690 of 6492. Elapsed 0:18:16\n",
            "Sample: 0.7761498093605042 v/s 0.7909138202667236 v/s 0.837087758550513\n",
            "Batch 3700 of 6492. Elapsed 0:18:19\n",
            "Sample: 0.749121367931366 v/s 0.7659817337989807 v/s 0.8092334044015619\n",
            "Batch 3710 of 6492. Elapsed 0:18:22\n",
            "Sample: 0.7773277759552002 v/s 0.6872585415840149 v/s 0.7337335374059748\n",
            "Batch 3720 of 6492. Elapsed 0:18:25\n",
            "Sample: 0.8114744424819946 v/s 0.7775959968566895 v/s 0.8304000496406028\n",
            "Batch 3730 of 6492. Elapsed 0:18:28\n",
            "Sample: 0.7999096512794495 v/s 0.7344081401824951 v/s 0.8011152443149608\n",
            "Batch 3740 of 6492. Elapsed 0:18:32\n",
            "Sample: 0.8239489197731018 v/s 0.8304158449172974 v/s 0.8617508607541229\n",
            "Batch 3750 of 6492. Elapsed 0:18:35\n",
            "Sample: 0.802379310131073 v/s 0.8054271340370178 v/s 0.8401384520599812\n",
            "Batch 3760 of 6492. Elapsed 0:18:38\n",
            "Sample: 0.8003211617469788 v/s 0.7574506998062134 v/s 0.8205929126302562\n",
            "Batch 3770 of 6492. Elapsed 0:18:41\n",
            "Sample: 0.782011091709137 v/s 0.7212002277374268 v/s 0.7741526526001138\n",
            "Batch 3780 of 6492. Elapsed 0:18:44\n",
            "Sample: 0.69974684715271 v/s 0.6950468420982361 v/s 0.7667031339439857\n",
            "Batch 3790 of 6492. Elapsed 0:18:46\n",
            "Sample: 0.7592790126800537 v/s 0.8200773596763611 v/s 0.8551238928162331\n",
            "Batch 3800 of 6492. Elapsed 0:18:49\n",
            "Sample: 0.7958106398582458 v/s 0.7912416458129883 v/s 0.8310836889561978\n",
            "Batch 3810 of 6492. Elapsed 0:18:52\n",
            "Sample: 0.8528522849082947 v/s 0.8973785042762756 v/s 0.913139115782727\n",
            "Batch 3820 of 6492. Elapsed 0:18:55\n",
            "Sample: 0.7656832337379456 v/s 0.7322920560836792 v/s 0.7769134093674928\n",
            "Batch 3830 of 6492. Elapsed 0:18:58\n",
            "Sample: 0.8104546070098877 v/s 0.8003175258636475 v/s 0.8509028062273591\n",
            "Batch 3840 of 6492. Elapsed 0:19:01\n",
            "Sample: 0.7662156224250793 v/s 0.840519368648529 v/s 0.8731056529291508\n",
            "Batch 3850 of 6492. Elapsed 0:19:04\n",
            "Sample: 0.8984072208404541 v/s 0.8691440224647522 v/s 0.904068548766867\n",
            "Batch 3860 of 6492. Elapsed 0:19:07\n",
            "Sample: 0.8217862248420715 v/s 0.7941891551017761 v/s 0.8282710211703685\n",
            "Batch 3870 of 6492. Elapsed 0:19:10\n",
            "Sample: 0.7235281467437744 v/s 0.7450506091117859 v/s 0.7927097108551278\n",
            "Batch 3880 of 6492. Elapsed 0:19:13\n",
            "Sample: 0.7714466452598572 v/s 0.8198373317718506 v/s 0.8678643933202573\n",
            "Batch 3890 of 6492. Elapsed 0:19:16\n",
            "Sample: 0.8355276584625244 v/s 0.8208543062210083 v/s 0.863040074865773\n",
            "Batch 3900 of 6492. Elapsed 0:19:19\n",
            "Sample: 0.6950141787528992 v/s 0.6856040358543396 v/s 0.7416544938337518\n",
            "Batch 3910 of 6492. Elapsed 0:19:21\n",
            "Sample: 0.755539059638977 v/s 0.7286269068717957 v/s 0.7926765065253942\n",
            "Batch 3920 of 6492. Elapsed 0:19:24\n",
            "Sample: 0.8113759160041809 v/s 0.7708248496055603 v/s 0.8254824089340974\n",
            "Batch 3930 of 6492. Elapsed 0:19:27\n",
            "Sample: 0.8278217911720276 v/s 0.8153111338615417 v/s 0.8492662193629862\n",
            "Batch 3940 of 6492. Elapsed 0:19:30\n",
            "Sample: 0.7562861442565918 v/s 0.7454343438148499 v/s 0.8281033701330713\n",
            "Batch 3950 of 6492. Elapsed 0:19:33\n",
            "Sample: 0.8819515705108643 v/s 0.9267356395721436 v/s 0.9385235955519681\n",
            "Batch 3960 of 6492. Elapsed 0:19:36\n",
            "Sample: 0.7719072699546814 v/s 0.7332566976547241 v/s 0.8019348598060098\n",
            "Batch 3970 of 6492. Elapsed 0:19:40\n",
            "Sample: 0.8715967535972595 v/s 0.8753828406333923 v/s 0.9192490369983332\n",
            "Batch 3980 of 6492. Elapsed 0:19:43\n",
            "Sample: 0.7404565811157227 v/s 0.7467430830001831 v/s 0.8008229150851889\n",
            "Batch 3990 of 6492. Elapsed 0:19:46\n",
            "Sample: 0.7184707522392273 v/s 0.7273903489112854 v/s 0.7751901987064115\n",
            "Batch 4000 of 6492. Elapsed 0:19:49\n",
            "Sample: 0.8440641164779663 v/s 0.8602412343025208 v/s 0.910069025495257\n",
            "Batch 4010 of 6492. Elapsed 0:19:52\n",
            "Sample: 0.6943700313568115 v/s 0.727629542350769 v/s 0.7939568212181966\n",
            "Batch 4020 of 6492. Elapsed 0:19:54\n",
            "Sample: 0.7505902647972107 v/s 0.7442439198493958 v/s 0.7871823139401853\n",
            "Batch 4030 of 6492. Elapsed 0:19:57\n",
            "Sample: 0.837257444858551 v/s 0.8864913582801819 v/s 0.925787965553098\n",
            "Batch 4040 of 6492. Elapsed 0:20:00\n",
            "Sample: 0.8169160485267639 v/s 0.8212559223175049 v/s 0.8613156888351187\n",
            "Batch 4050 of 6492. Elapsed 0:20:03\n",
            "Sample: 0.8369154930114746 v/s 0.80669105052948 v/s 0.8368836571181858\n",
            "Batch 4060 of 6492. Elapsed 0:20:06\n",
            "Sample: 0.7435124516487122 v/s 0.7244873046875 v/s 0.764714974223049\n",
            "Batch 4070 of 6492. Elapsed 0:20:09\n",
            "Sample: 0.8339588642120361 v/s 0.8555567860603333 v/s 0.875600818708678\n",
            "Batch 4080 of 6492. Elapsed 0:20:12\n",
            "Sample: 0.7940483689308167 v/s 0.7701234817504883 v/s 0.8129863792203742\n",
            "Batch 4090 of 6492. Elapsed 0:20:15\n",
            "Sample: 0.8386211395263672 v/s 0.8682835698127747 v/s 0.8901547308895883\n",
            "Batch 4100 of 6492. Elapsed 0:20:18\n",
            "Sample: 0.7445425987243652 v/s 0.7249937653541565 v/s 0.7880930397298489\n",
            "Batch 4110 of 6492. Elapsed 0:20:21\n",
            "Sample: 0.8236662149429321 v/s 0.8185983300209045 v/s 0.8499872552729638\n",
            "Batch 4120 of 6492. Elapsed 0:20:24\n",
            "Sample: 0.8645099401473999 v/s 0.8738101720809937 v/s 0.9109536224460043\n",
            "Batch 4130 of 6492. Elapsed 0:20:27\n",
            "Sample: 0.8133247494697571 v/s 0.788853645324707 v/s 0.8243010038126017\n",
            "Batch 4140 of 6492. Elapsed 0:20:30\n",
            "Sample: 0.800279438495636 v/s 0.8006091117858887 v/s 0.8414447674109321\n",
            "Batch 4150 of 6492. Elapsed 0:20:33\n",
            "Sample: 0.7818222045898438 v/s 0.8424816131591797 v/s 0.8812711101860203\n",
            "Batch 4160 of 6492. Elapsed 0:20:36\n",
            "Sample: 0.7926017045974731 v/s 0.7479134202003479 v/s 0.8065368315736533\n",
            "Batch 4170 of 6492. Elapsed 0:20:39\n",
            "Sample: 0.7949732542037964 v/s 0.7718101739883423 v/s 0.831519205877132\n",
            "Batch 4180 of 6492. Elapsed 0:20:42\n",
            "Sample: 0.7561123371124268 v/s 0.777146577835083 v/s 0.8216058169611561\n",
            "Batch 4190 of 6492. Elapsed 0:20:45\n",
            "Sample: 0.8272792100906372 v/s 0.8354020714759827 v/s 0.8843614883880976\n",
            "Batch 4200 of 6492. Elapsed 0:20:48\n",
            "Sample: 0.8734564781188965 v/s 0.8900409936904907 v/s 0.9103209355509909\n",
            "Batch 4210 of 6492. Elapsed 0:20:51\n",
            "Sample: 0.846342146396637 v/s 0.7793041467666626 v/s 0.8270465619520561\n",
            "Batch 4220 of 6492. Elapsed 0:20:54\n",
            "Sample: 0.76747727394104 v/s 0.7429488301277161 v/s 0.7855376175917006\n",
            "Batch 4230 of 6492. Elapsed 0:20:57\n",
            "Sample: 0.8098464608192444 v/s 0.763764500617981 v/s 0.7924580655031677\n",
            "Batch 4240 of 6492. Elapsed 0:21:00\n",
            "Sample: 0.8423486948013306 v/s 0.9336672425270081 v/s 0.9584632490666292\n",
            "Batch 4250 of 6492. Elapsed 0:21:03\n",
            "Sample: 0.8043598532676697 v/s 0.9326527118682861 v/s 0.9519116488286992\n",
            "Batch 4260 of 6492. Elapsed 0:21:05\n",
            "Sample: 0.803928017616272 v/s 0.8272924423217773 v/s 0.8543004135780806\n",
            "Batch 4270 of 6492. Elapsed 0:21:08\n",
            "Sample: 0.8318374156951904 v/s 0.8364927172660828 v/s 0.8669355475774674\n",
            "Batch 4280 of 6492. Elapsed 0:21:11\n",
            "Sample: 0.7594093680381775 v/s 0.7152697443962097 v/s 0.7738100924414189\n",
            "Batch 4290 of 6492. Elapsed 0:21:14\n",
            "Sample: 0.7732338309288025 v/s 0.7426374554634094 v/s 0.7834482603211613\n",
            "Batch 4300 of 6492. Elapsed 0:21:17\n",
            "Sample: 0.7505567669868469 v/s 0.7789180874824524 v/s 0.8197309171735868\n",
            "Batch 4310 of 6492. Elapsed 0:21:20\n",
            "Sample: 0.8331416249275208 v/s 0.8161913156509399 v/s 0.8529473098610008\n",
            "Batch 4320 of 6492. Elapsed 0:21:23\n",
            "Sample: 0.8314316272735596 v/s 0.8713874220848083 v/s 0.9036074972011273\n",
            "Batch 4330 of 6492. Elapsed 0:21:26\n",
            "Sample: 0.7628559470176697 v/s 0.7697934508323669 v/s 0.8343382412385709\n",
            "Batch 4340 of 6492. Elapsed 0:21:29\n",
            "Sample: 0.8314725160598755 v/s 0.7991887331008911 v/s 0.8478673903868533\n",
            "Batch 4350 of 6492. Elapsed 0:21:32\n",
            "Sample: 0.8621684312820435 v/s 0.9342208504676819 v/s 0.9518784077725183\n",
            "Batch 4360 of 6492. Elapsed 0:21:35\n",
            "Sample: 0.8444660902023315 v/s 0.8069857954978943 v/s 0.8593203456299007\n",
            "Batch 4370 of 6492. Elapsed 0:21:38\n",
            "Sample: 0.6784780621528625 v/s 0.6390610337257385 v/s 0.7377667788909494\n",
            "Batch 4380 of 6492. Elapsed 0:21:41\n",
            "Sample: 0.7922332286834717 v/s 0.7681821584701538 v/s 0.8116545477373015\n",
            "Batch 4390 of 6492. Elapsed 0:21:44\n",
            "Sample: 0.8413970470428467 v/s 0.8489450812339783 v/s 0.8872820452133103\n",
            "Batch 4400 of 6492. Elapsed 0:21:47\n",
            "Sample: 0.8072034120559692 v/s 0.7272652387619019 v/s 0.7786430747535562\n",
            "Batch 4410 of 6492. Elapsed 0:21:50\n",
            "Sample: 0.8451229929924011 v/s 0.83368319272995 v/s 0.8894178029912015\n",
            "Batch 4420 of 6492. Elapsed 0:21:53\n",
            "Sample: 0.7976393103599548 v/s 0.8434019088745117 v/s 0.8824493470714456\n",
            "Batch 4430 of 6492. Elapsed 0:21:56\n",
            "Sample: 0.7214616537094116 v/s 0.7155946493148804 v/s 0.7705530929740337\n",
            "Batch 4440 of 6492. Elapsed 0:21:58\n",
            "Sample: 0.8222373127937317 v/s 0.8375245332717896 v/s 0.8711699609826431\n",
            "Batch 4450 of 6492. Elapsed 0:22:02\n",
            "Sample: 0.8104802966117859 v/s 0.7438568472862244 v/s 0.8010026776214765\n",
            "Batch 4460 of 6492. Elapsed 0:22:05\n",
            "Sample: 0.8346005082130432 v/s 0.730512797832489 v/s 0.830611456784123\n",
            "Batch 4470 of 6492. Elapsed 0:22:08\n",
            "Sample: 0.8762048482894897 v/s 0.9107560515403748 v/s 0.9290464901203735\n",
            "Batch 4480 of 6492. Elapsed 0:22:11\n",
            "Sample: 0.7717170715332031 v/s 0.7855833768844604 v/s 0.831819377562835\n",
            "Batch 4490 of 6492. Elapsed 0:22:14\n",
            "Sample: 0.7357066869735718 v/s 0.8322490453720093 v/s 0.8577252713847906\n",
            "Batch 4500 of 6492. Elapsed 0:22:17\n",
            "Sample: 0.791118860244751 v/s 0.7965643405914307 v/s 0.838289623072462\n",
            "Batch 4510 of 6492. Elapsed 0:22:20\n",
            "Sample: 0.7521263360977173 v/s 0.7569060921669006 v/s 0.8191855873912667\n",
            "Batch 4520 of 6492. Elapsed 0:22:23\n",
            "Sample: 0.797620952129364 v/s 0.747447669506073 v/s 0.8020460582145356\n",
            "Batch 4530 of 6492. Elapsed 0:22:26\n",
            "Sample: 0.7476405501365662 v/s 0.7122328877449036 v/s 0.7577510294837947\n",
            "Batch 4540 of 6492. Elapsed 0:22:29\n",
            "Sample: 0.7817531824111938 v/s 0.7584980130195618 v/s 0.8002610063333969\n",
            "Batch 4550 of 6492. Elapsed 0:22:32\n",
            "Sample: 0.8177385926246643 v/s 0.72568678855896 v/s 0.7871695908107845\n",
            "Batch 4560 of 6492. Elapsed 0:22:35\n",
            "Sample: 0.810438871383667 v/s 0.8095270395278931 v/s 0.8266909146133292\n",
            "Batch 4570 of 6492. Elapsed 0:22:38\n",
            "Sample: 0.8058190941810608 v/s 0.7854191660881042 v/s 0.8376664193995925\n",
            "Batch 4580 of 6492. Elapsed 0:22:41\n",
            "Sample: 0.8054505586624146 v/s 0.7665862441062927 v/s 0.8172878489560265\n",
            "Batch 4590 of 6492. Elapsed 0:22:44\n",
            "Sample: 0.7543090581893921 v/s 0.7569454312324524 v/s 0.8171971923787277\n",
            "Batch 4600 of 6492. Elapsed 0:22:46\n",
            "Sample: 0.8080235719680786 v/s 0.7975244522094727 v/s 0.8515713961882886\n",
            "Batch 4610 of 6492. Elapsed 0:22:50\n",
            "Sample: 0.8522711992263794 v/s 0.8186070322990417 v/s 0.8495241284134643\n",
            "Batch 4620 of 6492. Elapsed 0:22:53\n",
            "Sample: 0.8116341233253479 v/s 0.8064625859260559 v/s 0.8351208348828323\n",
            "Batch 4630 of 6492. Elapsed 0:22:56\n",
            "Sample: 0.8664801120758057 v/s 0.8539170026779175 v/s 0.9033497034853786\n",
            "Batch 4640 of 6492. Elapsed 0:22:59\n",
            "Sample: 0.841251790523529 v/s 0.859401285648346 v/s 0.8920321434494314\n",
            "Batch 4650 of 6492. Elapsed 0:23:02\n",
            "Sample: 0.7388583421707153 v/s 0.7890642285346985 v/s 0.845540045950556\n",
            "Batch 4660 of 6492. Elapsed 0:23:05\n",
            "Sample: 0.7142863273620605 v/s 0.7447208762168884 v/s 0.8172651436301432\n",
            "Batch 4670 of 6492. Elapsed 0:23:08\n",
            "Sample: 0.8289951086044312 v/s 0.8172025084495544 v/s 0.8653346569040591\n",
            "Batch 4680 of 6492. Elapsed 0:23:11\n",
            "Sample: 0.8387808799743652 v/s 0.8113969564437866 v/s 0.8517440103800388\n",
            "Batch 4690 of 6492. Elapsed 0:23:14\n",
            "Sample: 0.8256499767303467 v/s 0.7772237062454224 v/s 0.8152862943550326\n",
            "Batch 4700 of 6492. Elapsed 0:23:17\n",
            "Sample: 0.8205496668815613 v/s 0.7599698901176453 v/s 0.8170553424680477\n",
            "Batch 4710 of 6492. Elapsed 0:23:20\n",
            "Sample: 0.8908382058143616 v/s 0.919628381729126 v/s 0.9451896655558643\n",
            "Batch 4720 of 6492. Elapsed 0:23:22\n",
            "Sample: 0.7557786703109741 v/s 0.7834200859069824 v/s 0.8379685828770865\n",
            "Batch 4730 of 6492. Elapsed 0:23:26\n",
            "Sample: 0.8595127463340759 v/s 0.8522915840148926 v/s 0.892544104633066\n",
            "Batch 4740 of 6492. Elapsed 0:23:28\n",
            "Sample: 0.8555905222892761 v/s 0.8726630806922913 v/s 0.9186051702590022\n",
            "Batch 4750 of 6492. Elapsed 0:23:31\n",
            "Sample: 0.7379622459411621 v/s 0.7627789378166199 v/s 0.8123236183547632\n",
            "Batch 4760 of 6492. Elapsed 0:23:35\n",
            "Sample: 0.8571142554283142 v/s 0.9416178464889526 v/s 0.9531168015359212\n",
            "Batch 4770 of 6492. Elapsed 0:23:38\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-418b38b1b10c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrue_stoi_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=============== Discriminator Epoch {} / {} =================\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_DISCRIMINATOR_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0minput_noisy_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-e49a491ac8f8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_discriminator_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-4c1e847904cf>\u001b[0m in \u001b[0;36mget_discriminator_sample\u001b[0;34m(file_pair)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mclean_wav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mclean_spectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_to_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0mtrue_stoi_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_wav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoisy_wav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_sig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;31m# both spectrograms are of the shape (1, n_frames, 257) now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pystoi/stoi.py\u001b[0m in \u001b[0;36mstoi\u001b[0;34m(x, y, fs_sig, extended)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfs_sig\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mFS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample_oct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample_oct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Remove silent frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pystoi/utils.py\u001b[0m in \u001b[0;36mresample_oct\u001b[0;34m(x, p, q)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resample_window_oct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mresample_poly\u001b[0;34m(x, up, down, axis, window, padtype, cval)\u001b[0m\n\u001b[1;32m   3123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3124\u001b[0m     \u001b[0;31m# filter then remove excess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3125\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupfirdn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mupfirdn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3126\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3127\u001b[0m     \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pre_remove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pre_remove_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/signal/_upfirdn.py\u001b[0m in \u001b[0;36mupfirdn\u001b[0;34m(h, x, up, down, axis, mode, cval)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mufd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UpFIRDn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;31m# This is equivalent to (but faster than) using np.apply_along_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/signal/_upfirdn.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(self, x, axis, mode, cval)\u001b[0m\n\u001b[1;32m     97\u001b[0m         _apply(np.asarray(x, self._output_type),\n\u001b[1;32m     98\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h_trans_flip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                self._up, self._down, axis, mode, cval)\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "save = True\n",
        "if FORCE_RESTART:\n",
        "  start_epoch = 0\n",
        "elif CONTINUE:\n",
        "  # Start from RESUME_FROM without loading state\n",
        "  start_epoch = RESUME_FROM\n",
        "else:\n",
        "  start_epoch = load_latest_checkpt() # 0-indexed\n",
        "for gan_epoch in range(start_epoch, NUM_GAN_EPOCHS):\n",
        "  print(\"<<<<<<<<<<<<<<< GAN epoch {} >>>>>>>>>>>>>>>>>\".format(gan_epoch+1))\n",
        "  discriminator.train()\n",
        "  for epoch in range(NUM_DISCRIMINATOR_EPOCHS):\n",
        "    val_sum = 0\n",
        "    epoch_loss = 0\n",
        "    epoch_start = time.time()\n",
        "    true_stoi_avg = 0\n",
        "    print(\"=============== Discriminator Epoch {} / {} =================\".format(epoch+1, NUM_DISCRIMINATOR_EPOCHS))\n",
        "    for step, batch in enumerate(discriminator_dataloader):\n",
        "      discriminator.zero_grad()\n",
        "      input_noisy_discriminator = batch[0].to(device)\n",
        "      expected_out_noisy = batch[1].to(device)\n",
        "\n",
        "      outputs_noisy = discriminator(input_noisy_discriminator)\n",
        "      MSE = nn.MSELoss(reduction='sum')\n",
        "      loss = MSE(outputs_noisy, expected_out_noisy)\n",
        "      epoch_loss += loss\n",
        "      loss.backward()\n",
        "      val_sum += outputs_noisy[0][0]\n",
        "      clip_grad_norm_(discriminator.parameters(), 1.0)\n",
        "      discriminator_optimizer.step()\n",
        "      true_stoi_avg += batch[1]\n",
        "      if step % 10 == 0 and step != 0:\n",
        "        elapsed = format_time(time.time() - epoch_start)\n",
        "        noisy = input_noisy_discriminator[0,0,:,:].cpu().detach().numpy()\n",
        "        clean = input_noisy_discriminator[0,1,:,:].cpu().detach().numpy()\n",
        "        x = batch[2][0,:,:].cpu().detach().numpy()\n",
        "        y = batch[3][0].cpu().detach().numpy()\n",
        "        noisy_wav = spectrogram_to_wav(noisy.T, x, y) / SCALE_FACTOR\n",
        "        clean_wav = spectrogram_to_wav(clean.T, x, y)\n",
        "        print(\"Sample: {} v/s {} v/s {}\".format(outputs_noisy[0][0], expected_out_noisy[0][0], stoi(x=clean_wav, y=noisy_wav, fs_sig=16000, extended=False)))\n",
        "        print(\"Batch {} of {}. Elapsed {}\".format(step, len(discriminator_dataloader), elapsed))\n",
        "    avg_train_loss = epoch_loss / (step+1)\n",
        "    true_stoi_avg = true_stoi_avg / (step+1)\n",
        "    val_sum = val_sum / (step+1)\n",
        "    print(\"Average discriminator training loss for epoch {} : {}\".format(epoch+1, avg_train_loss))\n",
        "    print(\"Average True STOI for generated outputs last epoch: {}\".format(true_stoi_avg[0][0]))\n",
        "    print(\"Epoch took {}\".format(format_time(time.time()-epoch_start)))\n",
        "    print(\"\")\n",
        "\n",
        "  discriminator.eval()\n",
        "  generator.train()\n",
        "  for epoch in range(NUM_GENERATOR_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    print(\"============= Generator Epoch {} / {} =================\".format(epoch+1, NUM_GENERATOR_EPOCHS))\n",
        "    epoch_start = time.time()\n",
        "    for step, batch in enumerate(generator_dataloader):\n",
        "      generator.zero_grad()\n",
        "      input_generator = batch[0].to(device)\n",
        "      noisy_audio = batch[1].to(device)\n",
        "      clean = batch[2].to(device)\n",
        "      min_mask = batch[3].to(device)\n",
        "      target = torch.tensor([[2.0]]).to(device)\n",
        "\n",
        "      output_generator = generator(input_generator)\n",
        "      mask = torch.maximum(output_generator, min_mask)\n",
        "      cleaned = torch.mul(mask, noisy_audio)\n",
        "      stacked = torch.unsqueeze(torch.cat((cleaned, clean), axis=0), 0)\n",
        "      discriminator_output = discriminator(stacked)\n",
        "      MSE = nn.MSELoss(reduction='sum')\n",
        "      loss = MSE(discriminator_output, target)\n",
        "      epoch_loss += loss\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(generator.parameters(), 1.0)\n",
        "      generator_optimizer.step()\n",
        "      if step % 10 == 0 and step != 0:\n",
        "        elapsed = format_time(time.time() - epoch_start)\n",
        "        cleaned = cleaned.squeeze().cpu().detach().numpy()\n",
        "        clean = clean.squeeze().cpu().detach().numpy()\n",
        "        x = batch[4][0,:,:].cpu().detach().numpy()\n",
        "        y = batch[5][0].cpu().detach().numpy()\n",
        "        cleaned_wav = spectrogram_to_wav(cleaned.T, x, y)  / SCALE_FACTOR\n",
        "        clean_wav = spectrogram_to_wav(clean.T, x, y)\n",
        "        print(\"Sample: {} v/s {}\".format(discriminator_output[0][0], stoi(x=clean_wav, y=cleaned_wav, fs_sig=16000, extended=False)))\n",
        "        print(\"Batch {} of {}. Elapsed {}\".format(step, len(generator_dataloader), elapsed))\n",
        "    avg_train_loss = epoch_loss / len(generator_dataloader)\n",
        "    print(\"Average generator training loss for epoch {} : {}\".format(epoch+1, avg_train_loss))\n",
        "    print(\"Epoch took {}\".format(format_time(time.time()-epoch_start)))\n",
        "    print(\"\")\n",
        "\n",
        "  print(\"Saving new files for next epoch\")\n",
        "  generator.eval()\n",
        "  if not os.path.exists('/content/gdrive/MyDrive/SE-training/epoch{}'.format(gan_epoch)):\n",
        "      os.mkdir('/content/gdrive/MyDrive/SE-training/epoch{}'.format(gan_epoch))\n",
        "  new_pairs = []\n",
        "  avg_stoi = 0\n",
        "  for file_pair in file_pairs:\n",
        "    batch = get_generator_sample(file_pair)\n",
        "    input_generator = batch[0].unsqueeze(0).to(device)\n",
        "    noisy_audio = batch[1].unsqueeze(0).to(device)\n",
        "    min_mask = batch[3].unsqueeze(0).to(device)\n",
        "\n",
        "    new_pair_name = (file_pair[0], get_path_for_generator(file_pair[1], gan_epoch))\n",
        "    output_generator = generator(input_generator)\n",
        "    mask = torch.maximum(output_generator, min_mask)\n",
        "    cleaned = torch.mul(mask, noisy_audio).squeeze().cpu().detach().numpy()\n",
        "    cleaned_wav = spectrogram_to_wav(cleaned.T, batch[4], batch[5]) / SCALE_FACTOR\n",
        "    orig_clean = librosa.load(file_pair[0], sr=16000)[0]\n",
        "    s = stoi(x=orig_clean, y=cleaned_wav, fs_sig=16000, extended=False)\n",
        "    avg_stoi += s\n",
        "    sf.write(new_pair_name[1], cleaned_wav, 16000)\n",
        "    new_pairs.append(new_pair_name)\n",
        "  new_pairs += high_pairs\n",
        "  avg_stoi /= len(file_pairs)\n",
        "  print(\"Average STOI: {}\".format(avg_stoi))\n",
        "  # New dataset for discriminator\n",
        "  discriminator_dataset = DiscriminatorDataset(new_pairs)\n",
        "  discriminator_sampler = RandomSampler(discriminator_dataset)\n",
        "  discriminator_dataloader = DataLoader(discriminator_dataset, sampler=discriminator_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "  if save:\n",
        "      torch.save(generator.state_dict(), os.path.join(CHECKPT_DIR, \"checkpt-gen-{}.pt\".format(gan_epoch+1)))\n",
        "      torch.save(discriminator.state_dict(), os.path.join(CHECKPT_DIR, \"checkpt-dis-{}.pt\".format(gan_epoch+1)))\n",
        "      torch.save(generator_optimizer.state_dict(), os.path.join(CHECKPT_DIR, \"checkpt-genopt-{}.pt\".format(gan_epoch+1)))\n",
        "      torch.save(discriminator_optimizer.state_dict(), os.path.join(CHECKPT_DIR, \"checkpt-disopt-{}.pt\".format(gan_epoch+1)))\n",
        "      pickle.dump(new_pairs, open(os.path.join(CHECKPT_DIR, \"npairs_{}.pkl\".format(gan_epoch+1)), 'wb+'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cSoSTAoicTc"
      },
      "outputs": [],
      "source": [
        "def run_generator_on_path(in_path, out_path=None):\n",
        "  if out_path is None:\n",
        "    out_path = in_path.split('.wav')[0] + '-out.wav'\n",
        "  noisy_wav, _ = librosa.load(in_path, sr=16000)\n",
        "  noisy_spectrogram_normalized, _, _ = wav_to_spectrogram(noisy_wav*SCALE_FACTOR, normalize=True)\n",
        "  noisy_spectrogram, phase, length = wav_to_spectrogram(noisy_wav*SCALE_FACTOR)\n",
        "\n",
        "  # The spectrograms now have the shape, (num_frames, frame_dim)\n",
        "  # which is what we want to give to the generator, since it expects (batch_size, seq_length, input_size)\n",
        "  # when batch_first=True is passed\n",
        "  noisy_spectrogram_normalized = torch.from_numpy(noisy_spectrogram_normalized)\n",
        "  noisy_spectrogram = torch.from_numpy(noisy_spectrogram)\n",
        "  mask = MASK_MIN_VALUE * torch.ones((noisy_spectrogram.shape[0], 257))\n",
        "\n",
        "  noisy_spectrogram_normalized = noisy_spectrogram_normalized.unsqueeze(0).to(device)\n",
        "  noisy_spectrogram = noisy_spectrogram.unsqueeze(0).to(device)\n",
        "  mask = mask.unsqueeze(0).to(device)\n",
        "  output_generator = generator(noisy_spectrogram_normalized)\n",
        "  mask = torch.maximum(output_generator, mask)\n",
        "  cleaned = torch.mul(mask, noisy_spectrogram).squeeze().cpu().detach().numpy()\n",
        "  cleaned_wav = spectrogram_to_wav(cleaned.T, phase, length) / SCALE_FACTOR\n",
        "  sf.write(out_path, cleaned_wav, 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLUSQd5DFvG1"
      },
      "outputs": [],
      "source": [
        "# num = 19\n",
        "# dblevel = 0.0\n",
        "for num in range(1,61):\n",
        "  for dblevel in [0.0, 10.0]:\n",
        "    name_wav = \"noisy{}_SNRdb_{:.1f}_clnsp{}.wav\".format(num, dblevel, num)\n",
        "    FROM_DIR = \"/content/gdrive/MyDrive/MS-SNSD-dataset-30/test-main/noisy/\"\n",
        "    TO_DIR = \"/content/gdrive/MyDrive/saved/tt1/test-main/\"\n",
        "    run_generator_on_path(FROM_DIR + name_wav, TO_DIR + name_wav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv-GsX1RVqJk"
      },
      "outputs": [],
      "source": [
        "def mix_audio_wavs(signal, noise, snr):\n",
        "  # Source: https://stackoverflow.com/questions/71915018/mix-second-audio-clip-at-specific-snr-to-original-audio-file-in-python\n",
        "  # if the audio is longer than the noise\n",
        "  # play the noise in repeat for the duration of the audio\n",
        "  noise = noise[np.arange(len(signal)) % len(noise)]\n",
        "\n",
        "  # if the audio is shorter than the noi\n",
        "  # this is important if loading resulted in \n",
        "  # uint8 or uint16 types, because it would cause overflow\n",
        "  # when squaring and calculating mean\n",
        "  noise = noise.astype(np.float32)\n",
        "  signal = signal.astype(np.float32)\n",
        "\n",
        "  # get the initial energy for reference\n",
        "  signal_energy = np.mean(signal**2)\n",
        "  noise_energy = np.mean(noise**2)\n",
        "  # calculates the gain to be applied to the noise \n",
        "  # to achieve the given SNR\n",
        "  g = np.sqrt(10.0 ** (-snr/10) * signal_energy / noise_energy)\n",
        "\n",
        "  # Assumes signal and noise to be decorrelated\n",
        "  # and calculate (a, b) such that energy of \n",
        "  # a*signal + b*noise matches the energy of the input signal\n",
        "  a = np.sqrt(1 / (1 + g**2))\n",
        "  b = np.sqrt(g**2 / (1 + g**2))\n",
        "  # print(g, a, b)\n",
        "  # mix the signals\n",
        "  return signal + g * noise\n",
        "\n",
        "def add_noise(sound_file, noise_file, snr=0.0, out_file=None):\n",
        "  if out_file is None:\n",
        "    out_file = sound_file.split('.wav')[0] + '-noisy.wav'\n",
        "  sound_wav, _ = librosa.load(sound_file, sr=16000)\n",
        "  noise_wav, _ = librosa.load(noise_file, sr=16000)\n",
        "  mixed = mix_audio_wavs(sound_wav, noise_wav, snr)\n",
        "  sf.write(out_file, mixed, 16000)\n",
        "\n",
        "def convert_m4a_to_wav(m4a, wav=None):\n",
        "  if wav is None:\n",
        "    wav = m4a.split(\".m4a\")[0] + \".wav\"\n",
        "  track = AudioSegment.from_file(m4a,  format= 'm4a')\n",
        "  file_handle = track.export(wav, format='wav')\n",
        "\n",
        "def full_cycle(file_path, noise_path, snr=0.0, from_m4a=True):\n",
        "  if from_m4a:\n",
        "    convert_m4a_to_wav(file_path)\n",
        "    file_path = file_path.split('.m4a')[0] + '.wav'\n",
        "  add_noise(file_path, noise_path, snr)\n",
        "  noisy_path = file_path.split('.wav')[0] + '-noisy.wav'\n",
        "  run_generator_on_path(noisy_path)\n",
        "\n",
        "def clean(file_path, from_m4a=True):\n",
        "  if from_m4a:\n",
        "    convert_m4a_to_wav(file_path)\n",
        "    file_path = file_path.split('.m4a')[0] + '.wav'\n",
        "  run_generator_on_path(file_path)\n",
        "\n",
        "def clean_video(file_path):\n",
        "  \"\"\"\n",
        "  Extracts audio from the video, cleans it, and then pastes it back on the video\n",
        "  \"\"\"\n",
        "  audio_path = file_path.split(\".mp4\")[0] + \".wav\"\n",
        "  command = \"ffmpeg -i {} -ab 160k -ac 2 -ar 44100 -vn {}\".format(file_path, audio_path)\n",
        "  subprocess.call(command, shell=True)\n",
        "  clean(audio_path)\n",
        "  cleaned_path = audio_path.split(\".wav\")[0] + \"-out.wav\"\n",
        "  new_path = file_path.split(\".mp4\")[0] + \"-cleaned.mp4\"\n",
        "  command = \"ffmpeg -i {} -i {} -c:v copy -map 0:v:0 -map 1:a:0 {}\".format(file_path, cleaned_path, new_path)\n",
        "  subprocess.call(command, shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOEiObjYUU4q"
      },
      "outputs": [],
      "source": [
        "# noise_p = '/content/gdrive/MyDrive/saved/tt1/noise/Bus_1.wav'\n",
        "noise_p = '/content/gdrive/MyDrive/saved/tt1/noise/VacuumCleaner_1.wav'\n",
        "m4a_p = '/content/gdrive/MyDrive/saved/tt1/audio/shaila3.m4a'\n",
        "# full_cycle(m4a_p, noise_p)\n",
        "# clean(m4a_p)\n",
        "clean_video(\"/content/gdrive/MyDrive/saved/tt1/audio/tomscott-esa.mp4\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SpeechEnhancement.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
